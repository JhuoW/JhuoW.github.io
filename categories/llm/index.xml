<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LLM on JhuoW‘s Notes</title>
    <link>https://JhuoW.github.io/categories/llm/</link>
    <description>Recent content in LLM on JhuoW‘s Notes</description>
    <image>
      <url>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 May 2025 11:57:35 +0800</lastBuildDate><atom:link href="https://JhuoW.github.io/categories/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ICLR2024《One for All：Towards Training One Graph Model for All Classification Tasks》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/ofa/</link>
      <pubDate>Wed, 21 May 2025 11:57:35 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/ofa/</guid>
      <description>ICLR2024 &amp;#34;One for All：Towards Training One Graph Model for All Classification Tasks&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><strong>What is in-context learning?</strong></p>
<p>“In-Context Learning is a way to use LLMs to learn tasks given only a few examples. During in-context learning, we give the LM a prompt that consists of a list of input-output pairs that demonstrate how to perform a task. At the end of the prompt, we append a test input and allow the LM to make a prediction just by conditioning on the prompt and predicting the next tokens. For example, to answer the two prompts below, the model needs to examine the training examples to figure out the input distribution (financial or general news), output distribution (Positive/Negative or topic), input-output mapping (sentiment or topic classification), and the formatting. “</p>
<p><img loading="lazy" src="/posts/2025-05-21-OFA/1.gif#center" alt="icl"  />
</p>
<p>如上图所示，在prompt中包含一些上下文input-output pairs来演示（demonstrate）如何执行任务。在这些prompt的最后添加text input token来让LLM学习上下文中的演示来执行text input token的任务。</p>
<h2 id="challenge"><strong>Challenge</strong></h2>
<p>Foundation Model指用单一模型来解决多个任务。但是Graph Foundation Model面临以下挑战：（1）不同来源的图数据在feature表征上通常完全不同。比如molecular graph中的节点特征是其中原子nominal feature的索引，e-commerce networks中的节点特征通常用Bag-of-Word来编码。这些不同来源的图数据特征维度、语义信息和尺度的差别都很大，几乎不可能用同一个模型来学习他们的表示。（2）不同的下游任务涉及图的不同部分（节点级、边级、图级）需要不同的策略和方法来学习表示。（3）如何设计统一的模型来实现跨领域和in-context learning是不确定的。</p>
<h1 id="ofa">OFA</h1>
<h2 id="用tag来统一不同领域的图都转化为tag形式">用TAG来统一不同领域的图（都转化为TAG形式）</h2>
<p><strong>将不同Domian的图转化为统一的TAG形式</strong></p>
<p>用human-interpretable language来描述节点和边的属性，从而使LLM可以将这些text attribute编码到同一个空间。具体来说，通过以下方式来生成每个节点的text feature:
将不同domain的graph的节点属性用统一形式的文本来描述，如上图中，对于一个节点的特征，它的文本描述以<strong>Feature node</strong>开头，后面的每个</p>
<p><img loading="lazy" src="/posts/2025-05-21-OFA/node_text_feature.jpg#center" alt="node_text_feature.jpg"  />
</p>
<p>将不同domain的graph的节点属性用统一形式的文本来描述，如上图中，对于一个节点的特征，它的文本描述以<strong>Feature node</strong>开头，后面的每个 $&lt;\text{feature describe}&gt;:&lt;\text{feature content}&gt;$是该节点的一个type-content文本对。例如对于一个molecule graph，其中的一个节点是原子，那么它的type是<strong>Atom</strong>，它的content是该原子的属性文本描述<strong>Carbon, Atomic number 6, helix chirality</strong>。如果是Citation Network， type是“Paper title and abstract”，content是“Attention is all you need. balabala”  （该文章具体的标题和摘要）
同理，边的text feature以<strong>Feature edge</strong>开头进行文本描述。</p>
<p>在用以上方式得到节点 $v_i$的text feature $s_{v_i}$和边 $e_{ij}$的text feature $s_{e_{ij}}$后，用LLM（sentence transformer, e5-large-v2, or Llama2）来将每个节点和边的text feature编码为vector embeddings：</p>
<p>$$
x_i = \operatorname{LLM}(s_{v_i}), \quad x_{ij} = \operatorname{LLM}(s_{e_{ij}})
$$</p>
<h2 id="用nodes-of-interest-noi来统一不同的图任务">用Nodes-of-Interest (NOI)来统一不同的图任务</h2>
<p>图上的任务主要分为3中：node-level tasks，link-level tasks和graph-level tasks。如果要用一个模型来处理这些任务的话，<strong>需要将这些任务统一为一个任务以便于在图数据上训练</strong>。</p>
<p><img loading="lazy" src="/posts/2025-05-21-OFA/NOI.jpg#center" alt="NOI.jpg"  />
</p>
<p>Nodes-of-Interest (<strong>NOI</strong>)指的是一个任务的<strong>目标节点（任务感兴趣的节点）</strong>，如上图的蓝色节点所示，表示为 $\mathcal{T}$。</p>
<ol>
<li>对于节点级任务，NOI是待预测节点集合。</li>
<li>边级任务NOI是待预测是否有边的节点对。</li>
<li>图级任务NOI是待预测图中的所有节点。</li>
</ol>
<p>待训练的有很多图，有的图要做节点分类，有的图做链路预测，有的图做图分类，通过构造NOI subgraph的方式，无论是什么任务，都把每个图中所有的 <strong>与任务相关的节点</strong> （nodes-of-interest）提取出来。</p>
<p>若一个NOI节点 $v$的 $h$-hop局部子图表示为 $\mathcal{S}_h(v)$，那么NOI中所有目标节点的局部子图共同构成了一个<strong>NOI subgraph</strong>，表示为 $\mathcal{G}_h (\mathcal{T})$：</p>
<p>$$
\mathcal{G}_h(\mathcal{T})=\bigcup_{v \in \mathcal{T}} \mathcal{S}_h(v)=\left\{\bigcup_{v \in \mathcal{T}} \mathcal{V}_v^h, \bigcup_{v \in \mathcal{T}} \mathcal{E}_v^h, \bigcup_{v \in \mathcal{T}} \mathcal{R}_v^h\right\} \quad \text{NOI中所有节点的局部子图共同构成}
$$</p>
<p><strong>NOI prompt node</strong>：定义NOI prompt node，该节点的文本信息用来描述任务，比如某个数据集上的节点分类、图分类等。NOI prompt node的节点text feature以如下形式构建：</p>
<p><img loading="lazy" src="/posts/2025-05-21-OFA/NOI_prompt_node.jpg" alt="NOI_prompt_node.jpg"  />
</p>
<p>NOI prompt node的节点特征以 “Prompt node.” 开头，该节点的文本表述为需要在NOI上进行的task，如果需要对NOI做node classification，那么Prompt node的文本特征为：“Node classification on the literature category of the paper.”。通过这种方式，即使是图上任务有不同，只需要用不同的NOI prompt node就可以描述不同的任务。</p>
<h2 id="graph-in-context-learning的图提示范式graph-prompting-paradigm">Graph In-Context Learning的图提示范式（Graph Prompting Paradigm）</h2>
<p>LLM的一大特性就是它可以通过prompt来实现in-context learning，使得模型可以在不用fine-tuning的情况下适应于不同的任务。比如在few-shot场景下，目标是基于一篇paper的摘要和内容预测它的类别，我们可以为LLM提供每个类别的 $k$篇papers作为context加入prompt中，来指导模型基于这些提供的context来生成目标摘要和内容的类别预测。（通过一些<strong>任务相关的其他信息</strong>来指导模型对目标样本的预测）</p>
<p>本文发现实现图上in-context learning的核心在于操作输入图使其和下游任务对齐。<strong>Graph Prompting Paradigm (GPP)</strong> 即图提示范式旨在操作输入图使其可以从输入数据本身获得任务相关的信息。如图2中的虚线所示，用来描述任务的NOI prompt node与所有NOI node建立连接（任务的目标节点），表示在这些NOI nodes上执行对应prompt的任务（如节点分类，链路预测，图分类等）。</p>
<p><strong>Zero-shot Learning:</strong> 对于一个NOI $q$，若是节点分类任务 $q$是一个节点；若是边分类任务 $q$是一条边的两端节点；若是图分类任务， $q$是图中的所有节点，如Figure 2中的蓝色节点所示。 $q$中节点构成的局部子图，即NOI subgraph 表示为 $\mathcal{G}^q_h (\mathcal{T}^q) = (\mathcal{V}^h_q, \mathcal{E}^h_q, \mathcal{R}^h_q)$。</p>
<p>对于一个NOI subgraph $\mathcal{G}^q_h (\mathcal{T}^q)$, 该子图的NOI的任务可能是节点级任务也可能是边级或图级任务，根据该NOI subgraph的目标任务不同，将对应任务的NOI prompt node $p_q$与该NOI subgraph中的所有NOI节点 $q$相连。如Figure 2中的虚线所示，任务描述节点NOI prompt node与该任务的目标节点用<strong>虚线</strong>相连。</p>
<p>除此之外，定义class node与NOI prompt node相连，class node用于描述NOI prompt node的分类任务的类别信息，有多少个类别就有多少个class nodes。最终可以得到所有NOI的prompt graph，如Figure 2的左边框中3个prompt graph所示。用同一个GNN模型来训练不同分类任务的Prompt Graph （任务仅仅通过NOI prompt nodes 和class nodes来做区分）。在半监督训练完成后，我们可以得到一个GNN模型，3种任务的NOI prompt nodes的embedding，以及每种任务的class nodes的embedding，以及一个从embedding映射到label的MLP。对于一个新的节点/边，首先提取他的NOI subgraph，如Figure 2的彩色框中所示，然后将新的NOI nodes连接到NOI prompt nodes，再将NOI prompt nodes连接到任务的class nodes。先用训练好的GNN应用在这个新的prompt graph上，然后可以得到每个class node的embedding, 再用训练好的MLP将class node embeddings映射到label space，从而得到该NOI属于不同类别的概率。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>KDD2023《All in One：Multi-Task Prompting for Graph Neural Networks》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/allinone/</link>
      <pubDate>Tue, 20 May 2025 14:22:08 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/allinone/</guid>
      <description>KDD2023 &amp;#34;All in One：Multi-Task Prompting for Graph Neural Networks&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p>图神经网络的预训练任务和下游任务之间可能存在较大gap，直接将预训练模型应用在下游任务上可能会产生负迁移现象（“negative transfer”）。例如，binary edge prediction经常用于pretrain graph model。这样的预训练模型使得有边连接的节点在representation space中接近。但是下游任务可能是node-level 或graph-level tasks，下游的任务如果是节点分类任务，那么预训练模型需要针对额外的节点类别标签搜索更高维度的参数空间。如果图中相连节点的类别不同（heterophilic），那么基于edge prediction pretrained的模型会对下游任务参数负面效果。</p>
<p>为了解决上述问题，一个潜在的方向是将“pretraining and fine-tuning”拓展为“pretraining, <strong>prompting</strong>, and fine-tuning”。例如在自然语言处理中，如果要赋予预训练语言模型预测句子情感的能力（sentiment analysis），可以通过prompt来完成，而不需要优化pretrained model。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/image.png#center" alt="你想输入的替代文字"  />
</p>
<p>以上图为例，对于一个fronzen LLM（参数固定），如果要为这个模型赋予情感分析的能力，我们可以额外训练一个最佳的prompt，训练数据为prompt parameters，要求这个prompt tokens在tasker $\phi$的优化下，生成的下一个token是正确的情感（label为excited）。即训练得到一个最佳的prompt tokens，比如训练得到的最佳prompt tokens是“I feel so [mask]”，使得frozen LLM应用在“KDD2023 will witness many high-quality papers. I feel so ” 这个句子上时，可以将下一个词预测为情感词，这样LLM在输入包含prompt tokens的情况下，可以具备预测句子情感的能力。也就是说， <strong>Prompt Learning的目的是训练得到一堆tokens，使得这些tokens与原来的context拼起来可以使得LLM具备新的能力。</strong></p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/1.png#center" alt="你想输入的替代文字"  />
</p>
<p><strong>这篇文章的目的是在图上做Prompt Learning，也就是在训练一个prompt graph，使得现有图拼上这个prompt graph后，预训练的GNN可以在新的任务上（预训练阶段没有接触过的任务上）也表现的较好。</strong> 但是在graph上做Prompt Learning存在以下挑战：</p>
<ul>
<li>自然语言处理中，prompt tokens是一个一维线性的句子，可以放在content的开头或结尾，但是在graph中，节点是非欧结构，因此如何组织prompt tokens，以及如何将graph prompts与input graph结合是一个挑战。</li>
<li>在自然语言处理中，类似于情感分析，和问答任务，这些任务都可以简单的重构为next token prediction（单词预测）的任务，所以只需要使用单词预测来训练prompt就可以。但是在图中，节点级任务、边级任务和图级任务难以统一成一种形式。因此如何将各种prompt任务统一来训练graph prompt也是一个挑战。</li>
</ul>
<p>训练好prompt token的向量化信息、连接结构、以及插入到原图的方式，然后Frozen Pretrained Model应用在这个combined graph上后，就可以为Pretrained Model赋予处理新任务的能力。</p>
<h2 id="reformulating-downstream-tasks">Reformulating Downstream Tasks</h2>
<p>将节点级和边级的下游任务统一为induced graph的标签预测问题。</p>
<p>对于节点预测任务，将它重构为图分类任务：</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/2.png#center" alt="你想输入的替代文字"  />
</p>
<p>将节点标签设置为它的 $k$-hop诱导子图的标签。</p>
<p>将边预测（存在性预测和类别预测都可以，即二分类和多分类）任务也重构为图分类任务，如下：</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/3.png#center" alt="你想输入的替代文字"  />
</p>
<h2 id="prompt-graph-design">Prompt Graph Design</h2>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/4.png#center" alt="你想输入的替代文字"  />
</p>
<p><strong>Prompt Tokens</strong> 首先Prompt graph 定义为 $\mathcal{G}_p(\mathcal{P},\mathcal{S})$，其中每个token $p_i \in \mathcal{P}$是Prompt graph中的节点，它的特征是 $\mathbf{p}_i$，维度与node features相同。</p>
<p><strong>Token Structures</strong> 每个tokens的特征 $\mathbf{p}_i$是随机初始化可学习的，然后可以通过计算相似度并用sigmoid和相应的阈值来控制 $\mathcal{G}_p$的结构。然后可以计算 $\mathbf{p}_k$和节点 $\mathbf{x}_i$之间的相似度来确定该prompt node如何将自身信息与节点 $\mathbf{x}_i$的信息结合，来赋予预训练模型处理节点 $i$相应任务的能力。
$$
w_{i k}= \begin{cases}\sigma\left(\mathrm{p}_k \cdot \mathrm{x}_i^T\right) &amp; \sigma\left(\mathrm{p}_k \cdot \mathrm{x}_i^T\right)&gt;\delta \\ 0 &amp; \text { otherwise }\end{cases}
$$</p>
<p>通过 $\hat{\mathbf{x}}_i=\mathbf{x}_i+\sum_{k=1}^{|\mathcal{P}|} w_{i k} \mathbf{p}_k$ 来为节点 $i$添加提示。</p>
<h2 id="如何训练-prompt-graph使其可以作为预训练模型的有效提示multi-task-prompting-via-meta-learning">如何训练 Prompt Graph，使其可以作为预训练模型的有效提示：Multi-task Prompting via Meta Learning</h2>
<p>学习最好的Prompt，使得该Prompt可以帮助Pretrained Model更好的适应下游任务。</p>
<p><strong>Phase 1</strong> 有一些 Source Task去训练Prompt 的初始值。</p>
<p><strong>Phase 2</strong> 对Target Task做测试。</p>
<p>具体来说，首先对于要训练的prompt graph $\theta$ （即所有token的特征）让它在多个training task上训练，如下图所示，又3个节点分类的tasks，每个tasks里又自己的训练集（support set）和测试集（query set）。每个task都有一个共同的起点，在几个tasks上训练上训练后，每个tasks上有个优化后的task-specific prompt (Prompt 1, Prompt 2, Prompt 3)。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/5.png#center" alt="你想输入的替代文字"  />
</p>
<p>在更新了之后，评估组合起来的Prompt是否会让整体的性能更好，如下图所示，把所有task-specific prompt组合起来，来看组合后的prompt是不是足够好。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/6.png#center" alt="你想输入的替代文字"  />
</p>
<p>如果当前的Initial prompt训练出来的模型在三个tasks上不够好，那么换一个Initial Prompt，直到某个Initial Prompt在所有training tasks经过训练后都表现的较好时，就说明这是一个 <strong>较好的初始prompt (训练起点)</strong>，它适合做training tasks的初始化prompt。</p>
<p>在Meta Training 结束后，我们可以得到一个较好的prompt初始化值，即上图中的Adapt prompt initialization。</p>
<p>在Meta Testing阶段，将我们通过Training Tasks学到的最佳初始Prompt在Test tasks的support set上做微调，然后在Test Task的query set上验证prompt initialization的效果。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/7.png#center" alt="你想输入的替代文字"  />
</p>
<p>通过上面方式得到的prompt可以作为graph prompt与input graph 结合，使其具备link prediction和node classification的能力。</p>
<p><strong>可以看作时学习一个图增强，使得预训练的图模型在这个增强图上可以适用于更多任务。</strong></p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
