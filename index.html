<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.95.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script type=text/javascript async src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var t=MathJax.Hub.getAllJax(),e;for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><title>JhuoWâ€˜s Notes</title><meta name=keywords content="Blog,Portfolio,PaperMod"><meta name=description content="Jhuoâ€™s Notes"><meta name=author content="JhuoW"><link rel=canonical href=https://JhuoW.github.io/><meta name=google-site-verification content="G-6F49SGED6V"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><link rel=preload href=/apple-touch-icon.png as=image><link rel=icon href=https://JhuoW.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://JhuoW.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://JhuoW.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://JhuoW.github.io/apple-touch-icon.png><link rel=mask-icon href=https://JhuoW.github.io/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://JhuoW.github.io/index.xml><link rel=alternate type=application/json href=https://JhuoW.github.io/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-6F49SGED6V"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6F49SGED6V",{anonymize_ip:!1})}</script><meta property="og:title" content="JhuoWâ€˜s Notes"><meta property="og:description" content="Jhuoâ€™s Notes"><meta property="og:type" content="website"><meta property="og:url" content="https://JhuoW.github.io/"><meta property="og:image" content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="JhuoW"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="JhuoWâ€˜s Notes"><meta name=twitter:description content="Jhuoâ€™s Notes"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"JhuoWâ€˜s Notes","url":"https://JhuoW.github.io/","description":"Jhuoâ€™s Notes","thumbnailUrl":"https://JhuoW.github.io/favicon.ico","sameAs":["https://github.com/JhuoW","mailto:jhuow@proton.me","https://t.me/funjhuow","https://open.spotify.com/playlist/0HMI5oRLTSYuZPYie7B1bG?si=f2ec0a118a8a4297","https://gitlab.com/JhuoW","https://arxiv.gtflashlab.com/","https://JhuoW.github.io/index.xml","https://github.com/The-Run-Philosophy-Organization/run","https://aideadlin.es/?sub=ML,CV,CG,NLP,RO,SP,DM"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://JhuoW.github.io/ accesskey=h title="JhuoW's Notes (Alt + H)"><img src=https://JhuoW.github.io/apple-touch-icon.png alt=logo aria-label=logo height=35>JhuoW's Notes</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://JhuoW.github.io/about/ title=About><span>About</span></a></li><li><a href=https://JhuoW.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://JhuoW.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://JhuoW.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://JhuoW.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://JhuoW.github.io/gallery/ title=Gallery><span>Gallery</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>ğŸ’Ÿ Welcome to JhuoW&rsquo;s Notebook ğŸŒ»</h1></header><section class=entry-content><p><p>Hey, this is JhuoW. I use this blog to write notes about machine learning and AI conference papers.</p><ul><li>News:</li><li>[2023-05] One paper accepted by IEEE TNNLS</li><li>[2022-09] One paper accepted by NeurIPS 2022.</li><li>[2022-04] One paper accepted by IJCAI 2022.</li></ul></p></section><footer class=entry-footer><div class=social-icons><a href=https://github.com/JhuoW target=_blank rel="noopener noreferrer me" title=Github><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a href=mailto:jhuow@proton.me target=_blank rel="noopener noreferrer me" title=Email><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 21" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a><a href=https://t.me/funjhuow target=_blank rel="noopener noreferrer me" title=Telegram><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21.198 2.433a2.242 2.242.0 00-1.022.215l-8.609 3.33c-2.068.8-4.133 1.598-5.724 2.21a405.15 405.15.0 01-2.849 1.09c-.42.147-.99.332-1.473.901-.728.968.193 1.798.919 2.286 1.61.516 3.275 1.009 4.654 1.472.509 1.793.997 3.592 1.48 5.388.16.36.506.494.864.498l-.002.018s.281.028.555-.038a2.1 2.1.0 00.933-.517c.345-.324 1.28-1.244 1.811-1.764l3.999 2.952.032.018s.442.311 1.09.355c.324.022.75-.04 1.116-.308.37-.27.613-.702.728-1.196.342-1.492 2.61-12.285 2.997-14.072l-.01.042c.27-1.006.17-1.928-.455-2.474a1.654 1.654.0 00-1.034-.407z"/></svg></a><a href="https://open.spotify.com/playlist/0HMI5oRLTSYuZPYie7B1bG?si=f2ec0a118a8a4297" target=_blank rel="noopener noreferrer me" title=Spotify><svg fill="currentcolor" stoke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 0C5.4.0.0 5.4.0 12s5.4 12 12 12 12-5.4 12-12S18.66.0 12 0zm5.521 17.34c-.24.359-.66.48-1.021.24-2.82-1.74-6.36-2.101-10.561-1.141-.418.122-.779-.179-.899-.539-.12-.421.18-.78.54-.9 4.56-1.021 8.52-.6 11.64 1.32.42.18.479.659.301 1.02zm1.44-3.3c-.301.42-.841.6-1.262.3-3.239-1.98-8.159-2.58-11.939-1.38-.479.12-1.02-.12-1.14-.6s.12-1.021.6-1.141C9.6 9.9 15 10.561 18.72 12.84c.361.181.54.78.241 1.2zm.12-3.36C15.24 8.4 8.82 8.16 5.16 9.301c-.6.179-1.2-.181-1.38-.721-.18-.601.18-1.2.72-1.381 4.26-1.26 11.28-1.02 15.721 1.621.539.3.719 1.02.419 1.56-.299.421-1.02.599-1.559.3z"/></svg></a><a href=https://gitlab.com/JhuoW target=_blank rel="noopener noreferrer me" title=Gitlab><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M22.65 14.39 12 22.13 1.35 14.39a.84.84.0 01-.3-.94l1.22-3.78 2.44-7.51A.42.42.0 014.82 2a.43.43.0 01.58.0.42.42.0 01.11.18l2.44 7.49h8.1l2.44-7.51A.42.42.0 0118.6 2a.43.43.0 01.58.0.42.42.0 01.11.18l2.44 7.51L23 13.45a.84.84.0 01-.35.94z"/></svg></a><a href=https://arxiv.gtflashlab.com/ target=_blank rel="noopener noreferrer me" title=Arxiv><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4v16a2 2 0 002 2h12a2 2 0 002-2V8.342a2 2 0 00-.602-1.43l-4.44-4.342A2 2 0 0013.56 2H6A2 2 0 004 4z"/><path d="M9 13h6"/><path d="M9 17h3"/><path d="M14 2v4a2 2 0 002 2h4"/></svg></a><a href=https://JhuoW.github.io/index.xml target=_blank rel="noopener noreferrer me" title=Rss><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a><a href=https://github.com/The-Run-Philosophy-Organization/run target=_blank rel="noopener noreferrer me" title=External-Link><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-external-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M11 7H6A2 2 0 004 9v9a2 2 0 002 2h9a2 2 0 002-2v-5"/><line x1="10" y1="14" x2="20" y2="4"/><polyline points="15 4 20 4 20 9"/></svg></a><a href="https://aideadlin.es/?sub=ML,CV,CG,NLP,RO,SP,DM" target=_blank rel="noopener noreferrer me" title=Other><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></a></div></footer></article><article class=post-entry><header class=entry-header><h2>Fraud Detection based on Graph Neural Networks</h2></header><section class=entry-content><p>1. Label Information Enhanced Fraud Detection against Low Homophily in Graphs (WWW â€˜23) Introduction GNN4FDå­˜åœ¨é—®é¢˜ï¼š å¤§å¤šæ•°åŸºäºGNNçš„æ¬ºè¯ˆæ£€æµ‹å™¨éš¾ä»¥æ³›åŒ–åˆ°low homophilyç½‘ç»œä¸­ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œå¦‚ä½•å……åˆ†åˆ©ç”¨labelä¿¡æ¯ä¹Ÿæ˜¯Fraud detectionçš„é‡è¦å› ç´ ã€‚å³å¦‚æœä¸€ä¸ªFraud nodeçš„é‚»å±…éƒ½æ˜¯benign nodesï¼Œé‚£ä¹ˆè¿™æ ·çš„å›¾å°±æ˜¯heterophily or low homophily graphï¼Œç”±äºGNNçš„neighborhood aggregationæœºåˆ¶ï¼Œtarget nodeçš„è¡¨ç¤ºä¼šå’Œå®ƒçš„é‚»å±…ç›¸ä¼¼ï¼Œæ— è®ºä»–ä»¬çš„labelæ˜¯å¦ä¸åŒï¼Œè¿™æ ·ä¼šä½¿å¾—GNNéš¾ä»¥åŒºåˆ†ä½äºå¼‚è´¨é‚»åŸŸå†…çš„Fraud nodesã€‚å¦å¤–ï¼Œ ç°æœ‰çš„GNN4FDæ–¹æ³•åˆ©ç”¨labelä¿¡æ¯çš„èƒ½åŠ›æœ‰é™ï¼Œè¿™äº›æ–¹æ³•ä»…åœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨labelä¿¡æ¯ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œä½†æ˜¯åœ¨è®¾è®¡message passing æœºåˆ¶çš„è¿‡ç¨‹ä¸­å¹¶æ²¡æœ‰ä½¿ç”¨labelä¿¡æ¯ã€‚
ä¸ºäº†è§£å†³ä¸Šè¿°2ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºGAGA: åŸºäºåˆ†ç»„èšåˆçš„Transformerã€‚ GAGAé¦–å…ˆæå‡ºäº†ä¸€ç§é¢„å¤„ç†ç­–ç•¥Group Aggregation (GA, åˆ†ç»„èšåˆ)ï¼Œç„¶åæ¯ä¸ªèŠ‚ç‚¹çš„åŸå§‹é‚»å±…ç‰¹ç‰¹å¾è¢«åˆ†ç»„ä¸ºåºåˆ—æ•°æ®ã€‚ ç„¶åæå‡ºä¸€ç§ç§‘å­¦ç³»çš„ç¼–ç æ–¹å¼æ¥ç¼–ç structuralï¼Œrelational å’Œlabelä¿¡æ¯ ï¼ˆå…¨å±€ï¼‰ï¼Œå³æ•´ä¸ªå›¾çš„relational encodingï¼Œgroup encoding å’Œ hop encoding ï¼ˆå›¾ä¸­åˆå‡ ä¸ªrelationå°±æœ‰å‡ ä¸ªrelational embeddingï¼Œå–å‡ ä¸ªhopå°±åˆå‡ ä¸ªhop embedding..ï¼‰ã€‚ æœ€åç”¨å¤šå¤´attentionä¸ºæ¯ä¸ªèŠ‚ç‚¹èšåˆembedding sequence.
Preliminaries Multi-relational fraud graph construction Multi-relational fraud graph $\mathcal{G}(\mathcal{V}, \mathcal{E}, \mathcal{X}, \mathcal{Y})$, å…¶ä¸­èŠ‚ç‚¹é›†$\mathcal{V}=\left\{v_1, v_2, \ldots, v_N\right\}(N=|\mathcal{V}|)$ï¼Œ$R$ ä¸ªé‚»æ¥çŸ©é˜µ$\mathcal{E}=\left\{\mathbf{A}_1, \mathbf{A}_2, \ldots, \mathbf{A}_R\right\}(R=|\mathcal{E}|)$çš„å¤šå…³ç³»å›¾ ï¼ˆ$R$ä¸ªå…³ç³»ï¼‰ã€‚èŠ‚ç‚¹feature vectors $X=\left\{\mathbf{x}_1, \mathrm{x}_2, \ldots, \mathrm{x}_N\right\}$ä»¥åŠèŠ‚ç‚¹çš„labelé›†åˆ$\mathcal{Y}$ã€‚ å¯¹äºä¸€ä¸ªrelationçš„é‚»æ¥çŸ©é˜µ$\mathbf{A}_r$ï¼Œå¦‚æœ$\mathbf{A}_1[u,v]=1$ï¼Œé‚£ä¹ˆåœ¨å…³ç³»$r$ä¸‹èŠ‚ç‚¹$u$å’Œ$v$è¢«è¿æ¥ã€‚æ¯ä¸ªèŠ‚ç‚¹$v \in \mathcal{V}$ æœ‰ä¸€ä¸ª$d$ç»´feature vector $\mathbf{x}_v \in \mathbb{R}^d$ã€‚ åœ¨åŸºäºGraphçš„fraud detectionä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘åŠç›‘ç£åœºæ™¯ï¼Œå…¶ä¸­ä¸€å°éƒ¨åˆ†èŠ‚ç‚¹ $\hat{\mathcal{V}} \supset \mathcal{V}$æ˜¯æœ‰labelçš„ ï¼ˆ$y=1$è¡¨ç¤ºè¯¥èŠ‚ç‚¹ä¸ºfraud nodeï¼Œ$y=0$è¡¨ç¤ºè¯¥èŠ‚ç‚¹ä¸ºbenign nodeï¼‰æ‰€ä»¥å¯¹äºfraud graphï¼ŒèŠ‚ç‚¹classæ•°ä¸º2ã€‚...</p></section><footer class=entry-footer><span title="2023-05-13 16:14:56 +0800 CST">May 13, 2023</span>&nbsp;Â·&nbsp;6 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to Fraud Detection based on Graph Neural Networks" href=https://JhuoW.github.io/posts/fd/></a></article><article class=post-entry><header class=entry-header><h2>ICML2022 ã€ŠLocal Augmentation for Graph Neural Networksã€‹ Reading Notes</h2></header><section class=entry-content><p>paper
Introduction åœ¨GNNçš„neighborhood aggregationä¸­ï¼Œå¯¹äºæ‹¥æœ‰å¾ˆå°‘é‚»å±…çš„èŠ‚ç‚¹ï¼Œåœ¨èšåˆè¿‡ç¨‹ä¸­æ˜¯å¦å……åˆ†ä»é‚»å±…ä¸­è·å¾—äº†ä¿¡æ¯æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚ä¸ºè§£å†³è¯¥é—®é¢˜ï¼Œ æœ¬æ–‡æå‡ºä¸ºæ¯ä¸ªèŠ‚ç‚¹åšå±€éƒ¨å¢å¼ºï¼Œå³ä»¥ä¸­å¿ƒèŠ‚ç‚¹ä¸ºæ¡ä»¶ï¼Œå­¦ä¹ é‚»å±…èŠ‚ç‚¹è¡¨ç¤ºçš„åˆ†å¸ƒã€‚ä¸ºäº†åœ¨å±€éƒ¨é‚»åŸŸä¸­ç”Ÿæˆä¸€äº›æ ·æœ¬æ¥æå‡ä¸­å¿ƒèŠ‚ç‚¹çš„neighborhood aggregationï¼Œæœ¬æ–‡æå‡ºä¸€ç§æ•°æ®å¢å¼ºæ¡†æ¶ï¼šLA-GNNsï¼Œ ä»¥å±€éƒ¨ç»“æ„å’Œä¸­å¿ƒèŠ‚ç‚¹ç‰¹å¾ä¸ºæ¡ä»¶ï¼Œç”Ÿæˆneighborhood featuresã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨pre-training é˜¶æ®µï¼Œé€šè¿‡ä¸€ä¸ªç”Ÿæˆæ¨¡å‹ï¼Œä»¥ä¸­å¿ƒèŠ‚ç‚¹çš„ç‰¹å¾ä¸ºæ¡ä»¶æ¥å­¦ä¹ é‚»å±…ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚ç„¶ååˆ©ç”¨è¿™ä¸ªé‚»å±…ç‰¹å¾åˆ†å¸ƒæ¥ç”Ÿæˆä¸­å¿ƒèŠ‚ç‚¹çš„å¢å¼ºé‚»å±…ç‰¹å¾ã€‚å¦å¤–ï¼Œé€šè¿‡pre-trainingæ¥å­¦ä¹ é‚»å±…å¢å¼ºç‰¹å¾ç”Ÿæˆå™¨çš„è¿‡ç¨‹æ˜¯ä¸ä¸‹æ¸¸ä»»åŠ¡æ— å…³çš„ï¼Œæ‰€ä»¥è¯¥ç”Ÿæˆå™¨ç”Ÿæˆçš„å¢å¼ºç‰¹å¾å¯ä»¥åº”ç”¨äºå…¶ä»–GNNæ¨¡å‹ã€‚
Local Augmentation for Graph Neural Networks (LAGNN) Motivation GNNåœ¨message passingçš„è¿‡ç¨‹åˆ©ç”¨å±€éƒ¨ä¿¡æ¯èšåˆæ¥å¾—åˆ°node representationsã€‚ ä½†æ˜¯å¯¹äºé‚»å±…æ•°é‡è¾ƒå°‘çš„èŠ‚ç‚¹ï¼Œä»é‚»å±…ä¸­å¾—åˆ°çš„ä¿¡æ¯å¯èƒ½ä¼šä¸è¶³ã€‚ä¸ºäº†ä¸ºèŠ‚ç‚¹$v$çš„é‚»åŸŸä¸­$\mathcal{N}_v$ç”Ÿæˆæ›´å¤šæ ·æœ¬ï¼Œå°±éœ€è¦çŸ¥é“é‚»å±…è¡¨ç¤ºçš„åˆ†å¸ƒã€‚ ç”±äºä¸€ä¸ªèŠ‚ç‚¹é‚»å±…åˆ†å¸ƒæ˜¯ä¸ä¸­å¿ƒèŠ‚ç‚¹ç›¸å…³ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ä»¥ä¸­å¿ƒèŠ‚ç‚¹$v$çš„representationä¸ºæ¡ä»¶ï¼Œå­¦ä¹ å®ƒçš„é‚»å±…è¡¨ç¤ºåˆ†å¸ƒã€‚
Approach æœ¬æ–‡åˆ©ç”¨Conditional Variational Auto-Encoder (CVAE) æ¥å­¦ä¹ ç»™å®šä¸­å¿ƒèŠ‚ç‚¹$v$ï¼Œé‚»å±…$u \in \mathcal{N}_v$çš„èŠ‚ç‚¹ç‰¹å¾çš„æ¡ä»¶åˆ†å¸ƒã€‚ç»™å®šä¸­å¿ƒèŠ‚ç‚¹ç‰¹å¾$\boldsymbol{X}_v$ï¼Œå…³äºä¸­å¿ƒèŠ‚ç‚¹çš„é‚»å±…åˆ†å¸ƒä¸º$p_\theta(\boldsymbol{X}_u | \boldsymbol{X}_v)$ã€‚å®šä¹‰éšå˜é‡$\mathbf{z}$ï¼Œåˆ™å…ˆéªŒå¯ä»¥å®šä¹‰ä¸º$p_\theta(\mathbf{z}|\boldsymbol{X}_v)$ã€‚ç»“åˆéšå˜é‡$\mathbf{z}$ï¼Œé‚»å±…ç‰¹å¾$\boldsymbol{X}_u$çš„åˆ†å¸ƒå¯ä»¥æ”¹å†™ä¸ºå¦‚ä¸‹å½¢å¼ï¼š $$ \begin{aligned} \log p_\theta(\boldsymbol{X}_u | \boldsymbol{X}_v) &= \log \frac{p_\theta(\boldsymbol{X}_u , \boldsymbol{X}_v)}{p_\theta( \boldsymbol{X}_v)}= \frac{p_\theta(\boldsymbol{X}_u , \boldsymbol{X}_v)p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)}{p_\theta( \boldsymbol{X}_v)p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)} \\ &=\log \frac{p_\theta(\boldsymbol{X}_u , \boldsymbol{X}_v, \mathbf{z})}{p_\theta( \boldsymbol{X}_v)p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)} \\ &= \log \frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)}\\ \end{aligned} $$ å‡è®¾éšå˜é‡$\mathbf{z}$çš„åˆ†å¸ƒä¸º$q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)$ï¼Œ å·¦å³ä¸¤è¾¹å¯¹åˆ†å¸ƒ$q_\phi$è®¡ç®—æœŸæœ›ï¼Œå·¦è¾¹ï¼š $$ \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log p_\theta(\boldsymbol{X}_u | \boldsymbol{X}_v) dz = \log p_\theta(\boldsymbol{X}_u | \boldsymbol{X}_v) $$ å³è¾¹ï¼š $$ \begin{aligned} &\int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)} dz \\ =& \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \left(\frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} \cdot \frac{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)}{p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)}\right) dz \\ =& \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} dz + \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \frac{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)}{p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)}dz \\ =& \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} dz + K L\left(q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) || p_\theta\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)\right) \\ \geq& \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u, \mathbf{z} \mid \boldsymbol{X}_v\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} = ELBO \end{aligned} $$ Evidence Lower Bound (ELBO) å¯ä»¥å†™ä¸º $$ \begin{aligned} L_{ELBO} &= \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u, \mathbf{z} \mid \boldsymbol{X}_v\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} \\ &= \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u, \boldsymbol{X}_v, \mathbf{z}\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) p_\theta\left(\boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} \\ &= \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u \mid \boldsymbol{X}_v, \mathbf{z}\right) p_\theta\left(\boldsymbol{X}_v, \mathbf{z}\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) p_\theta\left(\boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} \\ &= \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u \mid \boldsymbol{X}_v, \mathbf{z}\right) p_\theta\left(\mathbf{z} \mid \boldsymbol{X}_v\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} \\ &= -K L\left(q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) || p_\theta\left(\mathbf{z} \mid \boldsymbol{X}_v\right)\right)+\int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log p_\theta\left(\boldsymbol{X}_u \mid \boldsymbol{X}_v, \mathbf{z}\right) \mathrm{d} \mathbf{z} \\ &= -K L\left(\underbrace{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)}_{Encoder} || \underbrace{ p_\theta\left(\mathbf{z} \mid \boldsymbol{X}_v\right)}_{\text{Normal Distribution}}\right) + \mathbb{E}_{\mathbf{z} \sim q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) }\log p_\theta\left(\boldsymbol{X}_u \mid \boldsymbol{X}_v, \mathbf{z}\right) \end{aligned} $$ åœ¨CVAE pre-trainingçš„è¿‡ç¨‹ä¸­ï¼Œç¬¬ä¸€é¡¹KLä¸­CVAE Encoder çš„ä¸€å¯¹é‚»æ¥èŠ‚ç‚¹å¯¹ï¼Œå¯¹äºè¯¥èŠ‚ç‚¹å¯¹ï¼Œè¾“å‡ºä¸€ç»„åˆ†å¸ƒå‚æ•°å‡å€¼$\mu$å’Œæ–¹å·®$\sigma$ï¼Œä½œä¸ºéšå˜é‡$z$çš„åˆ†å¸ƒå‚æ•°ï¼Œç¬¬ä¸€é¡¹çš„ä¼˜åŒ–ç›®æ ‡ä½¿å¾—ç¼–ç å™¨è¾“å‡ºçš„åˆ†å¸ƒæ¥è¿‘Normal Distributionã€‚ç„¶ååˆ©ç”¨reparameterization trickå¯å¾®çš„ä»ç”Ÿæˆçš„$\mathbf{z}$åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªencoding:...</p></section><footer class=entry-footer><span title="2023-01-25 21:19:40 +0800 CST">January 25, 2023</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICML2022 ã€ŠLocal Augmentation for Graph Neural Networksã€‹ Reading Notes" href=https://JhuoW.github.io/posts/lagcn/></a></article><article class=post-entry><header class=entry-header><h2>ICML2022 ã€ŠProGCLï¼šRethinking Hard Negative Mining in Graph Contrastive Learningã€‹ Reading Note</h2></header><section class=entry-content><p>paper
Introduction Contrastive Learning å—ç›ŠäºåŒºåˆ†hard negatives (æœ€ç›¸ä¼¼çš„negative pairs)ï¼Œ ä½†æ˜¯å…¶ä»–é¢†åŸŸçš„hard negative miningæ–¹æ³•ä¸é€‚ç”¨äºgraphã€‚ å¯¹äºGCLæ¥è¯´å¤§é‡embeddingä¹‹åçš„hard negativeså®é™…ä¸Šæ˜¯false negativesã€‚å¦‚å·¦å›¾æ‰€ç¤ºï¼Œå¯¹äºCVä¸Šçš„SimCLRï¼Œå®ƒæ‰€å­¦åˆ°çš„é«˜ç›¸ä¼¼åº¦çš„negativesä¸­ï¼ŒTrue negatives å’ŒFalse negativesæ•°é‡ç›¸å½“ï¼Œé‚£ä¹ˆä»é«˜ç›¸ä¼¼åº¦çš„negativesä¸­é‡‡æ ·åˆ°true negativesçš„æ¦‚ç‡æ›´å¤§ã€‚ç„¶è€Œå¯¹äºGCLæ–¹æ³•GCAæ¥è¯´ï¼Œæ˜¯æ¯ä¸ªanchorèŠ‚ç‚¹å°†å…¶ä»–æ‰€æœ‰ï¼ˆinter/intraï¼‰èŠ‚ç‚¹ä½œä¸ºnegativesï¼Œä½¿å¾—åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸å®ƒåŒç±»çš„èŠ‚ç‚¹ä¹Ÿå˜æˆanchorçš„negativesï¼Œè¿™äº›negativesæ˜¯false negativesã€‚å¯¹äºGCAï¼Œé«˜ç›¸ä¼¼åº¦çš„negativesä¸­false negativesçš„æ•°é‡è¿œå¤šäºtrue negativesï¼Œæ‰€ä»¥ç›´æ¥é‡‡æ ·é«˜ç›¸ä¼¼åº¦çš„negativesä½œä¸ºhard negativesæ¥é’ˆå¯¹æ€§çš„åˆ¤åˆ«ä»–ä»¬ï¼Œä¼šå¯¼è‡´åŒç±»èŠ‚ç‚¹çš„embeddingç›¸äº’è¿œç¦»ã€‚è¿™æ˜¯ä¼ ç»Ÿçš„hard negatives miningæ–¹æ³•åœ¨graph domainå¤±æ•ˆçš„åŸå› ã€‚
ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œ æœ¬æ–‡æå‡ºåˆ©ç”¨Beta mixture modelæ¥ä¼°è®¡å¯¹äºä¸€ä¸ªanchor nodeï¼Œå®ƒçš„ä¸€ä¸ªnegatveæ˜¯true negativeçš„æ¦‚ç‡ï¼Œç»“åˆç›¸ä¼¼åº¦ï¼Œæ¥è¡¡é‡è¯¥negativeçš„hardnessã€‚å³ä¸anchor nodeç›¸ä¼¼åº¦è¶Šé«˜ï¼Œä¸”å®ƒæ˜¯true negativeçš„æ¦‚ç‡è¶Šå¤§ï¼Œé‚£ä¹ˆè¯¥èŠ‚ç‚¹çš„hardnessè¶Šé«˜ã€‚
Methodology GCL å¦‚ä¸Šå›¾æ‰€ç¤ºï¼ŒInfoNCEå°†è·¨å›¾same nodeè§†ä¸ºpositivesï¼Œå…¶ä»–èŠ‚ç‚¹å¯¹è§†ä¸ºnegativesï¼ŒGCLçš„ç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š $$ \begin{aligned} \ell\left(\boldsymbol{u}_{i},\boldsymbol{v}_{i}\right)= \log \frac{e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{i}\right) / \tau}}{\underbrace{e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{i}\right) / \tau}}_{\text{positive pair }}+\underbrace{\sum_{k\neq i}e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{k}\right) / \tau}}_{\text{inter-view negative pairs}}+\underbrace{\sum_{k\neq i}e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{u}_{k}\right) / \tau}}_{\text{intra-view negative pairs}}}, \end{aligned} $$ Overall objectiveå®šä¹‰åœ¨æ‰€æœ‰è·¨å›¾same node pairsä¸Šï¼š $$ \mathcal{J}=-\frac{1}{2 N} \sum_{i=1}^N\left[\ell\left(\boldsymbol{u}_{\boldsymbol{i}}, \boldsymbol{v}_{\boldsymbol{i}}\right)+\ell\left(\boldsymbol{v}_{\boldsymbol{i}}, \boldsymbol{u}_{\boldsymbol{i}}\right)\right] $$ å¦‚æœå°†GCAä¸­çš„2å±‚shared GNNæ›¿æ¢ä¸ºMLPï¼Œé‚£ä¹ˆcontrastive learningå°†ä¸å­˜åœ¨Message Passingï¼Œè¿™æ ·å¾—åˆ°çš„true/false negativeåˆ†å¸ƒå¦‚(b)æ‰€ç¤ºï¼Œå¯ä»¥çœ‹å‡ºMessage Passingæ˜¯GCLå’ŒCLä¹‹é—´äº§ç”ŸåŒºåˆ«å…³é”®å› ç´ ã€‚ç›´è§‚ä¸Šï¼ŒMPå°†anchorä¸ç›¸é‚»çš„negativesæ‹‰è¿‘ï¼Œè€Œç›¸é‚»çš„negativeså¤§å¤šä¸ºFalse negativesï¼ˆHomophilyï¼‰ï¼Œæ‰€ä»¥GCLå¾—åˆ°çš„é«˜ç›¸ä¼¼åº¦negativesä¸­false negativesè¦è¿œå¤šäºTrue negativesã€‚...</p></section><footer class=entry-footer><span title="2023-01-08 22:28:43 +0800 CST">January 8, 2023</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICML2022 ã€ŠProGCLï¼šRethinking Hard Negative Mining in Graph Contrastive Learningã€‹ Reading Note" href=https://JhuoW.github.io/posts/progcl/></a></article><article class=post-entry><header class=entry-header><h2>WWW2022 ã€ŠClusterSCLï¼šCluster-Aware Supervised Contrastive Learning on Graphsã€‹ Reading Notes</h2></header><section class=entry-content><p>paper
Introduction å¯¹äºç›‘ç£å¯¹æ¯”å­¦ä¹ ï¼ˆSupervised Contrastive Learning, SupConï¼‰, SupCon lossæ—¨åœ¨è¡¨ç¤ºç©ºé—´ä¸­æ‹‰è¿‘å±äºåŒä¸€ä¸ªclassçš„æ•°æ®ç‚¹ï¼Œåˆ†ç¦»ä¸åŒç±»çš„æ•°æ®ç‚¹ã€‚ ä½†æ˜¯SupConéš¾ä»¥å¤„ç†é«˜ç±»å†…æ–¹å·®ï¼Œç±»é—´ç›¸ä¼¼åº¦è¾ƒå¤§çš„æ•°æ®é›†ã€‚ä¸ºäº†è§£å†³è¯¥é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Cluster-aware supervised contrastive learning loss (ClusterSCL)ã€‚ä»€ä¹ˆæ˜¯é«˜ç±»å†…æ–¹å·®ï¼Œé«˜è·¨ç±»ç›¸ä¼¼åº¦é—®é¢˜ï¼Ÿå¦‚å›¾1(a)æ‰€ç¤ºï¼ŒèŠ‚ç‚¹$u_1$å’Œ$u_3$ æ˜¯åŒç±»èŠ‚ç‚¹ï¼Œ$u_2$å’Œ$u_4$æ˜¯åŒç±»èŠ‚ç‚¹ã€‚ä»–ä»¬æ˜¯åŒç±»èŠ‚ç‚¹ä½†åœ¨ä¸åŒçš„ç¤¾åŒºä¸­ï¼Œæ‰€ä»¥ç±»å†…æ–¹å·®è¾ƒå¤§ï¼Œå³åŒä¸€ä¸ªç±»å†…çš„èŠ‚ç‚¹è·¨è¶Šäº†å¤šä¸ªcommunityã€‚ å¦å¤–$u_1$å’Œ$u_2$ï¼Œ $u_3$å’Œ$u_4$ï¼Œæ˜¯ä¸åŒç±»çš„èŠ‚ç‚¹å¯¹ï¼Œ ä½†ä»–ä»¬å¤„åœ¨åŒä¸€ä¸ªç¤¾åŒºä¸­ï¼Œå¯¼è‡´åœ¨MPNNè¿‡ç¨‹ä¸­ï¼Œè¿™äº›å¤„åœ¨åŒä¸€ä¸ªcommunityä¸­çš„ä¸åŒç±»èŠ‚ç‚¹è¢«æ‹‰è¿‘ï¼Œå¯¼è‡´è·¨ç±»ç›¸ä¼¼åº¦è¾ƒé«˜çš„é—®é¢˜ã€‚
å¦‚æœå¯¹èŠ‚ç‚¹$u_2$è®¡ç®—SupConæ—¶ï¼Œå¦‚å›¾1(b)æ‰€ç¤ºï¼ŒSupConä¼šä½¿å¾—åŒç±»èŠ‚ç‚¹è¢«æ‹‰è¿‘ï¼Œå¦‚$u_2$å’Œ$u_4$ä¼šè¢«æ‹‰è¿‘ã€‚ä½†æ˜¯$u_3$å’Œ$u_4$å¤„åœ¨åŒä¸€ä¸ªç¤¾åŒºä¸­ï¼ˆstructurally similarï¼‰é‚£ä¹ˆMPNNä¼šä½¿å¾—$u_3$å’Œ$u_4$è¢«æ‹‰è¿‘ï¼Œæ‰€ä»¥SupConåœ¨æ‹‰è¿‘$u_2$å’Œ$u_4$çš„åŒæ—¶ï¼Œä¼šé—´æ¥æ‹‰è¿‘ä¸åŒç±»èŠ‚ç‚¹$u_2$å’Œ$u_3$ã€‚åŒæ—¶ï¼Œå¯¹äºæ„æˆnegative pairsçš„ä¸åŒç±»èŠ‚ç‚¹ï¼Œä¾‹å¦‚$u_1$å’Œ$u_2$ï¼ŒSupConä¼šæ¨è¿œ$u_1$å’Œ$u_2$ï¼Œä½†æ˜¯$u_1$å’Œ$u_5$ structurally similar, å› æ­¤ä¼šæ¨è¿œ$u_1$å’Œ$u_2$ä¼šé—´æ¥å¯¼è‡´$u_2$å’Œ$u_5$è¿™ä¸¤ä¸ªåŒç±»èŠ‚ç‚¹è¢«æ¨è¿œã€‚å› æ­¤å¯¹äºä¸€ä¸ªclusterå†…èŠ‚ç‚¹ä¸åŒç±»ï¼Œä¸”ä¸åŒclusterä¸­å­˜åœ¨åŒç±»èŠ‚ç‚¹çš„æƒ…å†µï¼Œä¼šå¯¼è‡´å¤æ‚çš„å†³ç­–è¾¹ç•Œï¼Œå³åœ¨æ‹‰è¿‘åŒç±»ä½†ä¸åŒç¤¾åŒºçš„èŠ‚ç‚¹æ—¶ï¼Œä¹Ÿä¼šé—´æ¥æ‹‰è¿‘ä¸åŒç±»ä¸åŒç¤¾åŒºçš„èŠ‚ç‚¹ã€‚åœ¨æ¨è¿œä¸åŒç±»åŒç¤¾åŒºçš„èŠ‚ç‚¹æ—¶ï¼Œä¹Ÿå¯èƒ½é—´æ¥æ¨è¿œåŒç±»åŒç¤¾åŒºçš„èŠ‚ç‚¹ã€‚
ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ€ç›´æ¥çš„æ–¹æ³•æ˜¯å¯¹äºæ¯ä¸ªclusterï¼Œå¦‚å›¾1(a)çš„Community 1ï¼Œä¸è€ƒè™‘å…¶ä»–clusterï¼Œåªå¯¹å½“å‰clusterå†…èŠ‚ç‚¹åšSupConã€‚ä½†æ˜¯è¿™ä¹ˆåšå¿½ç•¥äº†è·¨clusterçš„åŒç±»èŠ‚ç‚¹äº¤äº’ï¼Œå¦‚$u_1$å’Œ$u_3$ï¼Œ$u_2$å’Œ$u_4$ï¼Œè¿™äº›è·¨clusterçš„positive pairså¯èƒ½åŒ…å«æœ‰ç›Šçš„ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºcluster-aware data augmentation (CDA) èšç±»æ„ŸçŸ¥çš„æ•°æ®å¢å¼ºï¼Œæ¥ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆaugmented positives and negativesï¼Œå¦‚å›¾1(b)ä¸­ClusterSCLæ‰€ç¤ºã€‚å¯¹äºæ¯ä¸ªèŠ‚ç‚¹$u$ï¼Œä¸ºå®ƒç”Ÿæˆpositive å’Œnegative samples, ç”Ÿæˆçš„samples ä½äºæˆ–æ¥è¿‘$u$æ‰€åœ¨çš„clusterã€‚Recall SupConå­˜åœ¨çš„é—®é¢˜ï¼š
SupConä¼šä½¿å¾—$u_2$å’Œ$u_4$è¢«æ‹‰çš„å¤ªè¿‘ï¼Œä»è€Œé—´æ¥å¯¼è‡´$u_2$å’Œ$u_3$è¢«æ‹‰è¿‘ï¼Œæ‰€ä»¥å¯¹äºhigh intra-class variancesï¼Œè¦æ±‚ä¸åŒclusterçš„åŒç±»èŠ‚ç‚¹å¦‚$u_2$å’Œ$u_4$ä¸è¦è¢«æ‹‰å¤ªè¿‘ï¼› SupConä¼šä½¿å¾—$u_1$å’Œ$u_2$è¢«æ¨è¿œï¼Œä»è€Œé—´æ¥å¯¼è‡´$u_2$å’Œ$u_5$è¢«æ¨è¿œï¼Œæ‰€ä»¥å¯¹äºhigh inter-class similarityï¼Œè¦æ±‚åŒä¸€ä¸ªclusterå†…çš„ä¸åŒç±»èŠ‚ç‚¹å¦‚$u_1$å’Œ$u_2$ä¸è¦è¢«æ‹‰çš„å¤ªè¿œã€‚ Method Two stage training with Supervised Contrastive Loss SupCon encourages samples of the same class to have similar representations, while pushes apart samples of different classes in the embedding space....</p></section><footer class=entry-footer><span title="2022-11-17 01:33:20 +0800 CST">November 17, 2022</span>&nbsp;Â·&nbsp;4 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to WWW2022 ã€ŠClusterSCLï¼šCluster-Aware Supervised Contrastive Learning on Graphsã€‹ Reading Notes" href=https://JhuoW.github.io/posts/clusterscl/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2022 ã€ŠGraph Condensation for Graph Neural Networksã€‹ Reading Notes</h2></header><section class=entry-content><p>paper
Introduction æœ¬æ–‡æå‡ºå›¾æµ“ç¼©æŠ€æœ¯ï¼ˆGraph Condensationï¼‰ï¼Œæ—¨åœ¨å°†å¤§å›¾æµ“ç¼©ä¸ºä¸€ä¸ªå°å›¾ï¼Œä½¿å¾—åœ¨å°å›¾ä¸Šè®­ç»ƒçš„GNNå¯ä»¥å¾—åˆ°å’Œå¤§å›¾ç›¸å½“çš„æ•ˆæœã€‚é€šè¿‡ä¼˜åŒ–gradient matching lossæ¥æ¨¡æ‹ŸGNNåœ¨åŸå›¾ä¸Šçš„è®­ç»ƒè½¨è¿¹ï¼Œä»è€Œè§£å†³å›¾æµ“ç¼©é—®é¢˜ã€‚
é€šå¸¸æœ‰ä¸¤ä¸ªç­–ç•¥æ¥ç®€åŒ–å›¾ï¼šGraph Sparsification(å›¾ç¨€ç–åŒ–)å’ŒGraph Coarsening(å›¾ç²—åŒ–)ã€‚å›¾ç¨€ç–åŒ–é€šè¿‡å‡å°‘è¾¹æ•°æ¥è¿‘ä¼¼ä¸€ä¸ªå›¾ï¼› å›¾ç²—åŒ–æ—¨åœ¨å‡å°‘èŠ‚ç‚¹æ•°é‡ã€‚ï¼ˆ1ï¼‰å½“èŠ‚ç‚¹å…·æœ‰å±æ€§ç‰¹å¾æ—¶ï¼Œç”±äºç¨€ç–åŒ–ä¸ä¼šå‡å°‘èŠ‚ç‚¹æ•°é‡ï¼Œå› æ­¤å±æ€§é‡ä¸ä¼šå‡å°‘ã€‚ ï¼ˆ2ï¼‰å›¾ç²—åŒ–çš„ç›®çš„æ˜¯ä¿å­˜ä¸€äº›å›¾å±æ€§æ¯”å¦‚ä¸»ç‰¹å¾å€¼ï¼Œè¿™å¯èƒ½å¯¹ä¸‹æ¸¸ä»»åŠ¡ä¸æ˜¯æœ€ä¼˜çš„ä¿å­˜å±æ€§ã€‚
æœ¬æ–‡æå‡ºå›¾æµ“ç¼©ï¼Œæ¥å­¦ä¹ ç”Ÿæˆå›¾çš„ç»“æ„å’ŒèŠ‚ç‚¹å±æ€§ï¼Œä»è¿™ä¸¤æ–¹é¢åŒæ—¶è¿›è¡Œæµ“ç¼©ã€‚å¯¹äºRedditæ•°æ®é›†ï¼ŒGCondå¯ä»¥å°†èŠ‚ç‚¹æ•°æµ“ç¼©è‡³0.1%ï¼Œå¹¶ä¸”åœ¨æµ“ç¼©å›¾ä¸Šå¯ä»¥å¾—åˆ°å’ŒåŸå›¾ç›¸å½“çš„æ•ˆæœã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
æœ¬æ–‡è§£å†³äº†å›¾æµ“ç¼©é¢ä¸´çš„ä¸¤ä¸ªæŒ‘æˆ˜ï¼š1. æ„å»ºç›®æ ‡å‡½æ•°ï¼Œ 2. å‚æ•°åŒ–å¯å­¦ä¹ çš„èŠ‚ç‚¹ç‰¹å¾å’Œå›¾ç»“æ„ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°æŒ‘æˆ˜ï¼Œæœ¬æ–‡ä½¿ç”¨gradient matching lossæ¥åŒ¹é…æ¯ä¸€ä¸ªtraining stepä¸ŠåŸå›¾ä¸æµ“ç¼©å›¾çš„GNNå‚æ•°æ¢¯åº¦ï¼Œä½¿å¾—GNNåœ¨æµ“ç¼©å›¾ä¸Šçš„è®­ç»ƒè¶‹åŠ¿ä¸åŸå›¾ç›¸åŒ¹é…ã€‚ä¸ºäº†å‚æ•°åŒ–èŠ‚ç‚¹ç‰¹å¾å’Œå›¾ç»“æ„ï¼Œæœ¬æ–‡å°†æµ“ç¼©å›¾çš„Feature Matrixè®¾ä¸ºè‡ªç”±å‚æ•°çŸ©é˜µï¼Œå°†æµ“ç¼©å›¾ç»“æ„è®¾ä¸ºå…³äºFeature matrix çš„ å‡½æ•°ï¼ˆåŸºäºç»“æ„ä¸ç‰¹å¾ç›¸å…³è”å‡è®¾ï¼‰ï¼Œä½¿å¾—è®¡ç®—å¼€é”€é™ä½ã€‚
Methodology A graph $\mathcal{T}=\{\mathbf{A}, \mathbf{X}, \mathbf{Y}\}$ï¼Œå…¶ä¸­$\mathbf{X} \in \mathbb{R}^{N \times d}$æ˜¯$d$ç»´èŠ‚ç‚¹ç‰¹å¾ï¼Œ$\mathbf{Y} \in\{0, \ldots, C-1\}^N$ è¡¨ç¤º$N$ä¸ªèŠ‚ç‚¹çš„labelsï¼Œå…±æœ‰$C$ä¸ªclassã€‚å›¾æµ“ç¼©æ—¨åœ¨å­¦ä¹ ä¸€ä¸ªå°çš„ç”Ÿæˆå›¾$\mathcal{S}=\left\{\mathbf{A}^{\prime}, \mathbf{X}^{\prime}, \mathbf{Y}^{\prime}\right\}$ï¼Œå…¶ä¸­$\mathbf{A}^{\prime} \in \mathbb{R}^{N^{\prime} \times N^{\prime}}$æ˜¯æµ“ç¼©å›¾çš„é‚»æ¥çŸ©é˜µï¼Œ$\mathbf{X}^{\prime} \in \mathbb{R}^{N^{\prime} \times D}$æ˜¯æµ“ç¼©å›¾çš„ç‰¹å¾çŸ©é˜µï¼Œ$\mathbf{Y}^{\prime} \in\{0, \ldots, C-1\}^{N^{\prime}}$æ˜¯æµ“ç¼©å›¾çš„node labels å…¶ä¸­$N^{\prime} \ll N$ï¼Œç‰¹å¾ç»´åº¦ä»$d$å˜ä¸º$D$ã€‚å›¾æµ“ç¼©çš„ç›®æ ‡æ˜¯åŸºäºåŸå›¾è®­ç»ƒè¿‡ç¨‹å­¦ä¹ æµ“ç¼©å›¾$\mathcal{S}$ï¼Œä½¿å¾—åœ¨$\mathcal{S}$ä¸Šè®­ç»ƒçš„GNNåº”ç”¨åœ¨åŸå›¾ä¸Šçš„lossæœ€å°ï¼š $$ \min_{\mathcal{S}} \mathcal{L}\left(\mathrm{GNN}_{\boldsymbol{\theta}_{\mathcal{S}}}(\mathbf{A}, \mathbf{X}), \mathbf{Y}\right) \quad \text { s.t } \quad \boldsymbol{\theta}_{\mathcal{S}}=\underset{\boldsymbol{\theta}}{\arg \min } \mathcal{L}\left(\mathrm{GNN}_{\boldsymbol{\theta}}\left(\mathbf{A}^{\prime}, \mathbf{X}^{\prime}\right), \mathbf{Y}^{\prime}\right), $$ Outerï¼šå›ºå®šGNNå‚æ•°ï¼Œä¼˜åŒ–å°å›¾ã€‚ Inner: å›ºå®šå°å›¾ï¼Œåœ¨å°å›¾ä¸Šè®­ç»ƒGNNå‚æ•°ã€‚...</p></section><footer class=entry-footer><span title="2022-09-01 10:47:21 +0800 CST">September 1, 2022</span>&nbsp;Â·&nbsp;1 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2022 ã€ŠGraph Condensation for Graph Neural Networksã€‹ Reading Notes" href=https://JhuoW.github.io/posts/gcond/></a></article><article class=post-entry><header class=entry-header><h2>MLP and GNNs</h2></header><section class=entry-content><p>æœ€è¿‘ä¸€äº›å·¥ä½œé€šè¿‡è§£è€¦Message-Passing å’Œ Feature Learningçš„æ–¹å¼æ¥æå‡GNNçš„å¯æ‹“å±•æ€§ï¼Œè¿™é‡Œå¯¹ä¸€å°éƒ¨åˆ†ç›¸å…³å·¥ä½œåšä¸€ä¸ªå°æ€»ç»“ã€‚
1. Combining Label Propagation and Simple Models Out-performs Graph Neural Networks ï¼ˆICLR2021ï¼‰ æ¨¡å‹é¦–å…ˆå¿½ç•¥å›¾ç»“æ„ï¼Œç”¨ç®€å•æ¨¡å‹ï¼ˆMLPï¼‰ï¼Œåªä½¿ç”¨èŠ‚ç‚¹ç‰¹å¾é¢„æµ‹labelï¼š
$$ \min \sum_{i \in L_{t}} \ell\left(f\left(x_{i}\right), y_{i}\right) $$ è€ƒè™‘ä¸€ä¸ªinductive biasï¼šé¢„æµ‹è¯¯å·®ä¸é‚»è¿‘åº¦å…³ç³»å¼ºç›¸å…³ï¼Œå¯¹å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„è¯¯å·®åšæ ¡æ­£ã€‚
å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆè®¡ç®—ä¸€ä¸ªåˆå§‹çš„è¯¯å·®çŸ©é˜µ$E$ï¼Œå…¶ä¸­è®­ç»ƒé›†è¯¯å·®å¦‚ä¸‹ $$ E_{L_{t},:}=Y_{L_{t},:}-Z_{L_{t},:} $$ å…¶ä»–èŠ‚ç‚¹çš„è¯¯å·®æœªçŸ¥ï¼š$E_{L_{v},:}=0, \quad E_{U,:}=0$ã€‚ç„¶åé€šè¿‡Label Propagationå°†è¯¯å·®çŸ©é˜µåœ¨å›¾ä¸Šåšå¹³æ»‘ï¼Œä½¿å¾—ç›¸é‚»èŠ‚ç‚¹çš„è¯¯å·®ç›¸ä¼¼ï¼š
$$ \hat{E}=\underset{W \in \mathbb{R}^{n \times c}}{\arg \min } \operatorname{trace}\left(W^{T}(I-S) W\right)+\mu||W-E||_{F}^{2} $$ ç”±æ­¤å¾—åˆ°æ‰€æœ‰èŠ‚ç‚¹çš„è¯¯å·®çŸ©é˜µ$\hat{E}$ã€‚ç„¶åç”¨$\hat{E}$å¯¹åŸºç¡€MLPé¢„æµ‹åšæ ¡æ­£ï¼Œè¿™ä¸ªpost-processingè¿‡ç¨‹ä¸æ¶‰åŠè®­ç»ƒå‚æ•°ï¼Œæ ¡æ­£åçš„é¢„æµ‹ä¸ºï¼š $$ Z^{(r)} = Z + \hat{E} $$ è€ƒè™‘homophilyï¼šæ ¡æ­£çš„é¢„æµ‹labelè¦æ»¡è¶³ç›¸é‚»èŠ‚ç‚¹labelç›¸ä¼¼ã€‚ æ³¨æ„ï¼Œè¿™é‡Œä¸ç›´æ¥å¯¹$Z^{(r)}$åšLabel Propagationï¼Œè€Œæ˜¯æ„é€ äº†ä¸€ä¸ªlabelçŸ©é˜µ$H \in \mathbb{R}^{n \times c}$ï¼Œå…¶ä¸­å°†è®­ç»ƒé›†çœŸå®labelå’ŒéªŒè¯+æµ‹è¯•é›†æ ¡æ­£labelåŠ å…¥$H$ä¸­ï¼Œç„¶åå¯¹$H$åšlabel propagationï¼š $$ \begin{aligned} H_{L_{t},:}&=Y_{L_{t},:} \\ H_{L_{v} \cup U,:}&=Z_{L_{v} \cup U,:}^{(r)} \end{aligned} $$ Label Prop: $$ H^{(t+1)}=(1-\alpha) H+\alpha S H^{(t)} $$ æœ€åç›´æ¥ç”¨æ”¶æ•›çš„$H$åšé¢„æµ‹ï¼Œå³$\hat{Y} = H^{\infty}$ï¼Œnode $i$ çš„é¢„æµ‹classä¸ºï¼š $$ y_i = \arg \max _{j \in\{1, \ldots, c\}} \hat{Y}_{i j} $$...</p></section><footer class=entry-footer><span title="2022-08-27 00:00:00 +0000 UTC">August 27, 2022</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to MLP and GNNs" href=https://JhuoW.github.io/posts/glnn/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2021 ã€ŠCombining Label Propagation and Simple Models Out-performs Graph Neural Networksã€‹ Reading Notes</h2></header><section class=entry-content><p>paper
Introduction æœ¬æ–‡ç ”ç©¶äº†ç»“åˆæ›´ç®€å•çš„æ¨¡å‹æ¥å¤„ç†transductive node classificationä»»åŠ¡ã€‚ ä¸»è¦åŒ…æ‹¬1ä¸ªé¢„æµ‹æ¨¡å—å’Œä¸¤ä¸ªåå¤„ç†ï¼ˆpost-processingï¼‰æ¨¡å—ï¼š
Base predictorï¼šå¿½ç•¥å›¾ç»“æ„ï¼Œç”¨ç®€å•æ¨¡å‹ï¼ˆå¦‚MLPæˆ–çº¿æ€§æ¨¡å‹ï¼‰ä½¿ç”¨èŠ‚ç‚¹ç‰¹å¾é¢„æµ‹label Error correctionï¼šæ ¡æ­£æ­¥éª¤ï¼Œå°†è®­ç»ƒæ•°æ®ä¸­çš„ä¸ç¡®å®šæ€§ï¼ˆè¯¯å·®ï¼‰ä¼ æ’­åˆ°å›¾ä¸Šï¼Œæ¥æ ¡æ­£Base predictorçš„é¢„æµ‹ Smoothingï¼šåœ¨å›¾ä¸Šå¹³æ»‘é¢„æµ‹ å…¶ä¸­åªæœ‰ç¬¬ä¸€æ­¥base predictorçš„å‚æ•°æ˜¯å¯å­¦ä¹ çš„ï¼Œå³æ¶‰åŠå›¾ç»“æ„çš„æ“ä½œï¼ˆCorrectionå’ŒSmoothingï¼‰æ— éœ€å‚æ•°å­¦ä¹ ï¼Œè¿™ç§ç®€å•çš„æ¨¡å‹ä½¿å¾—å‚æ•°æ•°é‡å‡å°‘äº†å‡ ä¸ªæ•°é‡çº§ï¼Œè®­ç»ƒæ—¶é—´ä¹Ÿå‡å°‘äº†å‡ ä¸ªæ•°é‡çº§ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾æ‰©å±•åˆ°å¤§è§„æ¨¡å›¾ã€‚
ç›¸æ¯”äºè¿‡å»çš„GNN+LPçš„æ–¹æ³•ï¼ŒC&Sæ›´åŠ é«˜æ•ˆï¼š1ï¼‰C&Sé¦–å…ˆåªä½¿ç”¨èŠ‚ç‚¹ç‰¹å¾è¿›è¡Œä½æˆæœ¬çš„base predictionï¼›2ï¼‰ç„¶åå†ä½¿ç”¨æ ‡ç­¾ä¼ æ’­å¯¹åŸºç¡€é¢„æµ‹è¿›è¡Œæ ¡æ­£ ï¼›3ï¼‰æœ€åå¯¹æœ€ç»ˆé¢„æµ‹è¿›è¡Œå¹³æ»‘ã€‚ ç¬¬ä¸€æ­¥æ˜¯é¢„æµ‹æ“ä½œï¼Œåä¸¤éƒ¨æ˜¯åå¤„ç†æ“ä½œï¼Œä¹Ÿå°±æ˜¯ç¬¬ä¸€æ­¥ä¸ºä¸€ä¸ªç‹¬ç«‹çš„ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œåä¸¤éƒ¨åŸºäºä¸€ä¸ªinductive biasæ¥è°ƒæ•´èŠ‚ç‚¹çš„è¡¨ç¤ºã€‚å³homophilyå‡è®¾ï¼šç›¸è¿èŠ‚ç‚¹çš„è¯¯å·®å’Œlabelæ˜¯ç›¸ä¼¼çš„ï¼ˆæ­£ç›¸å…³ï¼‰ã€‚è®­ç»ƒèŠ‚ç‚¹çš„è¯¯å·®å’Œå®ƒç›¸è¿èŠ‚ç‚¹çš„è¯¯å·®åº”ç›¸ä¼¼ï¼Œé‚£ä¹ˆå°±ç”¨è®­ç»ƒèŠ‚ç‚¹çš„è¯¯å·®æ¥æ ¡æ­£é‚»å±…èŠ‚ç‚¹ã€‚
å› æ­¤ï¼Œå°†æ ‡ç­¾æ›´åŠ ç›´æ¥çš„æ•´åˆåˆ°GNNçš„å­¦ä¹ ç®—æ³•ä¸­æ˜¯æœ¬æ–‡æ€§èƒ½çš„å…³é”®ï¼Œå¹¶ä¸”å‘ç°LPä¸node featuresæ˜¯ç›¸äº’äº’è¡¥çš„ä¿¡å·ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨OGB-Productsä¸Šï¼Œå‚æ•°é‡æ¯”GNNå°‘äº†2ä¸ªæ•°é‡çº§ï¼Œè®­ç»ƒæ—¶é—´ä¹Ÿå‡å°‘2ä¸ªæ•°é‡çº§ã€‚
Correct and Smooth (C&S) Model ç»™å®šæ— å‘å›¾$G=(V,E)$ï¼Œ$A$ä¸ºé‚»æ¥çŸ©é˜µï¼Œ$S=D^{-1 / 2} A D^{-1 / 2}$ä¸ºå½’ä¸€åŒ–é‚»æ¥çŸ©é˜µã€‚èŠ‚ç‚¹é›†åˆ’åˆ†ä¸ºlabeled nodes $V_L$å’Œunlabeled nodes $V_U$ï¼Œå…¶ä¸­$V = V_L \cup V_U$ã€‚è¿›ä¸€æ­¥ï¼Œlabeled nodeså¯ä»¥åˆ†ä¸ºè®­ç»ƒèŠ‚ç‚¹é›†$V_{L_t}$å’ŒéªŒè¯èŠ‚ç‚¹é›†$V_{L_v}$ã€‚è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„labelåˆ†åˆ«ä¸º$Y_{L_t:}$å’Œ$Y_{L_v:}$ï¼Œ æ¯è¡Œä¸ºlabelçš„one-hotå‘é‡ã€‚
Simple Base Predictor $$ \min \sum_{i \in L_{t}} \ell\left(f\left(x_{i}\right), y_{i}\right) $$
$f(\cdot)$ä¸ºç®€å•çš„è®­ç»ƒæ¨¡å‹+softmaxï¼Œå¦‚æµ…å±‚MLPï¼Œ $\ell$ä¸ºcross-entropy lossã€‚ åŸºäºè®­ç»ƒèŠ‚ç‚¹$V_{L_t}$ç‰¹å¾çš„æ¨¡å‹$f$å¯ä»¥å¾—åˆ°è¾“å‡ºé¢„æµ‹$Z \in \mathbb{R}^{n\times c}$ï¼Œ å…¶ä¸­$Z$çš„æ¯è¡Œæ˜¯softmaxå¾—åˆ°çš„åˆ†ç±»æ¦‚ç‡åˆ†å¸ƒã€‚Simple Base Predictoræ˜¯ä¸€ä¸ªç‹¬ç«‹è®­ç»ƒçš„ç«¯åˆ°ç«¯æ¨¡å‹ã€‚
Correcting Base Prediction with Error Correlation (ä½¿ç”¨é‚»å±…è¯¯å·®å…³è”æ¥çº æ­£åŸºç¡€é¢„æµ‹ï¼‰ é€šè¿‡èåˆæ ‡ç­¾ä¿¡æ¯æ¥æé«˜base prediction $Z$çš„å‡†ç¡®ç‡ã€‚ æœ¬æ–‡æœŸæœ›base predictionä¸­çš„è¯¯å·®æ²¿ç€å›¾ä¸­çš„è¾¹æ­£ç›¸å…³ï¼Œå³èŠ‚ç‚¹$i$å‡ºçš„é¢„æµ‹è¯¯å·®åœ¨å®ƒçš„é‚»å±…å¤„ä¹Ÿä¼šå‡ºç°ç›¸ä¼¼çš„è¯¯å·®ã€‚ä¸ºäº†å®ç°è¿™ä¸ªç›®çš„ï¼Œé¦–å…ˆå®šä¹‰ä¸€ä¸ªè¯¯å·®çŸ©é˜µ$E \in \mathbb{R}^{n \times c}$ç”¨æ¥ä¿å­˜æ¯ä¸ªèŠ‚ç‚¹çš„é¢„æµ‹è¯¯å·®ï¼Œå…¶ä¸­è¯¯å·®ä¸ºè®­ç»ƒæ•°æ®é›†ä¸Šçš„æ®‹å·®ï¼ˆåªæœ‰è®­ç»ƒèŠ‚ç‚¹ç”±è¯¯å·®ï¼‰å…¶ä»–æ²¡æœ‰è®­ç»ƒè¿‡ç¨‹ä¸­ä¸çŸ¥é“labelçš„èŠ‚ç‚¹è¯¯å·®è®¾ä¸º0ï¼š $$ E_{L_{t},:}=Y_{L_{t},:}-Z_{L_{t},:} \quad ä¸ºè®­ç»ƒé›†èŠ‚ç‚¹ V_{L_t}çš„è¯¯å·® $$...</p></section><footer class=entry-footer><span title="2022-07-11 09:42:15 +0800 CST">July 11, 2022</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2021 ã€ŠCombining Label Propagation and Simple Models Out-performs Graph Neural Networksã€‹ Reading Notes" href=https://JhuoW.github.io/posts/c_and_s/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://JhuoW.github.io/page/2/>Next Page Â»</a></nav></footer></main><footer class=footer><span>Copyright &copy; 2023 <a href=https://JhuoW.github.io/>JhuoWâ€˜s Notes</a></span>
<span></span><br><script>function siteTime(){var u=1e3,r=u*60,a=r*60,n=a*24,x=n*365,e=new Date,d=2019,O=1,w=16,_=19,y=15,m=11,l=e.getFullYear(),C=e.getMonth()+1,f=e.getDate(),p=e.getHours(),g=e.getMinutes(),v=e.getSeconds(),b=Date.UTC(d,O,w,_,y,m),j=Date.UTC(l,C,f,p,g,v),s=j-b,o=Math.floor(s/x),t=Math.floor(s/n-o*365),i=Math.floor((s-(o*365+t)*n)/a),c=Math.floor((s-(o*365+t)*n-i*a)/r),h=Math.floor((s-(o*365+t)*n-i*a-c*r)/u);d==l?document.getElementById("sitetime").innerHTML="æœ¬ç«™å·²è¿è¡Œ "+t+" å¤© "+i+" å°æ—¶ "+c+" åˆ†é’Ÿ "+h+" ç§’":document.getElementById("sitetime").innerHTML="æœ¬ç«™å·²è¿è¡Œ "+o+" å¹´ "+t+" å¤© "+i+" å°æ—¶ "+c+" åˆ†é’Ÿ "+h+" ç§’"}setInterval(siteTime,1e3)</script><span id=sitetime>è½½å…¥è¿è¡Œæ—¶é—´...</span>
<script type=text/javascript id=clustrmaps src="//cdn.clustrmaps.com/map_v2.js?cl=080808&w=268&t=tt&d=YsONH-MzO6L7yrkA73Z_QW7LuMTfdUhk0uhb_KaBv-g&co=f5f5f5&cmo=3acc3a&cmn=ff5353&ct=808080"></script>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>