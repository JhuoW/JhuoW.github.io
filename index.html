<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.147.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script type=text/javascript async src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><title>JhuoWâ€˜s Notes</title>
<meta name=keywords content="Blog,Portfolio,PaperMod"><meta name=description content="Jhuoâ€™s Notes"><meta name=author content="JhuoW"><link rel=canonical href=https://JhuoW.github.io/><meta name=google-site-verification content="G-6F49SGED6V"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><link rel=preload href=/apple-touch-icon.png as=image><link rel=icon href=https://JhuoW.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://JhuoW.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://JhuoW.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://JhuoW.github.io/apple-touch-icon.png><link rel=mask-icon href=https://JhuoW.github.io/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://JhuoW.github.io/index.xml><link rel=alternate type=application/json href=https://JhuoW.github.io/index.json><link rel=alternate hreflang=en href=https://JhuoW.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-6F49SGED6V"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6F49SGED6V")}</script><meta property="og:title" content="JhuoWâ€˜s Notes"><meta property="og:description" content="Jhuoâ€™s Notes"><meta property="og:type" content="website"><meta property="og:url" content="https://JhuoW.github.io/"><meta property="og:image" content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="JhuoW"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="JhuoWâ€˜s Notes"><meta name=twitter:description content="Jhuoâ€™s Notes"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"JhuoWâ€˜s Notes","url":"https://JhuoW.github.io/","description":"Jhuoâ€™s Notes","thumbnailUrl":"https://JhuoW.github.io/favicon.ico","sameAs":["https://github.com/JhuoW","mailto:jhuow@proton.me"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://JhuoW.github.io/ accesskey=h title="JhuoW's Notes (Alt + H)"><img src=https://JhuoW.github.io/apple-touch-icon.png alt=logo aria-label=logo height=35>JhuoW's Notes</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></span></div><ul id=menu><li><a href=https://JhuoW.github.io/about/ title=About><span>About</span></a></li><li><a href=https://JhuoW.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://JhuoW.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://JhuoW.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://JhuoW.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>ğŸ’Ÿ My Notebook ğŸŒ»</h1></header><section class=entry-content><p><p>This is my notebook.</p><ul><li>You can know more about me in my personal website ğŸ‘‰ <strong><a href=https://wei2hu0.github.io/>https://wei2hu0.github.io/</a></strong></li></ul></p></section><footer class=entry-footer><div class=social-icons><a href=https://github.com/JhuoW target=_blank rel="noopener noreferrer me" title=Github><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a href=mailto:jhuow@proton.me target=_blank rel="noopener noreferrer me" title=Email><svg viewBox="0 0 24 21" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></footer></article><article class=post-entry><header class=entry-header><h2>Fair Graph Learning</h2></header><section class=entry-content><p>Overview The following two works reduce prediction discrimination by optimizing adjacency matrices, which can improve fairness for link prediction tasks:
On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections ï¼ˆICLR 2021ï¼‰ All of the Fairness for Edge Prediction with Optimal Transport (AISTATS 2021) é€šè¿‡ä¿®æ”¹åŸå›¾çš„æ•æ„Ÿå±æ€§ï¼Œä½¿ç”¨å¯¹æ¯”å­¦ä¹ æ¥å®ç°æ¨¡å‹å¯¹æ•æ„Ÿå±æ€§çš„é²æ£’æ€§ï¼Œå³æ•æ„Ÿå±æ€§çš„ä¿®æ”¹ä¸ä¼šå½±å“æ¨¡å‹çš„è¾“å‡º:
Towards a Unified Framework for Fair and Stable Graph Representation Learning (UAI 2021) ä½¿ç”¨å¯¹æŠ—è®­ç»ƒç­–ç•¥æ¥å¢å¼ºå›¾ï¼Œä½¿å¾—å¢å¼ºå›¾ä¸æ•æ„Ÿå±æ€§çš„å…³ç³»ï¼ˆMIï¼‰æœ€å°ï¼ŒåŸºäºå¢å¼ºå›¾è®­ç»ƒçš„representationå¯ä»¥å®ç°fairness:
Learning Fair Graph Representations via Automated Data Augmentations (ICLR 2023) è¯æ˜äº†message passingçš„neighbor aggregationä¼šä½¿å¾—æ‹“æ‰‘åå·®ç§¯ç´¯åˆ°node representationä¸­ï¼Œåœ¨GNNçš„signal denoisingä¼˜åŒ–æ¡†æ¶ä¸­åŠ å…¥fairness regularizationï¼Œä½¿å¾—å­¦ä¹ åˆ°çš„èŠ‚ç‚¹è¡¨ç¤ºå‘é‡è¦æ»¡è¶³ï¼Œä¸åŒæ•æ„Ÿgroupå…·æœ‰ç›¸åŒçš„æœŸæœ›logits:
...</p></section><footer class=entry-footer><span title='2025-05-21 12:13:13 +0800 +08'>May 21, 2025</span>&nbsp;Â·&nbsp;10 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to Fair Graph Learning" href=https://JhuoW.github.io/posts/fairnessgnn/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2024ã€ŠOne for Allï¼šTowards Training One Graph Model for All Classification Tasksã€‹ Reading Notes</h2></header><section class=entry-content><p>What is in-context learning?
â€œIn-Context Learning is a way to use LLMs to learn tasks given only a few examples. During in-context learning, we give the LM a prompt that consists of a list of input-output pairs that demonstrate how to perform a task. At the end of the prompt, we append a test input and allow the LM to make a prediction just by conditioning on the prompt and predicting the next tokens. For example, to answer the two prompts below, the model needs to examine the training examples to figure out the input distribution (financial or general news), output distribution (Positive/Negative or topic), input-output mapping (sentiment or topic classification), and the formatting. â€œ
...</p></section><footer class=entry-footer><span title='2025-05-21 11:57:35 +0800 +08'>May 21, 2025</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2024ã€ŠOne for Allï¼šTowards Training One Graph Model for All Classification Tasksã€‹ Reading Notes" href=https://JhuoW.github.io/posts/ofa/></a></article><article class=post-entry><header class=entry-header><h2>KDD2023ã€ŠAll in Oneï¼šMulti-Task Prompting for Graph Neural Networksã€‹ Reading Notes</h2></header><section class=entry-content><p>å›¾ç¥ç»ç½‘ç»œçš„é¢„è®­ç»ƒä»»åŠ¡å’Œä¸‹æ¸¸ä»»åŠ¡ä¹‹é—´å¯èƒ½å­˜åœ¨è¾ƒå¤§gapï¼Œç›´æ¥å°†é¢„è®­ç»ƒæ¨¡å‹åº”ç”¨åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šå¯èƒ½ä¼šäº§ç”Ÿè´Ÿè¿ç§»ç°è±¡ï¼ˆâ€œnegative transferâ€ï¼‰ã€‚ä¾‹å¦‚ï¼Œbinary edge predictionç»å¸¸ç”¨äºpretrain graph modelã€‚è¿™æ ·çš„é¢„è®­ç»ƒæ¨¡å‹ä½¿å¾—æœ‰è¾¹è¿æ¥çš„èŠ‚ç‚¹åœ¨representation spaceä¸­æ¥è¿‘ã€‚ä½†æ˜¯ä¸‹æ¸¸ä»»åŠ¡å¯èƒ½æ˜¯node-level æˆ–graph-level tasksï¼Œä¸‹æ¸¸çš„ä»»åŠ¡å¦‚æœæ˜¯èŠ‚ç‚¹åˆ†ç±»ä»»åŠ¡ï¼Œé‚£ä¹ˆé¢„è®­ç»ƒæ¨¡å‹éœ€è¦é’ˆå¯¹é¢å¤–çš„èŠ‚ç‚¹ç±»åˆ«æ ‡ç­¾æœç´¢æ›´é«˜ç»´åº¦çš„å‚æ•°ç©ºé—´ã€‚å¦‚æœå›¾ä¸­ç›¸è¿èŠ‚ç‚¹çš„ç±»åˆ«ä¸åŒï¼ˆheterophilicï¼‰ï¼Œé‚£ä¹ˆåŸºäºedge prediction pretrainedçš„æ¨¡å‹ä¼šå¯¹ä¸‹æ¸¸ä»»åŠ¡å‚æ•°è´Ÿé¢æ•ˆæœã€‚
ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä¸€ä¸ªæ½œåœ¨çš„æ–¹å‘æ˜¯å°†â€œpretraining and fine-tuningâ€æ‹“å±•ä¸ºâ€œpretraining, prompting, and fine-tuningâ€ã€‚ä¾‹å¦‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œå¦‚æœè¦èµ‹äºˆé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹é¢„æµ‹å¥å­æƒ…æ„Ÿçš„èƒ½åŠ›ï¼ˆsentiment analysisï¼‰ï¼Œå¯ä»¥é€šè¿‡promptæ¥å®Œæˆï¼Œè€Œä¸éœ€è¦ä¼˜åŒ–pretrained modelã€‚
ä»¥ä¸Šå›¾ä¸ºä¾‹ï¼Œå¯¹äºä¸€ä¸ªfronzen LLMï¼ˆå‚æ•°å›ºå®šï¼‰ï¼Œå¦‚æœè¦ä¸ºè¿™ä¸ªæ¨¡å‹èµ‹äºˆæƒ…æ„Ÿåˆ†æçš„èƒ½åŠ›ï¼Œæˆ‘ä»¬å¯ä»¥é¢å¤–è®­ç»ƒä¸€ä¸ªæœ€ä½³çš„promptï¼Œè®­ç»ƒæ•°æ®ä¸ºprompt parametersï¼Œè¦æ±‚è¿™ä¸ªprompt tokensåœ¨tasker $\phi$çš„ä¼˜åŒ–ä¸‹ï¼Œç”Ÿæˆçš„ä¸‹ä¸€ä¸ªtokenæ˜¯æ­£ç¡®çš„æƒ…æ„Ÿï¼ˆlabelä¸ºexcitedï¼‰ã€‚å³è®­ç»ƒå¾—åˆ°ä¸€ä¸ªæœ€ä½³çš„prompt tokensï¼Œæ¯”å¦‚è®­ç»ƒå¾—åˆ°çš„æœ€ä½³prompt tokensæ˜¯â€œI feel so [mask]â€ï¼Œä½¿å¾—frozen LLMåº”ç”¨åœ¨â€œKDD2023 will witness many high-quality papers. I feel so â€ è¿™ä¸ªå¥å­ä¸Šæ—¶ï¼Œå¯ä»¥å°†ä¸‹ä¸€ä¸ªè¯é¢„æµ‹ä¸ºæƒ…æ„Ÿè¯ï¼Œè¿™æ ·LLMåœ¨è¾“å…¥åŒ…å«prompt tokensçš„æƒ…å†µä¸‹ï¼Œå¯ä»¥å…·å¤‡é¢„æµ‹å¥å­æƒ…æ„Ÿçš„èƒ½åŠ›ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ Prompt Learningçš„ç›®çš„æ˜¯è®­ç»ƒå¾—åˆ°ä¸€å †tokensï¼Œä½¿å¾—è¿™äº›tokensä¸åŸæ¥çš„contextæ‹¼èµ·æ¥å¯ä»¥ä½¿å¾—LLMå…·å¤‡æ–°çš„èƒ½åŠ›ã€‚
è¿™ç¯‡æ–‡ç« çš„ç›®çš„æ˜¯åœ¨å›¾ä¸ŠåšPrompt Learningï¼Œä¹Ÿå°±æ˜¯åœ¨è®­ç»ƒä¸€ä¸ªprompt graphï¼Œä½¿å¾—ç°æœ‰å›¾æ‹¼ä¸Šè¿™ä¸ªprompt graphåï¼Œé¢„è®­ç»ƒçš„GNNå¯ä»¥åœ¨æ–°çš„ä»»åŠ¡ä¸Šï¼ˆé¢„è®­ç»ƒé˜¶æ®µæ²¡æœ‰æ¥è§¦è¿‡çš„ä»»åŠ¡ä¸Šï¼‰ä¹Ÿè¡¨ç°çš„è¾ƒå¥½ã€‚ ä½†æ˜¯åœ¨graphä¸ŠåšPrompt Learningå­˜åœ¨ä»¥ä¸‹æŒ‘æˆ˜ï¼š
è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œprompt tokensæ˜¯ä¸€ä¸ªä¸€ç»´çº¿æ€§çš„å¥å­ï¼Œå¯ä»¥æ”¾åœ¨contentçš„å¼€å¤´æˆ–ç»“å°¾ï¼Œä½†æ˜¯åœ¨graphä¸­ï¼ŒèŠ‚ç‚¹æ˜¯éæ¬§ç»“æ„ï¼Œå› æ­¤å¦‚ä½•ç»„ç»‡prompt tokensï¼Œä»¥åŠå¦‚ä½•å°†graph promptsä¸input graphç»“åˆæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œç±»ä¼¼äºæƒ…æ„Ÿåˆ†æï¼Œå’Œé—®ç­”ä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡éƒ½å¯ä»¥ç®€å•çš„é‡æ„ä¸ºnext token predictionï¼ˆå•è¯é¢„æµ‹ï¼‰çš„ä»»åŠ¡ï¼Œæ‰€ä»¥åªéœ€è¦ä½¿ç”¨å•è¯é¢„æµ‹æ¥è®­ç»ƒpromptå°±å¯ä»¥ã€‚ä½†æ˜¯åœ¨å›¾ä¸­ï¼ŒèŠ‚ç‚¹çº§ä»»åŠ¡ã€è¾¹çº§ä»»åŠ¡å’Œå›¾çº§ä»»åŠ¡éš¾ä»¥ç»Ÿä¸€æˆä¸€ç§å½¢å¼ã€‚å› æ­¤å¦‚ä½•å°†å„ç§promptä»»åŠ¡ç»Ÿä¸€æ¥è®­ç»ƒgraph promptä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ è®­ç»ƒå¥½prompt tokençš„å‘é‡åŒ–ä¿¡æ¯ã€è¿æ¥ç»“æ„ã€ä»¥åŠæ’å…¥åˆ°åŸå›¾çš„æ–¹å¼ï¼Œç„¶åFrozen Pretrained Modelåº”ç”¨åœ¨è¿™ä¸ªcombined graphä¸Šåï¼Œå°±å¯ä»¥ä¸ºPretrained Modelèµ‹äºˆå¤„ç†æ–°ä»»åŠ¡çš„èƒ½åŠ›ã€‚
Reformulating Downstream Tasks å°†èŠ‚ç‚¹çº§å’Œè¾¹çº§çš„ä¸‹æ¸¸ä»»åŠ¡ç»Ÿä¸€ä¸ºinduced graphçš„æ ‡ç­¾é¢„æµ‹é—®é¢˜ã€‚
...</p></section><footer class=entry-footer><span title='2025-05-20 14:22:08 +0800 +08'>May 20, 2025</span>&nbsp;Â·&nbsp;1 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to KDD2023ã€ŠAll in Oneï¼šMulti-Task Prompting for Graph Neural Networksã€‹ Reading Notes" href=https://JhuoW.github.io/posts/allinone/></a></article><article class=post-entry><header class=entry-header><h2>NeurIPS2023ã€ŠEvaluating GNN Performance On Unseen Graphs Without Labelsã€‹ Reading Notes</h2></header><section class=entry-content><p>Paper
ç›®çš„ï¼šåœ¨ä¸€ä¸ªå›¾ä¸Šè®­ç»ƒå¥½çš„GNNï¼Œåœ¨æœªçŸ¥çš„testing graphä¸Šçš„ç»“æœç”±äºtrainingå’Œtestæ•°æ®åˆ†å¸ƒçš„ä¸åŒï¼Œå¯èƒ½å­˜åœ¨å¾ˆå¤§çš„ä¸ç¡®å®šæ€§ã€‚é€šå¸¸æ¥è¯´ï¼Œin-serviceçš„GNNåœ¨å·²çŸ¥graph with labelsçš„å›¾ä¸Šè®­ç»ƒå¥½åï¼Œéœ€è¦éƒ¨ç½²åœ¨labelæœªçŸ¥çš„testing graphä¸Šï¼Œä½†æ˜¯ç”±äºlabelæœªçŸ¥ï¼Œæ— æ³•ä¼°è®¡GNNåœ¨testing graphä¸Šçš„æ•ˆæœã€‚
å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œå¯¹äºä¸€ä¸ªå·²ç»åœ¨è®­ç»ƒå›¾ $\mathcal{S}=(\mathbf{X}, \mathbf{A}, \mathbf{Y})$ä¸Šwell-trained & fixed GNN model $\mathrm{GNN}_{\mathcal{S}}^\star$ï¼Œå¹¶ä¸”å°†å®ƒdeploy in serviceã€‚å¯¹äºä¸€ä¸ªä¸çŸ¥é“labelçš„æµ‹è¯•å›¾ $\mathcal{T}$ï¼Œç”±äºä¸çŸ¥é“labelï¼Œå¦‚ä½•è¯„ä¼°GNNåœ¨è¯¥æµ‹è¯•å›¾ä¸Šçš„æ€§èƒ½æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç”±äºå¯è§çš„è®­ç»ƒgraphå’Œä¸å¯è§çš„test graphçš„åˆ†å¸ƒå·®å¼‚å¯èƒ½å¾ˆå¤§ï¼Œå› æ­¤GNNè¯„ä¼°å™¨GNNEvaluatoréœ€è¦å……åˆ†å­¦ä¹ å¤šæ ·åŒ–çš„å›¾ç»“æ„with diverse node context and graph structure distributionsï¼Œä»è€Œå¯ä»¥è¯„ä¼°ä¸åŒæ•°æ®åˆ†å¸ƒçš„æµ‹è¯•å›¾æ½œåœ¨çš„æ•ˆæœã€‚
å‡è®¾ï¼šCovariate shift between the training graph $\mathcal{S}$ and the label-unlabeled graph $\mathcal{T}$ with respect to the label spaceã€‚ å³æ— è®ºè¾“å…¥å›¾æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œè¾“å‡ºçš„label spaceç›¸åŒã€‚
å¦‚ä½•ç”Ÿæˆæ•°é‡è¶³å¤Ÿçš„graph setæ¥è®­ç»ƒGNNEvaluator $f_\theta$? Solutionï¼šé‡‡æ ·ä¸€ä¸ªseed subgraph $\mathcal{S}_{seed}$ from the observed training graph $\mathcal{S}$ã€‚é‡‡æ ·åŸåˆ™æ˜¯seed graph è¦å’Œ training graphä¹‹é—´æ»¡è¶³ç›¸åŒçš„label spaceï¼Œæ‰€ä»¥åŸå›¾ä¸­é‡‡æ ·å¯ä»¥ä½¿é‡‡æ ·å›¾$\mathcal{S}_{seed}$çš„åˆ†å¸ƒå°½å¯èƒ½å°‘çš„åç¦»åŸå›¾ï¼Œä»è€Œæ»¡è¶³Covariate shiftã€‚å¦‚ä¸‹å›¾å·¦è¾¹æ‰€ç¤ºã€‚
åœ¨å¾—åˆ°é‡‡æ ·seed graph $\mathcal{S}_{seed}$åï¼Œå¯¹ $\mathcal{S}_{seed}$åš $K$æ¬¡å¢å¼ºï¼Œå…¶ä¸­æ¶‰åŠçš„å¢å¼ºåŒ…æ‹¬ $\texttt{EdgeDrop}$ï¼Œ $\texttt{NodeDrop(Subgraph)}$ï¼Œ $\texttt{AttrMask}$å’Œ $\texttt{NodeMix}$ã€‚é€‰æ‹©å“ªç§å¢å¼ºæœ‰ç‰¹å®šçš„æ¦‚ç‡ $\epsilon$ã€‚åŸºäºseed graph $\mathcal{S}_{seed}$ï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸ª meta-graphé›†åˆ $\mathcal{G}_{\text{meta}}=\left\{g_{\text {meta }}^i\right\}_{i=1}^K$ï¼Œå…¶ä¸­çš„æ¯ä¸ªmeta-graphéƒ½æ˜¯ç”±seed graph æ‰°åŠ¨è€Œæ¥ï¼Œå’ŒåŸå›¾å…·æœ‰ç›¸åŒçš„label spaceã€‚æ¯ä¸ªmeta-graph $g_{\text {meta }}^i=\left\{\mathbf{X}_{\text {meta }}^i, \mathbf{A}_{\text {meta }}^i, \mathbf{Y}_{\text {meta }}^i\right\}$ï¼Œåˆ†åˆ«è¡¨ç¤ºmeta-graphçš„èŠ‚ç‚¹ç‰¹å¾ï¼Œç»“æ„å’Œæ ‡ç­¾ã€‚é€šè¿‡è¿™ç§æ–¹å¼å¯ä»¥ä¸ºåŸå›¾ç”Ÿæˆlabel spaceç›¸åŒï¼Œä½†ç»“æ„/ç‰¹å¾éƒ½ä¸ç›¸åŒå›¾ï¼Œæ‹“å±•äº†å·®å¼‚æ€§ï¼ŒåŸºäºè¿™äº›å›¾å­¦ä¹ åˆ°çš„GNNEvaluatorå¯ä»¥è¯„ä¼°ä¸åŒåˆ†å¸ƒå›¾çš„æ•ˆæœã€‚
...</p></section><footer class=entry-footer><span title='2025-05-20 13:45:31 +0800 +08'>May 20, 2025</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to NeurIPS2023ã€ŠEvaluating GNN Performance On Unseen Graphs Without Labelsã€‹ Reading Notes" href=https://JhuoW.github.io/posts/gnn-evaluator/></a></article><article class=post-entry><header class=entry-header><h2>ICML2023ã€ŠPersonalized Subgraph Federated Learningã€‹Reading Notes</h2></header><section class=entry-content><p>æœ¬æ–‡æ—¨åœ¨è§£å†³ä¸åŒå­å›¾ä½œä¸ºä¸åŒçš„clientï¼Œç”±äºclientæ˜¯locally accessibleï¼Œæ‰€ä»¥clienté—´å­˜åœ¨çš„missing edgesæ— æ³•è¢«serveræ•è·çš„æƒ…å†µã€‚ä¸FedSageä»…ä»…åŸºäºè‡ªèº«è¿æ¥æ¥expand missing neighborsï¼ˆå¹¶ä¸”æœ€å°åŒ–ç”Ÿæˆneighborå’Œå…¶ä»–æ‰€æœ‰å­å›¾çš„è·ç¦»ï¼‰ çš„missing neighborsç”Ÿæˆæ–¹å¼ä¸åŒï¼Œæœ¬æ–‡æå‡ºçš„FedPubè€ƒè™‘äº†å­å›¾çš„ç¤¾åŒºç»“æ„ï¼Œå³ä¸åŒç¤¾åŒºçš„å­å›¾ç›¸äº’ä¹‹é—´çš„è¾¹è¿æ¥å…³ç³»åº”è¯¥è¾ƒå¼±ï¼Œå¤„äºåŒä¸€ä¸ªç¤¾åŒºçš„å­å›¾åº”å­˜åœ¨æ›´å¼ºçš„è¾¹è¿æ¥å…³ç³»ã€‚
Personalized Subgraph FL (Overall) å¯¹äºæ¯ä¸ªå­å›¾ $G_i \in \mathcal{G}$ï¼Œä¼ ç»Ÿçš„æ–¹æ³•ä¼˜åŒ–æ–¹å¼æ˜¯å­¦ä¹ global optimal parameters $\bar{\theta}$ï¼Œä½¿å¾—è¯¥å‚æ•°åœ¨æ‰€æœ‰clientsä¸Šçš„æ€»lossæœ€å°ï¼š $\min_{\overline{\theta}} \sum_{G_i \subset \mathcal{G}} \mathcal{L}\left(G_i ; \overline{\theta}\right)$ã€‚ä½†æ˜¯ç”±äºå¤„åœ¨ä¸åŒç¤¾åŒºä¸­çš„å­å›¾å¼‚è´¨æ€§å¾ˆä¸¥é‡ï¼Œå¹¶ä¸”ä¸åŒç¤¾åŒºçš„å­å›¾é—´çš„edgesä¹Ÿå¾ˆç¨€ç–ï¼Œè¿™ç§å¼ºå¼‚è´¨æ€§å¾ˆéš¾å­¦ä¹ åˆ°ä¸€ä¸ªå¯¹æ‰€æœ‰å­å›¾éƒ½æœ€ä¼˜çš„ $\bar{\theta}$ã€‚å› æ­¤æœ¬æ–‡æå‡ºï¼Œåœ¨åŒä¸€ä¸ªcommunityçš„å­å›¾é—´å…±äº«å‚æ•°ï¼Œä¸åŒcommunityçš„å­å›¾ä¸å…±äº«å‚æ•°ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å…¨å±€é€šç”¨å‚æ•° $\bar{\theta}$ã€‚å› æ­¤ï¼ŒPersonalized Subgraph FLçš„å½¢å¼å¦‚ä¸‹ï¼š
$$ \begin{aligned} & \min_{\left\{\boldsymbol{\theta}_i, \boldsymbol{\mu}_i\right\}_{i=1}^K} \sum_{G_i \subseteq \mathcal{G}} \mathcal{L}\left(G_i ; \boldsymbol{\theta}_i, \boldsymbol{\mu}_i\right), \quad \boldsymbol{\theta}_i \leftarrow \boldsymbol{\mu}_i \odot\left(\sum_{j=1}^K \alpha_{i j} \boldsymbol{\theta}_j\right) \\ & \text { with } \alpha_{i k} \gg \alpha_{i l} \text { for } G_k \subseteq C \text { and } G_l \nsubseteq C \end{aligned} $$ å…¶ä¸­ $K$æ˜¯clientæ•°é‡ï¼Œ $\theta_i$æ˜¯å±äºcommunity $C$ çš„client $G_i$çš„å¯è®­ç»ƒæƒé‡ï¼Œ $\alpha_{ij}$æ˜¯client $i$ å’Œ $j$çš„æƒé‡èšåˆcoefficientã€‚å¦‚æœclient $k$å’Œ $i$å±äºåŒä¸€ä¸ªcommunityï¼Œè€Œclient $l$å’Œ $i$ä¸å±äºåŒä¸€ä¸ªcommunityï¼Œé‚£ä¹ˆå®ƒä»¬å…³äº $i$çš„å‚æ•°èšåˆç³»æ•° $\alpha_{i k} \gg \alpha_{i l}$ã€‚é€šè¿‡è¿™ç§æ–¹å¼æ¨¡å‹å¯ä»¥éšå¼åœ°è€ƒè™‘ä¸åŒsubgraphä¹‹é—´çš„å…³ç³»ã€‚
...</p></section><footer class=entry-footer><span title='2025-05-19 13:42:56 +0800 +08'>May 19, 2025</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICML2023ã€ŠPersonalized Subgraph Federated Learningã€‹Reading Notes" href=https://JhuoW.github.io/posts/fedpub/></a></article><article class=post-entry><header class=entry-header><h2>NeurIPS2021ã€ŠSubgraph Federated Learning with Missing Neighbor Generationã€‹Reading Notes</h2></header><section class=entry-content><p>Introduction Subgraph Federated Learningæ—¨åœ¨å¤šä¸ªåˆ†å¸ƒå¼çš„å­å›¾ä¸Šè®­ç»ƒä¸€ä¸ªå›¾æ¨¡å‹ï¼Œå¹¶ä¸”å­å›¾ä¹‹é—´æ²¡æœ‰æ•°æ®å…±äº«ã€‚é¢ä¸´2ä¸ªæŒ‘æˆ˜ï¼š
Q1: å¦‚ä½•å°†å„ä¸ªå­å›¾ä¸Šçš„æ¨¡å‹èåˆæˆä¸€ä¸ªå…¨å±€å¯ç”¨çš„æ¨¡å‹ï¼Œä½¿å…¶å¯ä»¥å¤„ç†æ¥è‡ªå…¨å±€å›¾çš„ä»»ä½•è¯·æ±‚ï¼Ÿ
A1: é’ˆå¯¹è¯¥æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºFedSageå°†GraphSageå’ŒFedAvgç»“åˆã€‚
Q2: å¦‚ä½•å¤„ç†local subgraphä¹‹é—´ç¼ºå¤±çš„è¾¹ï¼Ÿ
A2: åœ¨FedSageçš„åŸºç¡€ä¸Šæ·»åŠ ä¸€ä¸ªé‚»å±…ç”Ÿæˆå™¨ã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†å¾—åˆ°missing neighbor generatorï¼Œæ¯ä¸ªclienté¦–å…ˆé€šè¿‡éšæœºç§»é™¤ä¸€äº›èŠ‚ç‚¹å’Œä»–ä»¬çš„è¾¹æ¥æŸåsubgraphï¼Œç„¶ååŸºäºæŸåçš„å›¾æ¥å’Œç§»é™¤çš„èŠ‚ç‚¹æ¥è®­ç»ƒé‚»å±…ç”Ÿæˆå™¨ã€‚é‚»å±…ç”Ÿæˆå™¨ä¸ä»…ä¸ºå­å›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆmissing neighbor numberï¼Œä¹Ÿä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿäº§missing neighbor featuresã€‚ç„¶åç”¨ç”Ÿæˆçš„èŠ‚ç‚¹é‚»å±…å»ä¿®è¡¥subgraphï¼Œæ‰€è°“æ¨¡æ‹Ÿçš„è·¨å­å›¾äº¤äº’ã€‚æœ€ååœ¨ä¿®è¡¥å¥½çš„å­å›¾ä¸Šä½¿ç”¨FedSageã€‚
Collaborative Learning on Isolated Subgraphsï¼šFedSage å¯¹äºä¸€ä¸ªè¢«æŸ¥è¯¢èŠ‚ç‚¹ $v\in V$ï¼Œä¸€ä¸ªå…¨å±€ $K$å±‚GraphSageåˆ†ç±»å™¨ $F$é€šè¿‡èåˆ $v$å’Œå®ƒçš„ $K$è·³é‚»å±…æ¥å¾—åˆ°èŠ‚ç‚¹çš„é¢„æµ‹å€¼ï¼Œå…¶ä¸­æ¯å±‚çš„å¯å­¦ä¹ å‚æ•°ä¸º $\phi = \{\phi^k\}^K_{k = 1}$ï¼Œå…¶ä¸­ $\phi^k$è¡¨ç¤ºç¬¬ $k$å±‚çš„æƒé‡çŸ©é˜µã€‚è€ƒè™‘ä¸€ä¸ªå­å›¾ $G_i = \{V_i, E_i, X_i\}$ï¼Œ GraphSageé€šè¿‡ä¸€ä¸‹å¼å­è®¡ç®—èŠ‚ç‚¹ $v \in V_i$çš„ç¬¬ $k \in [K]$å±‚è¡¨ç¤ºï¼š
$$ h_v^k=\sigma\left(\phi^k \cdot\left(h_v^{k-1} || \operatorname{Agg}\left(\left\{h_u^{k-1}, \forall u \in \mathcal{N}_{G_i}(v)\right\}\right)\right)\right) $$
å…¶ä¸­ $\mathcal{N}_{G_i}(v)$è¡¨ç¤ºèŠ‚ç‚¹ $v$åœ¨å­å›¾ $G_i$ä¸­çš„é‚»å±…ï¼Œä¸Šå¼è¡¨ç¤ºé‚»å±…èŠ‚ç‚¹èšåˆåå’Œä¸­å¿ƒèŠ‚ç‚¹æ‹¼æ¥ï¼Œç„¶åå†ç”¨å‚æ•° $\phi^k$åšå˜æ¢åå¾—åˆ°ä¸­å¿ƒèŠ‚ç‚¹çš„è¡¨ç¤ºã€‚
åœ¨FedSageä¸­ï¼Œå…¨å±€æ¨¡å‹ $F$çš„å‚æ•° $\phi$é€šè¿‡ $e_c$æ¬¡è®­ç»ƒè¿­ä»£å¾—åˆ°ã€‚åœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ $t$ä¸­ï¼Œæ¯ä¸ªclient $D_i$é¦–å…ˆæ‹·è´å…¨å±€å‚æ•° $\phi$åˆ°æœ¬åœ°ï¼Œä½œä¸ºæœ¬åœ°æ¨¡å‹çš„åˆå§‹å‚æ•°ï¼Œå†åŸºäºè‡ªèº«çš„æ•°æ®æ›´æ–°å‚æ•° $\phi_i$ï¼š
...</p></section><footer class=entry-footer><span title='2025-05-18 14:59:38 +0800 +08'>May 18, 2025</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to NeurIPS2021ã€ŠSubgraph Federated Learning with Missing Neighbor Generationã€‹Reading Notes" href=https://JhuoW.github.io/posts/fedsage/></a></article><article class=post-entry><header class=entry-header><h2>LLMs and Graphs</h2></header><section class=entry-content><p>1. Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning (TAPE) Shallow model: Encoding the textual attributes using shallow or hand-crafted features such as skip-gram or bag-of-words (BoW) which used in PgG and DGL are limited in the complexity of the semantic features they can capture.
LM: æŒ‡ç›¸å¯¹è¾ƒå°å¹¶ä¸”å¯ä»¥è¢«fine-tuneçš„æ¨¡å‹ã€‚GIANT fine-tune an LM using neighborhood prediction task ï¼ˆåœ¨neighborhood prediction taskä¸Šæ¥å¾®è°ƒLMæ¨¡å‹ï¼‰. GLEM fine-tune an LM to predict the label distribution from GNNâ€™s output (GLEM ç”¨GNNé¢„æµ‹çš„ä¼ªæ ‡ç­¾ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œè®©LMæ¥fine tune èŠ‚ç‚¹çš„æ–‡æœ¬è¡¨ç¤º)ã€‚è¿™äº›å·¥ä½œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œå¹¶ä¸”ç”±äºè¦å¾®è°ƒæ¨¡å‹çš„å‚æ•°ï¼Œæ‰€ä»¥é€‰å–çš„LMç›¸å¯¹è¾ƒå°ï¼Œæ¯”å¦‚BERTå’ŒDeBERTaï¼Œå› æ­¤ç¼ºä¹LLMçš„æ¨ç†èƒ½åŠ›ã€‚
...</p></section><footer class=entry-footer><span title='2024-05-25 01:04:50 +0800 +08'>May 25, 2024</span>&nbsp;Â·&nbsp;5 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to LLMs and Graphs" href=https://JhuoW.github.io/posts/graphllm/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2023ã€ŠOrdered GNNï¼šOrdering Message Passing to Deal with Heterophily and Over-smoothingã€‹ Reading Nodes</h2></header><section class=entry-content><p>paper
Introduction å¤šå±‚message passingåï¼ŒGNNä¼šå¯¼è‡´Over-smoothingä½¿å¾—èŠ‚ç‚¹è¡¨ç¤ºè¶‹åŒã€‚å¦ä¸€æ–¹é¢ï¼Œæ ‡ç­¾ä¸åŒçš„ç›¸é‚»èŠ‚ç‚¹ç‰¹å¾ä¼šæ··åˆï¼Œå¯¼è‡´ä¸åŒæ ‡ç­¾èŠ‚ç‚¹è¾¹çš„éš¾ä»¥åŒºåˆ†ï¼Œå³Heterophilyé—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæå‡ºå¯¹ä¼ é€’åˆ°èŠ‚ç‚¹çš„messageè¿›è¡Œæ’åºï¼Œå³è¡¨ç¤ºå‘é‡çš„ç‰¹å®šneuronå—ç¼–ç ç‰¹å®šhopçš„æ¶ˆæ¯ã€‚é€šè¿‡å°†èŠ‚ç‚¹rooted computation treeçš„å±‚æ¬¡å’Œè¡¨ç¤ºå‘é‡neuron å—å¯¹é½ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œ3å±‚GNNå¯¹èŠ‚ç‚¹$v$çš„è¾“å‡º$h_v^{(3)}$çš„å‰$P_v^{(0)}$ä¸ªneurons ç¼–ç 1 hopé‚»å±…ä¿¡æ¯ï¼Œ$[P_v^{(0)}, P_v^{(1)}]$ç¼–ç äº†ç¬¬1å±‚å¦æ®çš„ä¿¡æ¯ã€‚é€šè¿‡ä»¥ç¡®å®šçš„é¡ºåºç¼–ç é‚»å±…ä¿¡æ¯ï¼Œæ¥é¿å…hopsçš„ç‰¹å¾èåˆï¼Œå³ä¸€ä¸ªèŠ‚ç‚¹çš„embeddingçš„ç¥ç»å…ƒè¦å’Œè®¡ç®—ä¹¦çš„å±‚æ¬¡å¯¹é½ï¼Œä¸åŒå±‚åˆ†é…ä¸åŒçš„neuronã€‚ä¹Ÿå°±æ˜¯æŒ‰ç…§é¡ºåºå°†ä¸åŒå±‚çš„é‚»å±…ä¿¡æ¯ç¼–ç åˆ°æœ€ç»ˆè¡¨ç¤º$h_v^{(k)}$çš„ä¸åŒç»´åº¦åŒºé—´ä¸­ã€‚
Approach Aligning Rooted-Tree with Node Embedding å¯¹äºä¸€ä¸ªèŠ‚ç‚¹$v$ï¼Œæ˜¾ç„¶å®ƒçš„ç¬¬$k-1$å±‚rooted-tree $\mathcal{T}^{(k-1)}_v$æ˜¯$k$å±‚rooted-tree $\mathcal{T}^{(k)}_v$çš„å­æ ‘: $$ \mathcal{T}_v^{(0)} \subseteq \mathcal{T}_v^{(1)} \subseteq \cdots \subseteq \mathcal{T}_v^{(k)} \subseteq \cdots \subseteq \mathcal{T}_v^{(K)} $$ éšç€$k$çš„å¢åŠ ï¼Œ$\mathcal{T}_v^{(K)}$ä¼šå˜å¾—è¶Šæ¥è¶Šå¤§ä¸”å¤æ‚ï¼Œä¸”åŒ…å«ä¹‹å‰å±‚çš„æ‰€æœ‰ä¿¡æ¯ã€‚æ‰€ä»¥$\mathcal{T}_v^{(K)}$éœ€è¦æ›´å¤šneuron (æœ€ç»ˆè¡¨ç¤ºå‘é‡$h_v^{(k)}$ä¸­çš„ç»´åº¦) æ¥ç¼–ç ä¿¡æ¯ã€‚ç”±äº$\mathcal{T}_v^{(k-1)}$æ˜¯$\mathcal{T}_v^{(k)}$çš„å­æ ‘ï¼Œæ‰€ä»¥åœ¨è¡¨ç¤ºå‘é‡$h_v^{(k)}$ä¸­ï¼Œç¼–ç tree $\mathcal{T}_v^{(k)}$ä¿¡æ¯çš„neuronsè¦åŒ…å«ç¼–ç  tree$\mathcal{T}_v^{(k-1)}$ä¿¡æ¯çš„neuronsã€‚å…·ä½“æ¥è¯´ï¼Œå…³äºèŠ‚ç‚¹$v$çš„$k-1$å±‚rooted-tree $\mathcal{T}_v^{(k-1)}$ï¼Œå®ƒçš„ä¿¡æ¯ä¼šè¢«ç¼–ç åˆ°$h_v^{(K)}$çš„å‰$P_v^{(k-1)}$ä¸ªneuronä¸­ï¼ˆç»´åº¦ï¼‰ï¼Œå¯¹äºä¸‹ä¸€ä¸ªå±‚æ¬¡çš„rooted-tree $\mathcal{T}_v^{(k)}$ï¼Œå®ƒä¼šè¢«ç¼–ç åˆ°$h_v^{(K)}$çš„å‰$P_v^{(k)}$ä¸ªneuronï¼ˆç»´åº¦ï¼‰ä¸­ã€‚å› ä¸º$\mathcal{T}_v^{(k-1)}$æ˜¯$\mathcal{T}_v^{(k)}$çš„å­æ ‘ï¼Œæ‰€ä»¥$P_v^{(k-1)} \leq P_v^{(k)}$ã€‚ $v$çš„$K$å±‚æœ€ç»ˆè¡¨ç¤º$h_v^{(K)}$ï¼Œå®ƒçš„æ¯ä¸ªç»´åº¦æ˜¯ä¸€ä¸ªneuronï¼Œå‰$P_v^{(k-1)}$ä¸ªneuronsç¼–ç äº†å‰$k-1$ hopé‚»å±…çš„ä¿¡æ¯ï¼Œå‰$P_v^{(k)}$ä¸ªneuronsç¼–ç äº†å‰$k$ hopé‚»å±…çš„ä¿¡æ¯ï¼Œ åœ¨ä¸¤ä¸ªåˆ†å‰²ç‚¹$P_v^{(k-1)}$å’Œ$P_v^{(k)}$ä¹‹é—´çš„neuronsè¦ç¼–ç çš„æ˜¯ç¬¬$k$ hopé‚»å±…çš„ä¿¡æ¯ã€‚æ‰€ä»¥èŠ‚ç‚¹$v$åœ¨$K$å±‚GNNä¸‹çš„æœ€ç»ˆembedding$h_v^{(K)} \in \mathbb{R}^D$ ä¼šè¢«$K+1$ä¸ªåˆ†å‰²ç‚¹åˆ†æˆ$K+1$å—ï¼Œå…¶ä¸­å‰$P_v^{(0)}$ä¸ªneuronsç¼–ç çš„æ˜¯èŠ‚ç‚¹$v$çš„è‡ªèº«ä¿¡æ¯ï¼Œ$P_v^{(k)}$ä¸º$h_v^{(K)}$çš„split pointï¼Œä¸”ï¼š $$ P_v^{(0)} \leq P_v^{(1)} \leq \cdots \leq P_v^{(k)} \leq \cdots \leq P_v^{(K)} = D $$
The Split Point åˆ†å‰²ç‚¹$P_v^{(k)}$æ˜¯ä¸€ä¸ªindexï¼Œä¼šå°†$D$ç»´node embedding åˆ†ä¸º2å—ï¼Œ$[0, P_v^{(k)}-1]$çš„neuronsç¼–ç äº†å‰$k$å±‚é‚»å±…çš„ä¿¡æ¯ã€‚ å®šä¹‰ä¸€ä¸ª$D$ç»´gatingå‘é‡$g^{(k)}_v = [1,1,1,1,1,1,0,0,0,0,0]$å…¶ä¸­å‰$P_v^{(k)}$ä¸ªentriesæ˜¯1ï¼Œ åé¢ä¸º0ï¼Œå³ç­›é€‰å‡ºå‰$k$å±‚è¦ç¼–ç è¿›çš„neuronsï¼š $$ h_v^{(k)}=g_v^{(k)} \circ h_v^{(k-1)}+\left(1-g_v^{(k)}\right) \circ m_v^{(k)} $$ å…¶ä¸­ç¬¬$k$å±‚çš„ä¿¡æ¯$h_v^{(k-1)}$ä¿ç•™åœ¨ç¬¬$k+1$å±‚embedding $h_v^{(k)}$çš„å‰$P_v^{(k)}$ä¸ªneuronä¸­ï¼Œè€Œ$h_v^{(k)}$çš„åé¢éƒ¨åˆ†neuronç¼–ç æ–°èšåˆçš„é‚»å±…ä¿¡æ¯ï¼Œé€šè¿‡è¿™ç§æ–¹å¼ï¼Œå°†æ¯ä¸€ä¸ªhopçš„ä¿¡æ¯åˆ†å¼€ã€‚ å†ä¸‹ä¸€å±‚æ—¶ï¼Œ $h_v^{(k)}$çš„ä¿¡æ¯å°±ä¼šè¢«ç¼–ç åˆ°$D$ä¸ªneuronsä¸­çš„å‰$P_v^{(k+1)}$ä¸ªneuronä¸­ï¼Œé‚£ä¹ˆå…¶å®$P_v^{(k)}$åˆ°$P_v^{(k+1)}$ä¹‹é—´çš„neuronå®é™…ä¸ŠåªåŒ…å«äº†$m_v^{(k)}$çš„ä¿¡æ¯ï¼Œå³ç¬¬$k$ä¸ªhopçš„ä¿¡æ¯ã€‚ä»¥è¿™ç§æ–¹å¼å°†æ¯ä¸€ä¸ªhopçš„é‚»å±…ä¿¡æ¯æŒ‰é¡ºåºç¼–ç åˆ°æœ€ç»ˆè¡¨ç¤ºå‘é‡$h_v^{(K)}$ä¸­ã€‚
...</p></section><footer class=entry-footer><span title='2023-07-16 17:47:14 +0800 +08'>July 16, 2023</span>&nbsp;Â·&nbsp;1 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2023ã€ŠOrdered GNNï¼šOrdering Message Passing to Deal with Heterophily and Over-smoothingã€‹ Reading Nodes" href=https://JhuoW.github.io/posts/orderedgnn/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2023ã€ŠMLPInitï¼šEmbarrassingly Simple GNN Training Acceleration with MLP Initializationã€‹ Reading Nodes</h2></header><section class=entry-content><p>paper
GNNä¸­çš„å±‚æ¬¡å åŠ éœ€è¦ç¨€ç–çŸ©é˜µä¹˜æ³•è®¡ç®—å¸¦æ¥è¾ƒå¤§çš„è®¡ç®—å¼€é”€ï¼Œè€ŒMLPä»…ä½¿ç”¨node featureå¯ä»¥é¿å…æ­¤é—®é¢˜ã€‚æœ¬æ–‡å‘ç°å¤§å¤šæ•°message-passingé€šè¿‡å°†è®­ç»ƒå‚æ•°è®¾ç½®ä¸ºç›¸åŒshapeï¼Œå¯ä»¥æ¨å¯¼å‡ºç­‰æ•ˆçš„MLPï¼ˆPeerMLPï¼‰ï¼Œè€Œä½¿ç”¨PeerMLPæ¥ä½œä¸ºGNNçš„åˆå§‹åŒ–å‚æ•°å¯ä»¥ç›¸è¾ƒäºä»…ä½¿ç”¨PeerMLPï¼Œæ•ˆæœæå‡æå¤§ã€‚
ä»ä¸Šå›¾çš„è“çº¿å¯ä»¥çœ‹å‡ºï¼ŒGNNé€šå¸¸éœ€è¦æ›´å¤šçš„è®­ç»ƒè¿­ä»£æ¬¡æ•°æ‰å¯ä»¥è¾¾åˆ°æ”¶æ•›ï¼Œå› ä¸ºå…¶ä¸­æ¶‰åŠå¤æ‚çš„ç¨€ç–çŸ©é˜µä¹˜æ³•è®¡ç®—ã€‚è€ŒMLPä¸ä½¿ç”¨ç»“æ„ä¿¡æ¯ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå› æ­¤æœ¬æ–‡å‘ç°MLPå’ŒGNNå¯ä»¥æœ‰ç›¸åŒçš„è®­ç»ƒæƒé‡ç©ºé—´ï¼Œå› æ­¤ Can we train GNNs more efficiently by leveraging the weights ofconverged MLPs? æœ¬æ–‡è¿›ä¸€æ­¥å‘ç°ï¼Œå¯¹äºä¸€ä¸ªGNNå’Œå®ƒå¯¹åº”çš„PeerMLP ï¼ˆç›¸åŒçš„weightï¼‰ï¼Œåœ¨PeerMLPä¸Šè®­ç»ƒçš„æƒé‡å¯ä»¥ä¼˜åŒ–GNNã€‚åŸºäºè¯¥å‘ç°ï¼Œå›¾ä¸Šè®­ç»ƒå¥½çš„PeerMLPä½œä¸ºGNNçš„æƒé‡çŸ©é˜µ$W$, ç„¶åå†è€ƒè™‘ç»“æ„ä¿¡æ¯ï¼Œå¯ä»¥å‘ç°GNNçš„æ•ˆæœç›¸è¾ƒäºPeerMLPæœ‰å¾ˆå¤§çš„æå‡ã€‚ å¦‚è¡¨2æ‰€ç¤ºï¼Œå…¶ä¸­PeerMLPå’ŒGNNæœ‰ç›¸åŒçš„æƒé‡ç©ºé—´ï¼Œé¦–å…ˆåœ¨å›¾ä¸Šè®­ç»ƒPeerMLPï¼Œå¾—åˆ°æ”¶æ•›æ—¶çš„æœ€æœ‰å‚æ•°$w^\star_{mlp}$ï¼ŒPeerMLPçš„é¢„æµ‹ç»“æœä¸º$f_{m l p}\left(\mathbf{X} ; w_{m l p}^\star\right)$ï¼Œ ç„¶åç›´æ¥ä½¿ç”¨ä¸è®­ç»ƒè€Œç›´æ¥ä½¿ç”¨$w_{m l p}^\star$ä½œä¸ºGNNçš„å‚æ•°ï¼Œå³$f_{g n n}\left(\mathbf{X}, \mathbf{A} ; w_{m l p}^\star\right)$,å¯ä»¥çœ‹å‡ºï¼Œåœ¨è€ƒè™‘å›¾ç»“æ„åï¼ŒGNNå³ä½¿ä¸è®­ç»ƒï¼Œç›´æ¥ä½¿ç”¨PeerMLPçš„æƒé‡çŸ©é˜µï¼Œæ•ˆæœä¹Ÿæœ‰å·¨å¤§æå‡ã€‚
å—æ­¤å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†ç”¨æ”¶æ•›çš„PeerMLPæœ€ä¼˜æƒé‡çŸ©é˜µï¼Œä½œä¸ºGNNçš„åˆå§‹åŒ–æƒé‡ã€‚ä»å›¾1çš„çº¢çº¿å¯ä»¥çœ‹å‡ºï¼Œç›¸è¾ƒäºéšæœºåˆå§‹åŒ–çš„GNNï¼ŒMLPInitåˆå§‹åŒ–çš„GNNåœ¨æ›´å°‘çš„epochåˆ°è¾¾æ”¶æ•› å¹¶ä¸”å¯ä»¥è¾¾åˆ°å’Œç›¸ä¼¼çš„å‡†ç¡®ç‡ã€‚
ä»ä¸Šè¡¨å¯ä»¥çœ‹å‡ºGNNçš„Propagationæ“ä½œ$AZ$çš„å‰å‘è®¡ç®—å’Œåå‘æ¢¯åº¦ä¼ æ’­çš„è€—æ—¶éƒ½è¿œè¿œè¶…è¿‡Feature Transformationæ“ä½œ$WX$ã€‚Feature Trançš„æ“ä½œç›¸å¯¹ä¸Propagationï¼Œè®¡ç®—æˆæœ¬å‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œæ‰€ä»¥å¦‚æœé¢„è®­ç»ƒæ“ä½œå¾—åˆ°çš„$W$å¯ä»¥ä½¿å¾—è®­ç»ƒGNNæ—¶çš„epochå¤§å¹…ä¸‹é™ï¼Œå¯ä»¥ä½¿æ¨¡å‹æ›´åŠ é«˜æ•ˆã€‚å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œè®­ç»ƒPeerMLPçš„æ—¶é—´å†åŠ ä¸Šçš„æƒé‡è¿ç§»åˆ°GNNåçš„fine-tuningæ—¶é—´ï¼Œ è¿œå°‘äºåœ¨GNNä¸Šç›´æ¥è®­ç»ƒéšæœºåˆå§‹åŒ–å‚æ•°çš„æ—¶é—´ã€‚
ä»ä¸‹å›¾åŒæ ·å¯ä»¥çœ‹å‡ºPeerMLPçš„å‚æ•°$w_{mlp}$çš„è®­ç»ƒè¶‹åŠ¿ï¼ŒPeerMLPè®­ç»ƒè¿‡ç¨‹ä¸­æ¯ä¸ªepochçš„$w_{mlp}$ç›´æ¥è¿ç§»åˆ°GNNä¸Šè®¡ç®—CEæŸå¤±ï¼Œå¯ä»¥å‘ç°ä½¿å¾—MLP çš„CE Lossä¸‹é™çš„$w_{mlp}$åŒæ ·å¯ä»¥ä½¿å¾—GNNä»¥åŒæ ·çš„è¶‹åŠ¿ä¸‹é™ã€‚</p></section><footer class=entry-footer><span title='2023-07-15 15:43:09 +0800 +08'>July 15, 2023</span>&nbsp;Â·&nbsp;1 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2023ã€ŠMLPInitï¼šEmbarrassingly Simple GNN Training Acceleration with MLP Initializationã€‹ Reading Nodes" href=https://JhuoW.github.io/posts/mlpinit/></a></article><article class=post-entry><header class=entry-header><h2>Fraud Detection based on Graph Neural Networks</h2></header><section class=entry-content><p>1. Label Information Enhanced Fraud Detection against Low Homophily in Graphs (WWW â€˜23) Introduction GNN4FDå­˜åœ¨é—®é¢˜ï¼š å¤§å¤šæ•°åŸºäºGNNçš„æ¬ºè¯ˆæ£€æµ‹å™¨éš¾ä»¥æ³›åŒ–åˆ°low homophilyç½‘ç»œä¸­ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œå¦‚ä½•å……åˆ†åˆ©ç”¨labelä¿¡æ¯ä¹Ÿæ˜¯Fraud detectionçš„é‡è¦å› ç´ ã€‚å³å¦‚æœä¸€ä¸ªFraud nodeçš„é‚»å±…éƒ½æ˜¯benign nodesï¼Œé‚£ä¹ˆè¿™æ ·çš„å›¾å°±æ˜¯heterophily or low homophily graphï¼Œç”±äºGNNçš„neighborhood aggregationæœºåˆ¶ï¼Œtarget nodeçš„è¡¨ç¤ºä¼šå’Œå®ƒçš„é‚»å±…ç›¸ä¼¼ï¼Œæ— è®ºä»–ä»¬çš„labelæ˜¯å¦ä¸åŒï¼Œè¿™æ ·ä¼šä½¿å¾—GNNéš¾ä»¥åŒºåˆ†ä½äºå¼‚è´¨é‚»åŸŸå†…çš„Fraud nodesã€‚å¦å¤–ï¼Œ ç°æœ‰çš„GNN4FDæ–¹æ³•åˆ©ç”¨labelä¿¡æ¯çš„èƒ½åŠ›æœ‰é™ï¼Œè¿™äº›æ–¹æ³•ä»…åœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨labelä¿¡æ¯ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œä½†æ˜¯åœ¨è®¾è®¡message passing æœºåˆ¶çš„è¿‡ç¨‹ä¸­å¹¶æ²¡æœ‰ä½¿ç”¨labelä¿¡æ¯ã€‚
ä¸ºäº†è§£å†³ä¸Šè¿°2ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºGAGA: åŸºäºåˆ†ç»„èšåˆçš„Transformerã€‚ GAGAé¦–å…ˆæå‡ºäº†ä¸€ç§é¢„å¤„ç†ç­–ç•¥Group Aggregation (GA, åˆ†ç»„èšåˆ)ï¼Œç„¶åæ¯ä¸ªèŠ‚ç‚¹çš„åŸå§‹é‚»å±…ç‰¹ç‰¹å¾è¢«åˆ†ç»„ä¸ºåºåˆ—æ•°æ®ã€‚ ç„¶åæå‡ºä¸€ç§ç§‘å­¦ç³»çš„ç¼–ç æ–¹å¼æ¥ç¼–ç structuralï¼Œrelational å’Œlabelä¿¡æ¯ ï¼ˆå…¨å±€ï¼‰ï¼Œå³æ•´ä¸ªå›¾çš„relational encodingï¼Œgroup encoding å’Œ hop encoding ï¼ˆå›¾ä¸­åˆå‡ ä¸ªrelationå°±æœ‰å‡ ä¸ªrelational embeddingï¼Œå–å‡ ä¸ªhopå°±åˆå‡ ä¸ªhop embedding..ï¼‰ã€‚ æœ€åç”¨å¤šå¤´attentionä¸ºæ¯ä¸ªèŠ‚ç‚¹èšåˆembedding sequence.
Preliminaries Multi-relational fraud graph construction Multi-relational fraud graph $\mathcal{G}(\mathcal{V}, \mathcal{E}, \mathcal{X}, \mathcal{Y})$, å…¶ä¸­èŠ‚ç‚¹é›†$\mathcal{V}=\left\{v_1, v_2, \ldots, v_N\right\}(N=|\mathcal{V}|)$ï¼Œ$R$ ä¸ªé‚»æ¥çŸ©é˜µ$\mathcal{E}=\left\{\mathbf{A}_1, \mathbf{A}_2, \ldots, \mathbf{A}_R\right\}(R=|\mathcal{E}|)$çš„å¤šå…³ç³»å›¾ ï¼ˆ$R$ä¸ªå…³ç³»ï¼‰ã€‚èŠ‚ç‚¹feature vectors $X=\left\{\mathbf{x}_1, \mathrm{x}_2, \ldots, \mathrm{x}_N\right\}$ä»¥åŠèŠ‚ç‚¹çš„labelé›†åˆ$\mathcal{Y}$ã€‚ å¯¹äºä¸€ä¸ªrelationçš„é‚»æ¥çŸ©é˜µ$\mathbf{A}_r$ï¼Œå¦‚æœ$\mathbf{A}_1[u,v]=1$ï¼Œé‚£ä¹ˆåœ¨å…³ç³»$r$ä¸‹èŠ‚ç‚¹$u$å’Œ$v$è¢«è¿æ¥ã€‚æ¯ä¸ªèŠ‚ç‚¹$v \in \mathcal{V}$ æœ‰ä¸€ä¸ª$d$ç»´feature vector $\mathbf{x}_v \in \mathbb{R}^d$ã€‚ åœ¨åŸºäºGraphçš„fraud detectionä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘åŠç›‘ç£åœºæ™¯ï¼Œå…¶ä¸­ä¸€å°éƒ¨åˆ†èŠ‚ç‚¹ $\hat{\mathcal{V}} \supset \mathcal{V}$æ˜¯æœ‰labelçš„ ï¼ˆ$y=1$è¡¨ç¤ºè¯¥èŠ‚ç‚¹ä¸ºfraud nodeï¼Œ$y=0$è¡¨ç¤ºè¯¥èŠ‚ç‚¹ä¸ºbenign nodeï¼‰æ‰€ä»¥å¯¹äºfraud graphï¼ŒèŠ‚ç‚¹classæ•°ä¸º2ã€‚
...</p></section><footer class=entry-footer><span title='2023-05-13 16:14:56 +0800 +08'>May 13, 2023</span>&nbsp;Â·&nbsp;6 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to Fraud Detection based on Graph Neural Networks" href=https://JhuoW.github.io/posts/fd/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://JhuoW.github.io/page/2/>Next Page Â»</a></nav></footer></main><footer class=footer><span>Copyright &copy; 2025 <a href=https://JhuoW.github.io/>JhuoWâ€˜s Notes</a></span>
<span></span><br><script>function siteTime(){var h=1e3,r=h*60,i=r*60,n=i*24,x=n*365,e=new Date,d=2019,w=1,_=16,y=19,b=15,C=11,l=e.getFullYear(),O=e.getMonth()+1,f=e.getDate(),p=e.getHours(),g=e.getMinutes(),v=e.getSeconds(),m=Date.UTC(d,w,_,y,b,C),j=Date.UTC(l,O,f,p,g,v),t=j-m,o=Math.floor(t/x),s=Math.floor(t/n-o*365),a=Math.floor((t-(o*365+s)*n)/i),c=Math.floor((t-(o*365+s)*n-a*i)/r),u=Math.floor((t-(o*365+s)*n-a*i-c*r)/h);d==l?document.getElementById("sitetime").innerHTML="æœ¬ç«™å·²è¿è¡Œ "+s+" å¤© "+a+" å°æ—¶ "+c+" åˆ†é’Ÿ "+u+" ç§’":document.getElementById("sitetime").innerHTML="æœ¬ç«™å·²è¿è¡Œ "+o+" å¹´ "+s+" å¤© "+a+" å°æ—¶ "+c+" åˆ†é’Ÿ "+u+" ç§’"}setInterval(siteTime,1e3)</script><span id=sitetime>è½½å…¥è¿è¡Œæ—¶é—´...</span>
<script type=text/javascript id=clustrmaps src="//cdn.clustrmaps.com/map_v2.js?cl=080808&w=268&t=tt&d=YsONH-MzO6L7yrkA73Z_QW7LuMTfdUhk0uhb_KaBv-g&co=f5f5f5&cmo=3acc3a&cmn=ff5353&ct=808080"></script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>