<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.95.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script type=text/javascript async src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var t=MathJax.Hub.getAllJax(),e;for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><title>JhuoWâ€˜s Notes</title><meta name=keywords content="Blog,Portfolio,PaperMod"><meta name=description content="Jhuoâ€™s Notes"><meta name=author content="JhuoW"><link rel=canonical href=https://JhuoW.github.io/><meta name=google-site-verification content="G-6F49SGED6V"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><link rel=preload href=/apple-touch-icon.png as=image><link rel=icon href=https://JhuoW.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://JhuoW.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://JhuoW.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://JhuoW.github.io/apple-touch-icon.png><link rel=mask-icon href=https://JhuoW.github.io/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://JhuoW.github.io/index.xml><link rel=alternate type=application/json href=https://JhuoW.github.io/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-6F49SGED6V"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6F49SGED6V",{anonymize_ip:!1})}</script><meta property="og:title" content="JhuoWâ€˜s Notes"><meta property="og:description" content="Jhuoâ€™s Notes"><meta property="og:type" content="website"><meta property="og:url" content="https://JhuoW.github.io/"><meta property="og:image" content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="JhuoW"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="JhuoWâ€˜s Notes"><meta name=twitter:description content="Jhuoâ€™s Notes"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"JhuoWâ€˜s Notes","url":"https://JhuoW.github.io/","description":"Jhuoâ€™s Notes","thumbnailUrl":"https://JhuoW.github.io/favicon.ico","sameAs":["https://github.com/JhuoW","mailto:jhuow@proton.me","https://t.me/funjhuow","https://open.spotify.com/playlist/0HMI5oRLTSYuZPYie7B1bG?si=f2ec0a118a8a4297","https://gitlab.com/JhuoW","https://arxiv.gtflashlab.com/","https://JhuoW.github.io/index.xml","https://github.com/The-Run-Philosophy-Organization/run","https://aideadlin.es/?sub=ML,CV,CG,NLP,RO,SP,DM"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://JhuoW.github.io/ accesskey=h title="JhuoW's Notes (Alt + H)"><img src=https://JhuoW.github.io/apple-touch-icon.png alt=logo aria-label=logo height=35>JhuoW's Notes</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://JhuoW.github.io/about/ title=About><span>About</span></a></li><li><a href=https://JhuoW.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://JhuoW.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://JhuoW.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://JhuoW.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>ğŸ’Ÿ Welcome to JhuoW&rsquo;s Notebook ğŸŒ»</h1></header><section class=entry-content><p><p>Hey, this is JhuoW. I use this blog to write notes about machine learning and AI conference papers.</p><ul><li>News:</li><li>[2024-03] <strong>I am on job market now! I&rsquo;m open for research positions in both academy and industry!</strong></li><li>[2024-01] One paper accepted by ICLR 2024.</li><li>[2023-05] One paper accepted by IEEE TNNLS.</li><li>[2022-09] One paper accepted by NeurIPS 2022.</li><li>[2022-04] One paper accepted by IJCAI 2022.</li></ul></p></section><footer class=entry-footer><div class=social-icons><a href=https://github.com/JhuoW target=_blank rel="noopener noreferrer me" title=Github><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a href=mailto:jhuow@proton.me target=_blank rel="noopener noreferrer me" title=Email><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 21" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a><a href=https://t.me/funjhuow target=_blank rel="noopener noreferrer me" title=Telegram><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21.198 2.433a2.242 2.242.0 00-1.022.215l-8.609 3.33c-2.068.8-4.133 1.598-5.724 2.21a405.15 405.15.0 01-2.849 1.09c-.42.147-.99.332-1.473.901-.728.968.193 1.798.919 2.286 1.61.516 3.275 1.009 4.654 1.472.509 1.793.997 3.592 1.48 5.388.16.36.506.494.864.498l-.002.018s.281.028.555-.038a2.1 2.1.0 00.933-.517c.345-.324 1.28-1.244 1.811-1.764l3.999 2.952.032.018s.442.311 1.09.355c.324.022.75-.04 1.116-.308.37-.27.613-.702.728-1.196.342-1.492 2.61-12.285 2.997-14.072l-.01.042c.27-1.006.17-1.928-.455-2.474a1.654 1.654.0 00-1.034-.407z"/></svg></a><a href="https://open.spotify.com/playlist/0HMI5oRLTSYuZPYie7B1bG?si=f2ec0a118a8a4297" target=_blank rel="noopener noreferrer me" title=Spotify><svg fill="currentcolor" stoke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 0C5.4.0.0 5.4.0 12s5.4 12 12 12 12-5.4 12-12S18.66.0 12 0zm5.521 17.34c-.24.359-.66.48-1.021.24-2.82-1.74-6.36-2.101-10.561-1.141-.418.122-.779-.179-.899-.539-.12-.421.18-.78.54-.9 4.56-1.021 8.52-.6 11.64 1.32.42.18.479.659.301 1.02zm1.44-3.3c-.301.42-.841.6-1.262.3-3.239-1.98-8.159-2.58-11.939-1.38-.479.12-1.02-.12-1.14-.6s.12-1.021.6-1.141C9.6 9.9 15 10.561 18.72 12.84c.361.181.54.78.241 1.2zm.12-3.36C15.24 8.4 8.82 8.16 5.16 9.301c-.6.179-1.2-.181-1.38-.721-.18-.601.18-1.2.72-1.381 4.26-1.26 11.28-1.02 15.721 1.621.539.3.719 1.02.419 1.56-.299.421-1.02.599-1.559.3z"/></svg></a><a href=https://gitlab.com/JhuoW target=_blank rel="noopener noreferrer me" title=Gitlab><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M22.65 14.39 12 22.13 1.35 14.39a.84.84.0 01-.3-.94l1.22-3.78 2.44-7.51A.42.42.0 014.82 2a.43.43.0 01.58.0.42.42.0 01.11.18l2.44 7.49h8.1l2.44-7.51A.42.42.0 0118.6 2a.43.43.0 01.58.0.42.42.0 01.11.18l2.44 7.51L23 13.45a.84.84.0 01-.35.94z"/></svg></a><a href=https://arxiv.gtflashlab.com/ target=_blank rel="noopener noreferrer me" title=Arxiv><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4v16a2 2 0 002 2h12a2 2 0 002-2V8.342a2 2 0 00-.602-1.43l-4.44-4.342A2 2 0 0013.56 2H6A2 2 0 004 4z"/><path d="M9 13h6"/><path d="M9 17h3"/><path d="M14 2v4a2 2 0 002 2h4"/></svg></a><a href=https://JhuoW.github.io/index.xml target=_blank rel="noopener noreferrer me" title=Rss><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a><a href=https://github.com/The-Run-Philosophy-Organization/run target=_blank rel="noopener noreferrer me" title=External-Link><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-external-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M11 7H6A2 2 0 004 9v9a2 2 0 002 2h9a2 2 0 002-2v-5"/><line x1="10" y1="14" x2="20" y2="4"/><polyline points="15 4 20 4 20 9"/></svg></a><a href="https://aideadlin.es/?sub=ML,CV,CG,NLP,RO,SP,DM" target=_blank rel="noopener noreferrer me" title=Other><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></a></div></footer></article><article class=post-entry><header class=entry-header><h2>ICLR2023ã€ŠOrdered GNNï¼šOrdering Message Passing to Deal with Heterophily and Over-smoothingã€‹ Reading Nodes</h2></header><section class=entry-content><p>paper
Introduction å¤šå±‚message passingåï¼ŒGNNä¼šå¯¼è‡´Over-smoothingä½¿å¾—èŠ‚ç‚¹è¡¨ç¤ºè¶‹åŒã€‚å¦ä¸€æ–¹é¢ï¼Œæ ‡ç­¾ä¸åŒçš„ç›¸é‚»èŠ‚ç‚¹ç‰¹å¾ä¼šæ··åˆï¼Œå¯¼è‡´ä¸åŒæ ‡ç­¾èŠ‚ç‚¹è¾¹çš„éš¾ä»¥åŒºåˆ†ï¼Œå³Heterophilyé—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæå‡ºå¯¹ä¼ é€’åˆ°èŠ‚ç‚¹çš„messageè¿›è¡Œæ’åºï¼Œå³è¡¨ç¤ºå‘é‡çš„ç‰¹å®šneuronå—ç¼–ç ç‰¹å®šhopçš„æ¶ˆæ¯ã€‚é€šè¿‡å°†èŠ‚ç‚¹rooted computation treeçš„å±‚æ¬¡å’Œè¡¨ç¤ºå‘é‡neuron å—å¯¹é½ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œ3å±‚GNNå¯¹èŠ‚ç‚¹$v$çš„è¾“å‡º$h_v^{(3)}$çš„å‰$P_v^{(0)}$ä¸ªneurons ç¼–ç 1 hopé‚»å±…ä¿¡æ¯ï¼Œ$[P_v^{(0)}, P_v^{(1)}]$ç¼–ç äº†ç¬¬1å±‚å¦æ®çš„ä¿¡æ¯ã€‚é€šè¿‡ä»¥ç¡®å®šçš„é¡ºåºç¼–ç é‚»å±…ä¿¡æ¯ï¼Œæ¥é¿å…hopsçš„ç‰¹å¾èåˆï¼Œå³ä¸€ä¸ªèŠ‚ç‚¹çš„embeddingçš„ç¥ç»å…ƒè¦å’Œè®¡ç®—ä¹¦çš„å±‚æ¬¡å¯¹é½ï¼Œä¸åŒå±‚åˆ†é…ä¸åŒçš„neuronã€‚ä¹Ÿå°±æ˜¯æŒ‰ç…§é¡ºåºå°†ä¸åŒå±‚çš„é‚»å±…ä¿¡æ¯ç¼–ç åˆ°æœ€ç»ˆè¡¨ç¤º$h_v^{(k)}$çš„ä¸åŒç»´åº¦åŒºé—´ä¸­ã€‚
Approach Aligning Rooted-Tree with Node Embedding å¯¹äºä¸€ä¸ªèŠ‚ç‚¹$v$ï¼Œæ˜¾ç„¶å®ƒçš„ç¬¬$k-1$å±‚rooted-tree $\mathcal{T}^{(k-1)}_v$æ˜¯$k$å±‚rooted-tree $\mathcal{T}^{(k)}_v$çš„å­æ ‘: $$ \mathcal{T}_v^{(0)} \subseteq \mathcal{T}_v^{(1)} \subseteq \cdots \subseteq \mathcal{T}_v^{(k)} \subseteq \cdots \subseteq \mathcal{T}_v^{(K)} $$ éšç€$k$çš„å¢åŠ ï¼Œ$\mathcal{T}_v^{(K)}$ä¼šå˜å¾—è¶Šæ¥è¶Šå¤§ä¸”å¤æ‚ï¼Œä¸”åŒ…å«ä¹‹å‰å±‚çš„æ‰€æœ‰ä¿¡æ¯ã€‚æ‰€ä»¥$\mathcal{T}_v^{(K)}$éœ€è¦æ›´å¤šneuron (æœ€ç»ˆè¡¨ç¤ºå‘é‡$h_v^{(k)}$ä¸­çš„ç»´åº¦) æ¥ç¼–ç ä¿¡æ¯ã€‚ç”±äº$\mathcal{T}_v^{(k-1)}$æ˜¯$\mathcal{T}_v^{(k)}$çš„å­æ ‘ï¼Œæ‰€ä»¥åœ¨è¡¨ç¤ºå‘é‡$h_v^{(k)}$ä¸­ï¼Œç¼–ç tree $\mathcal{T}_v^{(k)}$ä¿¡æ¯çš„neuronsè¦åŒ…å«ç¼–ç  tree$\mathcal{T}_v^{(k-1)}$ä¿¡æ¯çš„neuronsã€‚å…·ä½“æ¥è¯´ï¼Œå…³äºèŠ‚ç‚¹$v$çš„$k-1$å±‚rooted-tree $\mathcal{T}_v^{(k-1)}$ï¼Œå®ƒçš„ä¿¡æ¯ä¼šè¢«ç¼–ç åˆ°$h_v^{(K)}$çš„å‰$P_v^{(k-1)}$ä¸ªneuronä¸­ï¼ˆç»´åº¦ï¼‰ï¼Œå¯¹äºä¸‹ä¸€ä¸ªå±‚æ¬¡çš„rooted-tree $\mathcal{T}_v^{(k)}$ï¼Œå®ƒä¼šè¢«ç¼–ç åˆ°$h_v^{(K)}$çš„å‰$P_v^{(k)}$ä¸ªneuronï¼ˆç»´åº¦ï¼‰ä¸­ã€‚å› ä¸º$\mathcal{T}_v^{(k-1)}$æ˜¯$\mathcal{T}_v^{(k)}$çš„å­æ ‘ï¼Œæ‰€ä»¥$P_v^{(k-1)} \leq P_v^{(k)}$ã€‚ $v$çš„$K$å±‚æœ€ç»ˆè¡¨ç¤º$h_v^{(K)}$ï¼Œå®ƒçš„æ¯ä¸ªç»´åº¦æ˜¯ä¸€ä¸ªneuronï¼Œå‰$P_v^{(k-1)}$ä¸ªneuronsç¼–ç äº†å‰$k-1$ hopé‚»å±…çš„ä¿¡æ¯ï¼Œå‰$P_v^{(k)}$ä¸ªneuronsç¼–ç äº†å‰$k$ hopé‚»å±…çš„ä¿¡æ¯ï¼Œ åœ¨ä¸¤ä¸ªåˆ†å‰²ç‚¹$P_v^{(k-1)}$å’Œ$P_v^{(k)}$ä¹‹é—´çš„neuronsè¦ç¼–ç çš„æ˜¯ç¬¬$k$ hopé‚»å±…çš„ä¿¡æ¯ã€‚æ‰€ä»¥èŠ‚ç‚¹$v$åœ¨$K$å±‚GNNä¸‹çš„æœ€ç»ˆembedding$h_v^{(K)} \in \mathbb{R}^D$ ä¼šè¢«$K+1$ä¸ªåˆ†å‰²ç‚¹åˆ†æˆ$K+1$å—ï¼Œå…¶ä¸­å‰$P_v^{(0)}$ä¸ªneuronsç¼–ç çš„æ˜¯èŠ‚ç‚¹$v$çš„è‡ªèº«ä¿¡æ¯ï¼Œ$P_v^{(k)}$ä¸º$h_v^{(K)}$çš„split pointï¼Œä¸”ï¼š $$ P_v^{(0)} \leq P_v^{(1)} \leq \cdots \leq P_v^{(k)} \leq \cdots \leq P_v^{(K)} = D $$
The Split Point åˆ†å‰²ç‚¹$P_v^{(k)}$æ˜¯ä¸€ä¸ªindexï¼Œä¼šå°†$D$ç»´node embedding åˆ†ä¸º2å—ï¼Œ$[0, P_v^{(k)}-1]$çš„neuronsç¼–ç äº†å‰$k$å±‚é‚»å±…çš„ä¿¡æ¯ã€‚ å®šä¹‰ä¸€ä¸ª$D$ç»´gatingå‘é‡$g^{(k)}_v = [1,1,1,1,1,1,0,0,0,0,0]$å…¶ä¸­å‰$P_v^{(k)}$ä¸ªentriesæ˜¯1ï¼Œ åé¢ä¸º0ï¼Œå³ç­›é€‰å‡ºå‰$k$å±‚è¦ç¼–ç è¿›çš„neuronsï¼š $$ h_v^{(k)}=g_v^{(k)} \circ h_v^{(k-1)}+\left(1-g_v^{(k)}\right) \circ m_v^{(k)} $$ å…¶ä¸­ç¬¬$k$å±‚çš„ä¿¡æ¯$h_v^{(k-1)}$ä¿ç•™åœ¨ç¬¬$k+1$å±‚embedding $h_v^{(k)}$çš„å‰$P_v^{(k)}$ä¸ªneuronä¸­ï¼Œè€Œ$h_v^{(k)}$çš„åé¢éƒ¨åˆ†neuronç¼–ç æ–°èšåˆçš„é‚»å±…ä¿¡æ¯ï¼Œé€šè¿‡è¿™ç§æ–¹å¼ï¼Œå°†æ¯ä¸€ä¸ªhopçš„ä¿¡æ¯åˆ†å¼€ã€‚ å†ä¸‹ä¸€å±‚æ—¶ï¼Œ $h_v^{(k)}$çš„ä¿¡æ¯å°±ä¼šè¢«ç¼–ç åˆ°$D$ä¸ªneuronsä¸­çš„å‰$P_v^{(k+1)}$ä¸ªneuronä¸­ï¼Œé‚£ä¹ˆå…¶å®$P_v^{(k)}$åˆ°$P_v^{(k+1)}$ä¹‹é—´çš„neuronå®é™…ä¸ŠåªåŒ…å«äº†$m_v^{(k)}$çš„ä¿¡æ¯ï¼Œå³ç¬¬$k$ä¸ªhopçš„ä¿¡æ¯ã€‚ä»¥è¿™ç§æ–¹å¼å°†æ¯ä¸€ä¸ªhopçš„é‚»å±…ä¿¡æ¯æŒ‰é¡ºåºç¼–ç åˆ°æœ€ç»ˆè¡¨ç¤ºå‘é‡$h_v^{(K)}$ä¸­ã€‚...</p></section><footer class=entry-footer><span title="2023-07-16 17:47:14 +0800 CST">July 16, 2023</span>&nbsp;Â·&nbsp;1 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2023ã€ŠOrdered GNNï¼šOrdering Message Passing to Deal with Heterophily and Over-smoothingã€‹ Reading Nodes" href=https://JhuoW.github.io/posts/orderedgnn/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2023ã€ŠMLPInitï¼šEmbarrassingly Simple GNN Training Acceleration with MLP Initializationã€‹ Reading Nodes</h2></header><section class=entry-content><p>paper
GNNä¸­çš„å±‚æ¬¡å åŠ éœ€è¦ç¨€ç–çŸ©é˜µä¹˜æ³•è®¡ç®—å¸¦æ¥è¾ƒå¤§çš„è®¡ç®—å¼€é”€ï¼Œè€ŒMLPä»…ä½¿ç”¨node featureå¯ä»¥é¿å…æ­¤é—®é¢˜ã€‚æœ¬æ–‡å‘ç°å¤§å¤šæ•°message-passingé€šè¿‡å°†è®­ç»ƒå‚æ•°è®¾ç½®ä¸ºç›¸åŒshapeï¼Œå¯ä»¥æ¨å¯¼å‡ºç­‰æ•ˆçš„MLPï¼ˆPeerMLPï¼‰ï¼Œè€Œä½¿ç”¨PeerMLPæ¥ä½œä¸ºGNNçš„åˆå§‹åŒ–å‚æ•°å¯ä»¥ç›¸è¾ƒäºä»…ä½¿ç”¨PeerMLPï¼Œæ•ˆæœæå‡æå¤§ã€‚
ä»ä¸Šå›¾çš„è“çº¿å¯ä»¥çœ‹å‡ºï¼ŒGNNé€šå¸¸éœ€è¦æ›´å¤šçš„è®­ç»ƒè¿­ä»£æ¬¡æ•°æ‰å¯ä»¥è¾¾åˆ°æ”¶æ•›ï¼Œå› ä¸ºå…¶ä¸­æ¶‰åŠå¤æ‚çš„ç¨€ç–çŸ©é˜µä¹˜æ³•è®¡ç®—ã€‚è€ŒMLPä¸ä½¿ç”¨ç»“æ„ä¿¡æ¯ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå› æ­¤æœ¬æ–‡å‘ç°MLPå’ŒGNNå¯ä»¥æœ‰ç›¸åŒçš„è®­ç»ƒæƒé‡ç©ºé—´ï¼Œå› æ­¤ Can we train GNNs more efficiently by leveraging the weights ofconverged MLPs? æœ¬æ–‡è¿›ä¸€æ­¥å‘ç°ï¼Œå¯¹äºä¸€ä¸ªGNNå’Œå®ƒå¯¹åº”çš„PeerMLP ï¼ˆç›¸åŒçš„weightï¼‰ï¼Œåœ¨PeerMLPä¸Šè®­ç»ƒçš„æƒé‡å¯ä»¥ä¼˜åŒ–GNNã€‚åŸºäºè¯¥å‘ç°ï¼Œå›¾ä¸Šè®­ç»ƒå¥½çš„PeerMLPä½œä¸ºGNNçš„æƒé‡çŸ©é˜µ$W$, ç„¶åå†è€ƒè™‘ç»“æ„ä¿¡æ¯ï¼Œå¯ä»¥å‘ç°GNNçš„æ•ˆæœç›¸è¾ƒäºPeerMLPæœ‰å¾ˆå¤§çš„æå‡ã€‚ å¦‚è¡¨2æ‰€ç¤ºï¼Œå…¶ä¸­PeerMLPå’ŒGNNæœ‰ç›¸åŒçš„æƒé‡ç©ºé—´ï¼Œé¦–å…ˆåœ¨å›¾ä¸Šè®­ç»ƒPeerMLPï¼Œå¾—åˆ°æ”¶æ•›æ—¶çš„æœ€æœ‰å‚æ•°$w^\star_{mlp}$ï¼ŒPeerMLPçš„é¢„æµ‹ç»“æœä¸º$f_{m l p}\left(\mathbf{X} ; w_{m l p}^\star\right)$ï¼Œ ç„¶åç›´æ¥ä½¿ç”¨ä¸è®­ç»ƒè€Œç›´æ¥ä½¿ç”¨$w_{m l p}^\star$ä½œä¸ºGNNçš„å‚æ•°ï¼Œå³$f_{g n n}\left(\mathbf{X}, \mathbf{A} ; w_{m l p}^\star\right)$,å¯ä»¥çœ‹å‡ºï¼Œåœ¨è€ƒè™‘å›¾ç»“æ„åï¼ŒGNNå³ä½¿ä¸è®­ç»ƒï¼Œç›´æ¥ä½¿ç”¨PeerMLPçš„æƒé‡çŸ©é˜µï¼Œæ•ˆæœä¹Ÿæœ‰å·¨å¤§æå‡ã€‚
å—æ­¤å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†ç”¨æ”¶æ•›çš„PeerMLPæœ€ä¼˜æƒé‡çŸ©é˜µï¼Œä½œä¸ºGNNçš„åˆå§‹åŒ–æƒé‡ã€‚ä»å›¾1çš„çº¢çº¿å¯ä»¥çœ‹å‡ºï¼Œç›¸è¾ƒäºéšæœºåˆå§‹åŒ–çš„GNNï¼ŒMLPInitåˆå§‹åŒ–çš„GNNåœ¨æ›´å°‘çš„epochåˆ°è¾¾æ”¶æ•› å¹¶ä¸”å¯ä»¥è¾¾åˆ°å’Œç›¸ä¼¼çš„å‡†ç¡®ç‡ã€‚
ä»ä¸Šè¡¨å¯ä»¥çœ‹å‡ºGNNçš„Propagationæ“ä½œ$AZ$çš„å‰å‘è®¡ç®—å’Œåå‘æ¢¯åº¦ä¼ æ’­çš„è€—æ—¶éƒ½è¿œè¿œè¶…è¿‡Feature Transformationæ“ä½œ$WX$ã€‚Feature Trançš„æ“ä½œç›¸å¯¹ä¸Propagationï¼Œè®¡ç®—æˆæœ¬å‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œæ‰€ä»¥å¦‚æœé¢„è®­ç»ƒæ“ä½œå¾—åˆ°çš„$W$å¯ä»¥ä½¿å¾—è®­ç»ƒGNNæ—¶çš„epochå¤§å¹…ä¸‹é™ï¼Œå¯ä»¥ä½¿æ¨¡å‹æ›´åŠ é«˜æ•ˆã€‚å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œè®­ç»ƒPeerMLPçš„æ—¶é—´å†åŠ ä¸Šçš„æƒé‡è¿ç§»åˆ°GNNåçš„fine-tuningæ—¶é—´ï¼Œ è¿œå°‘äºåœ¨GNNä¸Šç›´æ¥è®­ç»ƒéšæœºåˆå§‹åŒ–å‚æ•°çš„æ—¶é—´ã€‚
ä»ä¸‹å›¾åŒæ ·å¯ä»¥çœ‹å‡ºPeerMLPçš„å‚æ•°$w_{mlp}$çš„è®­ç»ƒè¶‹åŠ¿ï¼ŒPeerMLPè®­ç»ƒè¿‡ç¨‹ä¸­æ¯ä¸ªepochçš„$w_{mlp}$ç›´æ¥è¿ç§»åˆ°GNNä¸Šè®¡ç®—CEæŸå¤±ï¼Œå¯ä»¥å‘ç°ä½¿å¾—MLP çš„CE Lossä¸‹é™çš„$w_{mlp}$åŒæ ·å¯ä»¥ä½¿å¾—GNNä»¥åŒæ ·çš„è¶‹åŠ¿ä¸‹é™ã€‚</p></section><footer class=entry-footer><span title="2023-07-15 15:43:09 +0800 CST">July 15, 2023</span>&nbsp;Â·&nbsp;1 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2023ã€ŠMLPInitï¼šEmbarrassingly Simple GNN Training Acceleration with MLP Initializationã€‹ Reading Nodes" href=https://JhuoW.github.io/posts/mlpinit/></a></article><article class=post-entry><header class=entry-header><h2>Fraud Detection based on Graph Neural Networks</h2></header><section class=entry-content><p>1. Label Information Enhanced Fraud Detection against Low Homophily in Graphs (WWW â€˜23) Introduction GNN4FDå­˜åœ¨é—®é¢˜ï¼š å¤§å¤šæ•°åŸºäºGNNçš„æ¬ºè¯ˆæ£€æµ‹å™¨éš¾ä»¥æ³›åŒ–åˆ°low homophilyç½‘ç»œä¸­ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œå¦‚ä½•å……åˆ†åˆ©ç”¨labelä¿¡æ¯ä¹Ÿæ˜¯Fraud detectionçš„é‡è¦å› ç´ ã€‚å³å¦‚æœä¸€ä¸ªFraud nodeçš„é‚»å±…éƒ½æ˜¯benign nodesï¼Œé‚£ä¹ˆè¿™æ ·çš„å›¾å°±æ˜¯heterophily or low homophily graphï¼Œç”±äºGNNçš„neighborhood aggregationæœºåˆ¶ï¼Œtarget nodeçš„è¡¨ç¤ºä¼šå’Œå®ƒçš„é‚»å±…ç›¸ä¼¼ï¼Œæ— è®ºä»–ä»¬çš„labelæ˜¯å¦ä¸åŒï¼Œè¿™æ ·ä¼šä½¿å¾—GNNéš¾ä»¥åŒºåˆ†ä½äºå¼‚è´¨é‚»åŸŸå†…çš„Fraud nodesã€‚å¦å¤–ï¼Œ ç°æœ‰çš„GNN4FDæ–¹æ³•åˆ©ç”¨labelä¿¡æ¯çš„èƒ½åŠ›æœ‰é™ï¼Œè¿™äº›æ–¹æ³•ä»…åœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨labelä¿¡æ¯ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œä½†æ˜¯åœ¨è®¾è®¡message passing æœºåˆ¶çš„è¿‡ç¨‹ä¸­å¹¶æ²¡æœ‰ä½¿ç”¨labelä¿¡æ¯ã€‚
ä¸ºäº†è§£å†³ä¸Šè¿°2ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºGAGA: åŸºäºåˆ†ç»„èšåˆçš„Transformerã€‚ GAGAé¦–å…ˆæå‡ºäº†ä¸€ç§é¢„å¤„ç†ç­–ç•¥Group Aggregation (GA, åˆ†ç»„èšåˆ)ï¼Œç„¶åæ¯ä¸ªèŠ‚ç‚¹çš„åŸå§‹é‚»å±…ç‰¹ç‰¹å¾è¢«åˆ†ç»„ä¸ºåºåˆ—æ•°æ®ã€‚ ç„¶åæå‡ºä¸€ç§ç§‘å­¦ç³»çš„ç¼–ç æ–¹å¼æ¥ç¼–ç structuralï¼Œrelational å’Œlabelä¿¡æ¯ ï¼ˆå…¨å±€ï¼‰ï¼Œå³æ•´ä¸ªå›¾çš„relational encodingï¼Œgroup encoding å’Œ hop encoding ï¼ˆå›¾ä¸­åˆå‡ ä¸ªrelationå°±æœ‰å‡ ä¸ªrelational embeddingï¼Œå–å‡ ä¸ªhopå°±åˆå‡ ä¸ªhop embedding..ï¼‰ã€‚ æœ€åç”¨å¤šå¤´attentionä¸ºæ¯ä¸ªèŠ‚ç‚¹èšåˆembedding sequence.
Preliminaries Multi-relational fraud graph construction Multi-relational fraud graph $\mathcal{G}(\mathcal{V}, \mathcal{E}, \mathcal{X}, \mathcal{Y})$, å…¶ä¸­èŠ‚ç‚¹é›†$\mathcal{V}=\left\{v_1, v_2, \ldots, v_N\right\}(N=|\mathcal{V}|)$ï¼Œ$R$ ä¸ªé‚»æ¥çŸ©é˜µ$\mathcal{E}=\left\{\mathbf{A}_1, \mathbf{A}_2, \ldots, \mathbf{A}_R\right\}(R=|\mathcal{E}|)$çš„å¤šå…³ç³»å›¾ ï¼ˆ$R$ä¸ªå…³ç³»ï¼‰ã€‚èŠ‚ç‚¹feature vectors $X=\left\{\mathbf{x}_1, \mathrm{x}_2, \ldots, \mathrm{x}_N\right\}$ä»¥åŠèŠ‚ç‚¹çš„labelé›†åˆ$\mathcal{Y}$ã€‚ å¯¹äºä¸€ä¸ªrelationçš„é‚»æ¥çŸ©é˜µ$\mathbf{A}_r$ï¼Œå¦‚æœ$\mathbf{A}_1[u,v]=1$ï¼Œé‚£ä¹ˆåœ¨å…³ç³»$r$ä¸‹èŠ‚ç‚¹$u$å’Œ$v$è¢«è¿æ¥ã€‚æ¯ä¸ªèŠ‚ç‚¹$v \in \mathcal{V}$ æœ‰ä¸€ä¸ª$d$ç»´feature vector $\mathbf{x}_v \in \mathbb{R}^d$ã€‚ åœ¨åŸºäºGraphçš„fraud detectionä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘åŠç›‘ç£åœºæ™¯ï¼Œå…¶ä¸­ä¸€å°éƒ¨åˆ†èŠ‚ç‚¹ $\hat{\mathcal{V}} \supset \mathcal{V}$æ˜¯æœ‰labelçš„ ï¼ˆ$y=1$è¡¨ç¤ºè¯¥èŠ‚ç‚¹ä¸ºfraud nodeï¼Œ$y=0$è¡¨ç¤ºè¯¥èŠ‚ç‚¹ä¸ºbenign nodeï¼‰æ‰€ä»¥å¯¹äºfraud graphï¼ŒèŠ‚ç‚¹classæ•°ä¸º2ã€‚...</p></section><footer class=entry-footer><span title="2023-05-13 16:14:56 +0800 CST">May 13, 2023</span>&nbsp;Â·&nbsp;6 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to Fraud Detection based on Graph Neural Networks" href=https://JhuoW.github.io/posts/fd/></a></article><article class=post-entry><header class=entry-header><h2>ICML2022 ã€ŠLocal Augmentation for Graph Neural Networksã€‹ Reading Notes</h2></header><section class=entry-content><p>paper
Introduction åœ¨GNNçš„neighborhood aggregationä¸­ï¼Œå¯¹äºæ‹¥æœ‰å¾ˆå°‘é‚»å±…çš„èŠ‚ç‚¹ï¼Œåœ¨èšåˆè¿‡ç¨‹ä¸­æ˜¯å¦å……åˆ†ä»é‚»å±…ä¸­è·å¾—äº†ä¿¡æ¯æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚ä¸ºè§£å†³è¯¥é—®é¢˜ï¼Œ æœ¬æ–‡æå‡ºä¸ºæ¯ä¸ªèŠ‚ç‚¹åšå±€éƒ¨å¢å¼ºï¼Œå³ä»¥ä¸­å¿ƒèŠ‚ç‚¹ä¸ºæ¡ä»¶ï¼Œå­¦ä¹ é‚»å±…èŠ‚ç‚¹è¡¨ç¤ºçš„åˆ†å¸ƒã€‚ä¸ºäº†åœ¨å±€éƒ¨é‚»åŸŸä¸­ç”Ÿæˆä¸€äº›æ ·æœ¬æ¥æå‡ä¸­å¿ƒèŠ‚ç‚¹çš„neighborhood aggregationï¼Œæœ¬æ–‡æå‡ºä¸€ç§æ•°æ®å¢å¼ºæ¡†æ¶ï¼šLA-GNNsï¼Œ ä»¥å±€éƒ¨ç»“æ„å’Œä¸­å¿ƒèŠ‚ç‚¹ç‰¹å¾ä¸ºæ¡ä»¶ï¼Œç”Ÿæˆneighborhood featuresã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨pre-training é˜¶æ®µï¼Œé€šè¿‡ä¸€ä¸ªç”Ÿæˆæ¨¡å‹ï¼Œä»¥ä¸­å¿ƒèŠ‚ç‚¹çš„ç‰¹å¾ä¸ºæ¡ä»¶æ¥å­¦ä¹ é‚»å±…ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚ç„¶ååˆ©ç”¨è¿™ä¸ªé‚»å±…ç‰¹å¾åˆ†å¸ƒæ¥ç”Ÿæˆä¸­å¿ƒèŠ‚ç‚¹çš„å¢å¼ºé‚»å±…ç‰¹å¾ã€‚å¦å¤–ï¼Œé€šè¿‡pre-trainingæ¥å­¦ä¹ é‚»å±…å¢å¼ºç‰¹å¾ç”Ÿæˆå™¨çš„è¿‡ç¨‹æ˜¯ä¸ä¸‹æ¸¸ä»»åŠ¡æ— å…³çš„ï¼Œæ‰€ä»¥è¯¥ç”Ÿæˆå™¨ç”Ÿæˆçš„å¢å¼ºç‰¹å¾å¯ä»¥åº”ç”¨äºå…¶ä»–GNNæ¨¡å‹ã€‚
Local Augmentation for Graph Neural Networks (LAGNN) Motivation GNNåœ¨message passingçš„è¿‡ç¨‹åˆ©ç”¨å±€éƒ¨ä¿¡æ¯èšåˆæ¥å¾—åˆ°node representationsã€‚ ä½†æ˜¯å¯¹äºé‚»å±…æ•°é‡è¾ƒå°‘çš„èŠ‚ç‚¹ï¼Œä»é‚»å±…ä¸­å¾—åˆ°çš„ä¿¡æ¯å¯èƒ½ä¼šä¸è¶³ã€‚ä¸ºäº†ä¸ºèŠ‚ç‚¹$v$çš„é‚»åŸŸä¸­$\mathcal{N}_v$ç”Ÿæˆæ›´å¤šæ ·æœ¬ï¼Œå°±éœ€è¦çŸ¥é“é‚»å±…è¡¨ç¤ºçš„åˆ†å¸ƒã€‚ ç”±äºä¸€ä¸ªèŠ‚ç‚¹é‚»å±…åˆ†å¸ƒæ˜¯ä¸ä¸­å¿ƒèŠ‚ç‚¹ç›¸å…³ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ä»¥ä¸­å¿ƒèŠ‚ç‚¹$v$çš„representationä¸ºæ¡ä»¶ï¼Œå­¦ä¹ å®ƒçš„é‚»å±…è¡¨ç¤ºåˆ†å¸ƒã€‚
Approach æœ¬æ–‡åˆ©ç”¨Conditional Variational Auto-Encoder (CVAE) æ¥å­¦ä¹ ç»™å®šä¸­å¿ƒèŠ‚ç‚¹$v$ï¼Œé‚»å±…$u \in \mathcal{N}_v$çš„èŠ‚ç‚¹ç‰¹å¾çš„æ¡ä»¶åˆ†å¸ƒã€‚ç»™å®šä¸­å¿ƒèŠ‚ç‚¹ç‰¹å¾$\boldsymbol{X}_v$ï¼Œå…³äºä¸­å¿ƒèŠ‚ç‚¹çš„é‚»å±…åˆ†å¸ƒä¸º$p_\theta(\boldsymbol{X}_u | \boldsymbol{X}_v)$ã€‚å®šä¹‰éšå˜é‡$\mathbf{z}$ï¼Œåˆ™å…ˆéªŒå¯ä»¥å®šä¹‰ä¸º$p_\theta(\mathbf{z}|\boldsymbol{X}_v)$ã€‚ç»“åˆéšå˜é‡$\mathbf{z}$ï¼Œé‚»å±…ç‰¹å¾$\boldsymbol{X}_u$çš„åˆ†å¸ƒå¯ä»¥æ”¹å†™ä¸ºå¦‚ä¸‹å½¢å¼ï¼š $$ \begin{aligned} \log p_\theta(\boldsymbol{X}_u | \boldsymbol{X}_v) &= \log \frac{p_\theta(\boldsymbol{X}_u , \boldsymbol{X}_v)}{p_\theta( \boldsymbol{X}_v)}= \frac{p_\theta(\boldsymbol{X}_u , \boldsymbol{X}_v)p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)}{p_\theta( \boldsymbol{X}_v)p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)} \\ &=\log \frac{p_\theta(\boldsymbol{X}_u , \boldsymbol{X}_v, \mathbf{z})}{p_\theta( \boldsymbol{X}_v)p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)} \\ &= \log \frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)}\\ \end{aligned} $$ å‡è®¾éšå˜é‡$\mathbf{z}$çš„åˆ†å¸ƒä¸º$q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)$ï¼Œ å·¦å³ä¸¤è¾¹å¯¹åˆ†å¸ƒ$q_\phi$è®¡ç®—æœŸæœ›ï¼Œå·¦è¾¹ï¼š $$ \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log p_\theta(\boldsymbol{X}_u | \boldsymbol{X}_v) dz = \log p_\theta(\boldsymbol{X}_u | \boldsymbol{X}_v) $$ å³è¾¹ï¼š $$ \begin{aligned} &\int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)} dz \\ =& \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \left(\frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} \cdot \frac{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)}{p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)}\right) dz \\ =& \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} dz + \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \frac{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)}{p_\theta(\mathbf{z}|\boldsymbol{X}_u , \boldsymbol{X}_v)}dz \\ =& \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta(\boldsymbol{X}_u , \mathbf{z}| \boldsymbol{X}_v)}{ q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} dz + K L\left(q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) || p_\theta\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)\right) \\ \geq& \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u, \mathbf{z} \mid \boldsymbol{X}_v\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} = ELBO \end{aligned} $$ Evidence Lower Bound (ELBO) å¯ä»¥å†™ä¸º $$ \begin{aligned} L_{ELBO} &= \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u, \mathbf{z} \mid \boldsymbol{X}_v\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} \\ &= \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u, \boldsymbol{X}_v, \mathbf{z}\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) p_\theta\left(\boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} \\ &= \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u \mid \boldsymbol{X}_v, \mathbf{z}\right) p_\theta\left(\boldsymbol{X}_v, \mathbf{z}\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) p_\theta\left(\boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} \\ &= \int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log \frac{p_\theta\left(\boldsymbol{X}_u \mid \boldsymbol{X}_v, \mathbf{z}\right) p_\theta\left(\mathbf{z} \mid \boldsymbol{X}_v\right)}{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)} \mathrm{d} \mathbf{z} \\ &= -K L\left(q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) || p_\theta\left(\mathbf{z} \mid \boldsymbol{X}_v\right)\right)+\int_z q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) \log p_\theta\left(\boldsymbol{X}_u \mid \boldsymbol{X}_v, \mathbf{z}\right) \mathrm{d} \mathbf{z} \\ &= -K L\left(\underbrace{q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right)}_{Encoder} || \underbrace{ p_\theta\left(\mathbf{z} \mid \boldsymbol{X}_v\right)}_{\text{Normal Distribution}}\right) + \mathbb{E}_{\mathbf{z} \sim q_\phi\left(\mathbf{z} \mid \boldsymbol{X}_u, \boldsymbol{X}_v\right) }\log p_\theta\left(\boldsymbol{X}_u \mid \boldsymbol{X}_v, \mathbf{z}\right) \end{aligned} $$ åœ¨CVAE pre-trainingçš„è¿‡ç¨‹ä¸­ï¼Œç¬¬ä¸€é¡¹KLä¸­CVAE Encoder çš„ä¸€å¯¹é‚»æ¥èŠ‚ç‚¹å¯¹ï¼Œå¯¹äºè¯¥èŠ‚ç‚¹å¯¹ï¼Œè¾“å‡ºä¸€ç»„åˆ†å¸ƒå‚æ•°å‡å€¼$\mu$å’Œæ–¹å·®$\sigma$ï¼Œä½œä¸ºéšå˜é‡$z$çš„åˆ†å¸ƒå‚æ•°ï¼Œç¬¬ä¸€é¡¹çš„ä¼˜åŒ–ç›®æ ‡ä½¿å¾—ç¼–ç å™¨è¾“å‡ºçš„åˆ†å¸ƒæ¥è¿‘Normal Distributionã€‚ç„¶ååˆ©ç”¨reparameterization trickå¯å¾®çš„ä»ç”Ÿæˆçš„$\mathbf{z}$åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªencoding:...</p></section><footer class=entry-footer><span title="2023-01-25 21:19:40 +0800 CST">January 25, 2023</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICML2022 ã€ŠLocal Augmentation for Graph Neural Networksã€‹ Reading Notes" href=https://JhuoW.github.io/posts/lagcn/></a></article><article class=post-entry><header class=entry-header><h2>ICML2022 ã€ŠProGCLï¼šRethinking Hard Negative Mining in Graph Contrastive Learningã€‹ Reading Note</h2></header><section class=entry-content><p>paper
Introduction Contrastive Learning å—ç›ŠäºåŒºåˆ†hard negatives (æœ€ç›¸ä¼¼çš„negative pairs)ï¼Œ ä½†æ˜¯å…¶ä»–é¢†åŸŸçš„hard negative miningæ–¹æ³•ä¸é€‚ç”¨äºgraphã€‚ å¯¹äºGCLæ¥è¯´å¤§é‡embeddingä¹‹åçš„hard negativeså®é™…ä¸Šæ˜¯false negativesã€‚å¦‚å·¦å›¾æ‰€ç¤ºï¼Œå¯¹äºCVä¸Šçš„SimCLRï¼Œå®ƒæ‰€å­¦åˆ°çš„é«˜ç›¸ä¼¼åº¦çš„negativesä¸­ï¼ŒTrue negatives å’ŒFalse negativesæ•°é‡ç›¸å½“ï¼Œé‚£ä¹ˆä»é«˜ç›¸ä¼¼åº¦çš„negativesä¸­é‡‡æ ·åˆ°true negativesçš„æ¦‚ç‡æ›´å¤§ã€‚ç„¶è€Œå¯¹äºGCLæ–¹æ³•GCAæ¥è¯´ï¼Œæ˜¯æ¯ä¸ªanchorèŠ‚ç‚¹å°†å…¶ä»–æ‰€æœ‰ï¼ˆinter/intraï¼‰èŠ‚ç‚¹ä½œä¸ºnegativesï¼Œä½¿å¾—åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸å®ƒåŒç±»çš„èŠ‚ç‚¹ä¹Ÿå˜æˆanchorçš„negativesï¼Œè¿™äº›negativesæ˜¯false negativesã€‚å¯¹äºGCAï¼Œé«˜ç›¸ä¼¼åº¦çš„negativesä¸­false negativesçš„æ•°é‡è¿œå¤šäºtrue negativesï¼Œæ‰€ä»¥ç›´æ¥é‡‡æ ·é«˜ç›¸ä¼¼åº¦çš„negativesä½œä¸ºhard negativesæ¥é’ˆå¯¹æ€§çš„åˆ¤åˆ«ä»–ä»¬ï¼Œä¼šå¯¼è‡´åŒç±»èŠ‚ç‚¹çš„embeddingç›¸äº’è¿œç¦»ã€‚è¿™æ˜¯ä¼ ç»Ÿçš„hard negatives miningæ–¹æ³•åœ¨graph domainå¤±æ•ˆçš„åŸå› ã€‚
ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œ æœ¬æ–‡æå‡ºåˆ©ç”¨Beta mixture modelæ¥ä¼°è®¡å¯¹äºä¸€ä¸ªanchor nodeï¼Œå®ƒçš„ä¸€ä¸ªnegatveæ˜¯true negativeçš„æ¦‚ç‡ï¼Œç»“åˆç›¸ä¼¼åº¦ï¼Œæ¥è¡¡é‡è¯¥negativeçš„hardnessã€‚å³ä¸anchor nodeç›¸ä¼¼åº¦è¶Šé«˜ï¼Œä¸”å®ƒæ˜¯true negativeçš„æ¦‚ç‡è¶Šå¤§ï¼Œé‚£ä¹ˆè¯¥èŠ‚ç‚¹çš„hardnessè¶Šé«˜ã€‚
Methodology GCL å¦‚ä¸Šå›¾æ‰€ç¤ºï¼ŒInfoNCEå°†è·¨å›¾same nodeè§†ä¸ºpositivesï¼Œå…¶ä»–èŠ‚ç‚¹å¯¹è§†ä¸ºnegativesï¼ŒGCLçš„ç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š $$ \begin{aligned} \ell\left(\boldsymbol{u}_{i},\boldsymbol{v}_{i}\right)= \log \frac{e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{i}\right) / \tau}}{\underbrace{e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{i}\right) / \tau}}_{\text{positive pair }}+\underbrace{\sum_{k\neq i}e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{k}\right) / \tau}}_{\text{inter-view negative pairs}}+\underbrace{\sum_{k\neq i}e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{u}_{k}\right) / \tau}}_{\text{intra-view negative pairs}}}, \end{aligned} $$ Overall objectiveå®šä¹‰åœ¨æ‰€æœ‰è·¨å›¾same node pairsä¸Šï¼š $$ \mathcal{J}=-\frac{1}{2 N} \sum_{i=1}^N\left[\ell\left(\boldsymbol{u}_{\boldsymbol{i}}, \boldsymbol{v}_{\boldsymbol{i}}\right)+\ell\left(\boldsymbol{v}_{\boldsymbol{i}}, \boldsymbol{u}_{\boldsymbol{i}}\right)\right] $$ å¦‚æœå°†GCAä¸­çš„2å±‚shared GNNæ›¿æ¢ä¸ºMLPï¼Œé‚£ä¹ˆcontrastive learningå°†ä¸å­˜åœ¨Message Passingï¼Œè¿™æ ·å¾—åˆ°çš„true/false negativeåˆ†å¸ƒå¦‚(b)æ‰€ç¤ºï¼Œå¯ä»¥çœ‹å‡ºMessage Passingæ˜¯GCLå’ŒCLä¹‹é—´äº§ç”ŸåŒºåˆ«å…³é”®å› ç´ ã€‚ç›´è§‚ä¸Šï¼ŒMPå°†anchorä¸ç›¸é‚»çš„negativesæ‹‰è¿‘ï¼Œè€Œç›¸é‚»çš„negativeså¤§å¤šä¸ºFalse negativesï¼ˆHomophilyï¼‰ï¼Œæ‰€ä»¥GCLå¾—åˆ°çš„é«˜ç›¸ä¼¼åº¦negativesä¸­false negativesè¦è¿œå¤šäºTrue negativesã€‚...</p></section><footer class=entry-footer><span title="2023-01-08 22:28:43 +0800 CST">January 8, 2023</span>&nbsp;Â·&nbsp;2 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICML2022 ã€ŠProGCLï¼šRethinking Hard Negative Mining in Graph Contrastive Learningã€‹ Reading Note" href=https://JhuoW.github.io/posts/progcl/></a></article><article class=post-entry><header class=entry-header><h2>WWW2022 ã€ŠClusterSCLï¼šCluster-Aware Supervised Contrastive Learning on Graphsã€‹ Reading Notes</h2></header><section class=entry-content><p>paper
Introduction å¯¹äºç›‘ç£å¯¹æ¯”å­¦ä¹ ï¼ˆSupervised Contrastive Learning, SupConï¼‰, SupCon lossæ—¨åœ¨è¡¨ç¤ºç©ºé—´ä¸­æ‹‰è¿‘å±äºåŒä¸€ä¸ªclassçš„æ•°æ®ç‚¹ï¼Œåˆ†ç¦»ä¸åŒç±»çš„æ•°æ®ç‚¹ã€‚ ä½†æ˜¯SupConéš¾ä»¥å¤„ç†é«˜ç±»å†…æ–¹å·®ï¼Œç±»é—´ç›¸ä¼¼åº¦è¾ƒå¤§çš„æ•°æ®é›†ã€‚ä¸ºäº†è§£å†³è¯¥é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Cluster-aware supervised contrastive learning loss (ClusterSCL)ã€‚ä»€ä¹ˆæ˜¯é«˜ç±»å†…æ–¹å·®ï¼Œé«˜è·¨ç±»ç›¸ä¼¼åº¦é—®é¢˜ï¼Ÿå¦‚å›¾1(a)æ‰€ç¤ºï¼ŒèŠ‚ç‚¹$u_1$å’Œ$u_3$ æ˜¯åŒç±»èŠ‚ç‚¹ï¼Œ$u_2$å’Œ$u_4$æ˜¯åŒç±»èŠ‚ç‚¹ã€‚ä»–ä»¬æ˜¯åŒç±»èŠ‚ç‚¹ä½†åœ¨ä¸åŒçš„ç¤¾åŒºä¸­ï¼Œæ‰€ä»¥ç±»å†…æ–¹å·®è¾ƒå¤§ï¼Œå³åŒä¸€ä¸ªç±»å†…çš„èŠ‚ç‚¹è·¨è¶Šäº†å¤šä¸ªcommunityã€‚ å¦å¤–$u_1$å’Œ$u_2$ï¼Œ $u_3$å’Œ$u_4$ï¼Œæ˜¯ä¸åŒç±»çš„èŠ‚ç‚¹å¯¹ï¼Œ ä½†ä»–ä»¬å¤„åœ¨åŒä¸€ä¸ªç¤¾åŒºä¸­ï¼Œå¯¼è‡´åœ¨MPNNè¿‡ç¨‹ä¸­ï¼Œè¿™äº›å¤„åœ¨åŒä¸€ä¸ªcommunityä¸­çš„ä¸åŒç±»èŠ‚ç‚¹è¢«æ‹‰è¿‘ï¼Œå¯¼è‡´è·¨ç±»ç›¸ä¼¼åº¦è¾ƒé«˜çš„é—®é¢˜ã€‚
å¦‚æœå¯¹èŠ‚ç‚¹$u_2$è®¡ç®—SupConæ—¶ï¼Œå¦‚å›¾1(b)æ‰€ç¤ºï¼ŒSupConä¼šä½¿å¾—åŒç±»èŠ‚ç‚¹è¢«æ‹‰è¿‘ï¼Œå¦‚$u_2$å’Œ$u_4$ä¼šè¢«æ‹‰è¿‘ã€‚ä½†æ˜¯$u_3$å’Œ$u_4$å¤„åœ¨åŒä¸€ä¸ªç¤¾åŒºä¸­ï¼ˆstructurally similarï¼‰é‚£ä¹ˆMPNNä¼šä½¿å¾—$u_3$å’Œ$u_4$è¢«æ‹‰è¿‘ï¼Œæ‰€ä»¥SupConåœ¨æ‹‰è¿‘$u_2$å’Œ$u_4$çš„åŒæ—¶ï¼Œä¼šé—´æ¥æ‹‰è¿‘ä¸åŒç±»èŠ‚ç‚¹$u_2$å’Œ$u_3$ã€‚åŒæ—¶ï¼Œå¯¹äºæ„æˆnegative pairsçš„ä¸åŒç±»èŠ‚ç‚¹ï¼Œä¾‹å¦‚$u_1$å’Œ$u_2$ï¼ŒSupConä¼šæ¨è¿œ$u_1$å’Œ$u_2$ï¼Œä½†æ˜¯$u_1$å’Œ$u_5$ structurally similar, å› æ­¤ä¼šæ¨è¿œ$u_1$å’Œ$u_2$ä¼šé—´æ¥å¯¼è‡´$u_2$å’Œ$u_5$è¿™ä¸¤ä¸ªåŒç±»èŠ‚ç‚¹è¢«æ¨è¿œã€‚å› æ­¤å¯¹äºä¸€ä¸ªclusterå†…èŠ‚ç‚¹ä¸åŒç±»ï¼Œä¸”ä¸åŒclusterä¸­å­˜åœ¨åŒç±»èŠ‚ç‚¹çš„æƒ…å†µï¼Œä¼šå¯¼è‡´å¤æ‚çš„å†³ç­–è¾¹ç•Œï¼Œå³åœ¨æ‹‰è¿‘åŒç±»ä½†ä¸åŒç¤¾åŒºçš„èŠ‚ç‚¹æ—¶ï¼Œä¹Ÿä¼šé—´æ¥æ‹‰è¿‘ä¸åŒç±»ä¸åŒç¤¾åŒºçš„èŠ‚ç‚¹ã€‚åœ¨æ¨è¿œä¸åŒç±»åŒç¤¾åŒºçš„èŠ‚ç‚¹æ—¶ï¼Œä¹Ÿå¯èƒ½é—´æ¥æ¨è¿œåŒç±»åŒç¤¾åŒºçš„èŠ‚ç‚¹ã€‚
ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ€ç›´æ¥çš„æ–¹æ³•æ˜¯å¯¹äºæ¯ä¸ªclusterï¼Œå¦‚å›¾1(a)çš„Community 1ï¼Œä¸è€ƒè™‘å…¶ä»–clusterï¼Œåªå¯¹å½“å‰clusterå†…èŠ‚ç‚¹åšSupConã€‚ä½†æ˜¯è¿™ä¹ˆåšå¿½ç•¥äº†è·¨clusterçš„åŒç±»èŠ‚ç‚¹äº¤äº’ï¼Œå¦‚$u_1$å’Œ$u_3$ï¼Œ$u_2$å’Œ$u_4$ï¼Œè¿™äº›è·¨clusterçš„positive pairså¯èƒ½åŒ…å«æœ‰ç›Šçš„ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºcluster-aware data augmentation (CDA) èšç±»æ„ŸçŸ¥çš„æ•°æ®å¢å¼ºï¼Œæ¥ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆaugmented positives and negativesï¼Œå¦‚å›¾1(b)ä¸­ClusterSCLæ‰€ç¤ºã€‚å¯¹äºæ¯ä¸ªèŠ‚ç‚¹$u$ï¼Œä¸ºå®ƒç”Ÿæˆpositive å’Œnegative samples, ç”Ÿæˆçš„samples ä½äºæˆ–æ¥è¿‘$u$æ‰€åœ¨çš„clusterã€‚Recall SupConå­˜åœ¨çš„é—®é¢˜ï¼š
SupConä¼šä½¿å¾—$u_2$å’Œ$u_4$è¢«æ‹‰çš„å¤ªè¿‘ï¼Œä»è€Œé—´æ¥å¯¼è‡´$u_2$å’Œ$u_3$è¢«æ‹‰è¿‘ï¼Œæ‰€ä»¥å¯¹äºhigh intra-class variancesï¼Œè¦æ±‚ä¸åŒclusterçš„åŒç±»èŠ‚ç‚¹å¦‚$u_2$å’Œ$u_4$ä¸è¦è¢«æ‹‰å¤ªè¿‘ï¼› SupConä¼šä½¿å¾—$u_1$å’Œ$u_2$è¢«æ¨è¿œï¼Œä»è€Œé—´æ¥å¯¼è‡´$u_2$å’Œ$u_5$è¢«æ¨è¿œï¼Œæ‰€ä»¥å¯¹äºhigh inter-class similarityï¼Œè¦æ±‚åŒä¸€ä¸ªclusterå†…çš„ä¸åŒç±»èŠ‚ç‚¹å¦‚$u_1$å’Œ$u_2$ä¸è¦è¢«æ‹‰çš„å¤ªè¿œã€‚ Method Two stage training with Supervised Contrastive Loss SupCon encourages samples of the same class to have similar representations, while pushes apart samples of different classes in the embedding space....</p></section><footer class=entry-footer><span title="2022-11-17 01:33:20 +0800 CST">November 17, 2022</span>&nbsp;Â·&nbsp;4 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to WWW2022 ã€ŠClusterSCLï¼šCluster-Aware Supervised Contrastive Learning on Graphsã€‹ Reading Notes" href=https://JhuoW.github.io/posts/clusterscl/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2022 ã€ŠGraph Condensation for Graph Neural Networksã€‹ Reading Notes</h2></header><section class=entry-content><p>paper
Introduction æœ¬æ–‡æå‡ºå›¾æµ“ç¼©æŠ€æœ¯ï¼ˆGraph Condensationï¼‰ï¼Œæ—¨åœ¨å°†å¤§å›¾æµ“ç¼©ä¸ºä¸€ä¸ªå°å›¾ï¼Œä½¿å¾—åœ¨å°å›¾ä¸Šè®­ç»ƒçš„GNNå¯ä»¥å¾—åˆ°å’Œå¤§å›¾ç›¸å½“çš„æ•ˆæœã€‚é€šè¿‡ä¼˜åŒ–gradient matching lossæ¥æ¨¡æ‹ŸGNNåœ¨åŸå›¾ä¸Šçš„è®­ç»ƒè½¨è¿¹ï¼Œä»è€Œè§£å†³å›¾æµ“ç¼©é—®é¢˜ã€‚
é€šå¸¸æœ‰ä¸¤ä¸ªç­–ç•¥æ¥ç®€åŒ–å›¾ï¼šGraph Sparsification(å›¾ç¨€ç–åŒ–)å’ŒGraph Coarsening(å›¾ç²—åŒ–)ã€‚å›¾ç¨€ç–åŒ–é€šè¿‡å‡å°‘è¾¹æ•°æ¥è¿‘ä¼¼ä¸€ä¸ªå›¾ï¼› å›¾ç²—åŒ–æ—¨åœ¨å‡å°‘èŠ‚ç‚¹æ•°é‡ã€‚ï¼ˆ1ï¼‰å½“èŠ‚ç‚¹å…·æœ‰å±æ€§ç‰¹å¾æ—¶ï¼Œç”±äºç¨€ç–åŒ–ä¸ä¼šå‡å°‘èŠ‚ç‚¹æ•°é‡ï¼Œå› æ­¤å±æ€§é‡ä¸ä¼šå‡å°‘ã€‚ ï¼ˆ2ï¼‰å›¾ç²—åŒ–çš„ç›®çš„æ˜¯ä¿å­˜ä¸€äº›å›¾å±æ€§æ¯”å¦‚ä¸»ç‰¹å¾å€¼ï¼Œè¿™å¯èƒ½å¯¹ä¸‹æ¸¸ä»»åŠ¡ä¸æ˜¯æœ€ä¼˜çš„ä¿å­˜å±æ€§ã€‚
æœ¬æ–‡æå‡ºå›¾æµ“ç¼©ï¼Œæ¥å­¦ä¹ ç”Ÿæˆå›¾çš„ç»“æ„å’ŒèŠ‚ç‚¹å±æ€§ï¼Œä»è¿™ä¸¤æ–¹é¢åŒæ—¶è¿›è¡Œæµ“ç¼©ã€‚å¯¹äºRedditæ•°æ®é›†ï¼ŒGCondå¯ä»¥å°†èŠ‚ç‚¹æ•°æµ“ç¼©è‡³0.1%ï¼Œå¹¶ä¸”åœ¨æµ“ç¼©å›¾ä¸Šå¯ä»¥å¾—åˆ°å’ŒåŸå›¾ç›¸å½“çš„æ•ˆæœã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
æœ¬æ–‡è§£å†³äº†å›¾æµ“ç¼©é¢ä¸´çš„ä¸¤ä¸ªæŒ‘æˆ˜ï¼š1. æ„å»ºç›®æ ‡å‡½æ•°ï¼Œ 2. å‚æ•°åŒ–å¯å­¦ä¹ çš„èŠ‚ç‚¹ç‰¹å¾å’Œå›¾ç»“æ„ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°æŒ‘æˆ˜ï¼Œæœ¬æ–‡ä½¿ç”¨gradient matching lossæ¥åŒ¹é…æ¯ä¸€ä¸ªtraining stepä¸ŠåŸå›¾ä¸æµ“ç¼©å›¾çš„GNNå‚æ•°æ¢¯åº¦ï¼Œä½¿å¾—GNNåœ¨æµ“ç¼©å›¾ä¸Šçš„è®­ç»ƒè¶‹åŠ¿ä¸åŸå›¾ç›¸åŒ¹é…ã€‚ä¸ºäº†å‚æ•°åŒ–èŠ‚ç‚¹ç‰¹å¾å’Œå›¾ç»“æ„ï¼Œæœ¬æ–‡å°†æµ“ç¼©å›¾çš„Feature Matrixè®¾ä¸ºè‡ªç”±å‚æ•°çŸ©é˜µï¼Œå°†æµ“ç¼©å›¾ç»“æ„è®¾ä¸ºå…³äºFeature matrix çš„ å‡½æ•°ï¼ˆåŸºäºç»“æ„ä¸ç‰¹å¾ç›¸å…³è”å‡è®¾ï¼‰ï¼Œä½¿å¾—è®¡ç®—å¼€é”€é™ä½ã€‚
Methodology A graph $\mathcal{T}=\{\mathbf{A}, \mathbf{X}, \mathbf{Y}\}$ï¼Œå…¶ä¸­$\mathbf{X} \in \mathbb{R}^{N \times d}$æ˜¯$d$ç»´èŠ‚ç‚¹ç‰¹å¾ï¼Œ$\mathbf{Y} \in\{0, \ldots, C-1\}^N$ è¡¨ç¤º$N$ä¸ªèŠ‚ç‚¹çš„labelsï¼Œå…±æœ‰$C$ä¸ªclassã€‚å›¾æµ“ç¼©æ—¨åœ¨å­¦ä¹ ä¸€ä¸ªå°çš„ç”Ÿæˆå›¾$\mathcal{S}=\left\{\mathbf{A}^{\prime}, \mathbf{X}^{\prime}, \mathbf{Y}^{\prime}\right\}$ï¼Œå…¶ä¸­$\mathbf{A}^{\prime} \in \mathbb{R}^{N^{\prime} \times N^{\prime}}$æ˜¯æµ“ç¼©å›¾çš„é‚»æ¥çŸ©é˜µï¼Œ$\mathbf{X}^{\prime} \in \mathbb{R}^{N^{\prime} \times D}$æ˜¯æµ“ç¼©å›¾çš„ç‰¹å¾çŸ©é˜µï¼Œ$\mathbf{Y}^{\prime} \in\{0, \ldots, C-1\}^{N^{\prime}}$æ˜¯æµ“ç¼©å›¾çš„node labels å…¶ä¸­$N^{\prime} \ll N$ï¼Œç‰¹å¾ç»´åº¦ä»$d$å˜ä¸º$D$ã€‚å›¾æµ“ç¼©çš„ç›®æ ‡æ˜¯åŸºäºåŸå›¾è®­ç»ƒè¿‡ç¨‹å­¦ä¹ æµ“ç¼©å›¾$\mathcal{S}$ï¼Œä½¿å¾—åœ¨$\mathcal{S}$ä¸Šè®­ç»ƒçš„GNNåº”ç”¨åœ¨åŸå›¾ä¸Šçš„lossæœ€å°ï¼š $$ \min_{\mathcal{S}} \mathcal{L}\left(\mathrm{GNN}_{\boldsymbol{\theta}_{\mathcal{S}}}(\mathbf{A}, \mathbf{X}), \mathbf{Y}\right) \quad \text { s.t } \quad \boldsymbol{\theta}_{\mathcal{S}}=\underset{\boldsymbol{\theta}}{\arg \min } \mathcal{L}\left(\mathrm{GNN}_{\boldsymbol{\theta}}\left(\mathbf{A}^{\prime}, \mathbf{X}^{\prime}\right), \mathbf{Y}^{\prime}\right), $$ Outerï¼šå›ºå®šGNNå‚æ•°ï¼Œä¼˜åŒ–å°å›¾ã€‚ Inner: å›ºå®šå°å›¾ï¼Œåœ¨å°å›¾ä¸Šè®­ç»ƒGNNå‚æ•°ã€‚...</p></section><footer class=entry-footer><span title="2022-09-01 10:47:21 +0800 CST">September 1, 2022</span>&nbsp;Â·&nbsp;1 min&nbsp;Â·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2022 ã€ŠGraph Condensation for Graph Neural Networksã€‹ Reading Notes" href=https://JhuoW.github.io/posts/gcond/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://JhuoW.github.io/page/2/>Next Page Â»</a></nav></footer></main><footer class=footer><span>Copyright &copy; 2024 <a href=https://JhuoW.github.io/>JhuoWâ€˜s Notes</a></span>
<span></span><br><script>function siteTime(){var u=1e3,r=u*60,a=r*60,n=a*24,x=n*365,e=new Date,d=2019,O=1,w=16,_=19,y=15,m=11,l=e.getFullYear(),C=e.getMonth()+1,f=e.getDate(),p=e.getHours(),g=e.getMinutes(),v=e.getSeconds(),b=Date.UTC(d,O,w,_,y,m),j=Date.UTC(l,C,f,p,g,v),s=j-b,o=Math.floor(s/x),t=Math.floor(s/n-o*365),i=Math.floor((s-(o*365+t)*n)/a),c=Math.floor((s-(o*365+t)*n-i*a)/r),h=Math.floor((s-(o*365+t)*n-i*a-c*r)/u);d==l?document.getElementById("sitetime").innerHTML="æœ¬ç«™å·²è¿è¡Œ "+t+" å¤© "+i+" å°æ—¶ "+c+" åˆ†é’Ÿ "+h+" ç§’":document.getElementById("sitetime").innerHTML="æœ¬ç«™å·²è¿è¡Œ "+o+" å¹´ "+t+" å¤© "+i+" å°æ—¶ "+c+" åˆ†é’Ÿ "+h+" ç§’"}setInterval(siteTime,1e3)</script><span id=sitetime>è½½å…¥è¿è¡Œæ—¶é—´...</span>
<script type=text/javascript id=clustrmaps src="//cdn.clustrmaps.com/map_v2.js?cl=080808&w=268&t=tt&d=YsONH-MzO6L7yrkA73Z_QW7LuMTfdUhk0uhb_KaBv-g&co=f5f5f5&cmo=3acc3a&cmn=ff5353&ct=808080"></script>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>