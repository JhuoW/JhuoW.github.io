<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LLM on JhuoW‘s Notes</title>
    <link>https://JhuoW.github.io/tags/llm/</link>
    <description>Recent content in LLM on JhuoW‘s Notes</description>
    <image>
      <url>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 26 Oct 2025 13:59:35 +0800</lastBuildDate><atom:link href="https://JhuoW.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 阅读笔记</title>
      <link>https://JhuoW.github.io/posts/2025-10-26-autogfm/</link>
      <pubDate>Sun, 26 Oct 2025 13:59:35 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/2025-10-26-autogfm/</guid>
      <description>ICML2025 &amp;#34;AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>GFM旨在实现跨领域和任务之间的知识共享来提升图机器学习，但是现有的GFM依赖于手工设计并且fixed的backbone GNN架构，不能根据任务或者领域来自适应调整最优的GNN backbone架构。对于此问题，本文通过发现跨领域和任务的不变“图-架构”关系（invariant graph-architecture relationship）来解决该问题。什么是invariant graph-architecture relationship，就是不管是什么领域，图和架构之间存在一种不变的关系，什么样的图就应该对应于什么样的架构。这会带来3个挑战：</p>
<ol>
<li>如何捕获invariant和variant的pattern，其中invariant pattern指的是可以用来可靠预测图的架构的pattern，variant pattern指的是图中不能用来稳定预测图架构的pattern。<strong>换句话说，invariant pattern指的是图中可以决定架构的固有图结构，可以形成与对应GNN架构之间的一一对应的不变关系，而variant pattern指的是一个可变pattern，他可能对应于各种GNN架构，对于这类pattern，GNN架构是不确定的。</strong> Invariant relationship between graph data and corresponding architecture 指的是一个架构适用于的固有图结构，即一个GNN架构对什么样的图结构一定适用。</li>
<li>如何为不同的领域和任务调整GFM中的GNN架构。</li>
<li>如何减轻架构搜索中的数据支配显现（Data domination）。</li>
</ol>
<p>AutoGFM的<strong>核心思想</strong>是训练一个架构映射函数 $\pi: \mathcal{G} \to \mathcal{A}$，用于将图数据映射为特定GNN架构。</p>
<h1 id="architecture-inconsistency-in-gfm">Architecture Inconsistency in GFM</h1>
<p>当前GFM模型存在一个架构不一致（Architecture Inconsistency）问题，也就是说，不同领域不同任务的最优架构不一致。这边拿GFT这个foundation model为例，它在预训练图上预训练一个GNN模型，然后基于预训练图的embedding来构造一堆词汇表，然后下游任务的图基于这些预训练好的词汇表来作预测。其他GFM模型也都会在预训练阶段预训练好一个GNN模块。这个GNN模块的架构，比如可能是GCN也可能是GAT，是固定的。但这样就存在一个问题，就是下游任务的图不一定适用于这个固定的GNN架构。</p>
<p><img loading="lazy" src="/posts/2025-10-26-autogfm/1.png#center" alt="autogfm"  />
</p>
<h1 id="preliminary">Preliminary</h1>
<h2 id="problem-formulation">Problem Formulation</h2>
<p><strong>TAG</strong>：所有图用Text-attributed graph $\mathcal{G}=(\mathcal{V}, \mathcal{E}, \mathcal{R})$来统一所有图，其中 $\mathcal{R}=r_1, \ldots, r_{|\mathcal{R}|}$是关系数量。</p>
<p><strong>Node of Interest (NOI) Subgraph</strong>：用子图分类任务来统一节点级，边级，图级任务。NOI subgraph $G_h$定义为一个在NOI node周围的子图。用 $S_h(v)=\left\{\mathcal{V}_v^h, \mathcal{E}_v^h, \mathcal{R}_v^h\right\}$表示以节点 $v$为中心的 $h$-hop ego-subgraph。</p>
<p>节点级：NOI node 就是节点 $v$本身，因此 $\mathcal{T} = {v}$，NOI graph 表示为 $G_h(\mathcal{T}) = S_h(v)$。</p>
<p>边级：对于一条边 $(v_i,v_j$)，定义 $\mathcal{T} = \{v_i, v_j\}$，该任务的NOI graph为 $G_h\left(\left\{v_i, v_j\right\}\right)=S_h\left(v_i\right) \cup S_h\left(v_j\right)$。</p>
<p>图级：NOI graph是整个图。</p>
<p>所有的任务均可以统一成对NOI graph的分类任务。</p>
<h2 id="graph-neural-architecture-search-gnas">Graph Neural Architecture Search (GNAS)</h2>
<p>对于一个图数据 $\mathcal{D} = (\mathcal{G}, \mathcal{Y})$，图架构搜索旨在搜索一个从graph 到 label的函数 $F_{\alpha,w}: \mathcal{G} \to \mathcal{Y}$，其中 $\alpha \in \mathcal{A}$是架构参数， $\mathcal{A}$是架构空间。 $w\in \mathcal{W}$是权重。最优架构指的是，在该GNN架构下，模型的最优参数对图预测的loss最小，是一个bi-level optimization problem。如下图所示，上面的式子表示找到最有架构 $\alpha^*$，满足该架构的最优参数可以使模型与 $\mathcal{Y}$的loss最小。</p>
<p><img loading="lazy" src="/posts/2025-10-26-autogfm/2.png#center" alt="autogfm"  />
</p>
<p><strong>Invariant View of Architecture Customization</strong></p>
<p>The goal is to identify <em><strong>invariant relationships between graph data and the correspond architecture</strong></em>, addressing the issue of <em><strong>architecture inconsistency</strong></em> by tailoring graph neural architecture for each data individually. （不变关系：一个图结构一定对应固定的架构，而不会对应于变化的架构，这样的图结构相对于架构空间称为invariant pattern）。</p>
<p>基于此，本文构建了4个核心变量：输入图 $G$，架构 $A$，invariant pattern $Z_I$，variant pattern $Z_V$。将图到架构的映射分为2个成分：encoder $\theta: G \to Z_I$和 predictor $\psi: Z_I \to A$。分别从图中提取invariant pattern，以及用invariant pattern预测最适用于该图的架构。</p>
<p><strong>Assumption</strong>：（1） $Z_I=G \backslash Z_V$， invariant pattern $Z_I$用于可靠预测架构；（2） $Z_V \not \perp A$， $Z_V$虽然不能稳定预测架构，但他并不是与架构相互独立；（3） $A \perp Z_V \mid Z_I$， $\mathrm{A}=\psi\left(\mathrm{Z}_I\right)$，表示给定invariant pattern $Z_I$，架构 $A$的选择不会受到 variant pattern $Z_V$的影响。也就是说如果确定了图中的invariant pattern $Z_I$可以决定该图的架构 $A$，那么其他部分 $Z_V$不应该影响 $Z_I$对架构的选择。</p>
<p>上面三个假设可以写为下式：</p>
<p>$$
\max _{\theta, \psi} I\left(\mathrm{Z}_I, \mathrm{~A}\right)-\lambda I\left(\mathrm{Z}_I, \mathrm{Z}_V\right)-\beta I\left(\mathrm{~A}, \mathrm{Z}_V \mid \mathrm{Z}_I\right)
$$</p>
<p>即 学到的invariant pattern $Z_I$要和架构完全相关，并且与variant pattern分离，同时在 $Z_I$可以确定架构的情况下， $Z_V$不能对架构的选择产生影响。AutoGFM就是要实现该目标。</p>
<h1 id="autogfm">AutoGFM</h1>
<h2 id="disentangled-contrastive-graph-encoder">Disentangled Contrastive Graph Encoder</h2>
<p><img loading="lazy" src="/posts/2025-10-26-autogfm/3.png#center" alt="autogfm"  />
</p>
<p>输入是一堆NOI graphs。对于一个NOI graph $G_i$，它的invariant和variant部分需要被disentangle (解纠缠)。Disentangled NOI-graph Encoder用于学习两个channel 的表示：</p>
<p>$$
\begin{aligned}\mathrm{H}_k^{(l)} &amp; =\mathrm{GNN}_k\left(\mathrm{H}_k^{(l-1)}, \mathbf{A}\right), \quad k=1,2, \\ \mathrm{z}_k &amp; =\mathrm{MLP}_k\left(\mathrm{~h}_k\right) \\ \mathrm{h}_k &amp; =\operatorname{Readout}_k\left(\mathrm{H}_k^{(L)}\right), \quad k=1,2 .\end{aligned}
$$</p>
<p>这里用两个GNN $\mathrm{GNN}_1$和 $\mathrm{GNN}_2$并行的学习一个图的2个表示 $z_1$和 $z_2$，作为图的invariant表示 $Z_I$和variant表示 $Z_V$。然后，本文提出NOI-graph-level contrastive learning方法来解纠缠的表示可以反应图数据的架构需求。这里要求两个表示被disentangle：</p>
<p>$$
p_\theta\left(\mathrm{z}_{i, k} \mid \mathrm{G}_i\right)=\frac{\exp \phi\left(\mathrm{z}_{i, k}, \mathrm{p}_k\right)}{\sum_{j=1}^2 \exp \phi\left(\mathrm{z}_{i, k}, \mathrm{p}_j\right)}
$$</p>
<p>$\mathrm{p}_k$（ $k=1,2$）是第 $k$个表示chunk的prototype，用于表示invariant或variant的<strong>可学习的protontype</strong>，上面的对比函数表示NOI graph $G_i$的表示 $z_{i,1}$要和 $\mathrm{p}_1$相似，$z_{i,2}$要和 $\mathrm{p}_2$相似，而 $z_{i,1}$要和 $\mathrm{p}_2$不相似。以此来区分图中的invariant和variant成分。最大化上面的概率目的是最小化 NOI graph $G_i$ 的 $I\left(\mathrm{Z}_I, \mathrm{Z}_V\right)$。另外，不同NOI graph的invariant representation $Z_I$，需要encourage $Z_I$可以为不同的图数据捕获不同的架构需求，因此对于同一个图的invariant表示 $Z_I$，同一个图的 $Z_I$要相似，不同NOI graph的 $Z_I$要不相似，下面式子用到的 $z$全是 $Z_I$：</p>
<p>$$
p_\theta\left(s\left(\mathrm{z}_{i, k}\right) \mid \mathrm{G}_i, \mathrm{z}_{i, k}\right)=\frac{\exp \phi\left(\mathrm{z}_{i, k}, \mathrm{z}_{i, k}^{\prime}\right)}{\sum_{j=1}^N \exp \phi\left(\mathrm{z}_{i, k}, \mathrm{z}_{j, k}^{\prime}\right)}
$$</p>
<p>模型参数 $\theta$的优化目标如下：</p>
<p>$$
\mathcal{L}_{\text {dis }}=\sum_i-\log \mathbb{E}_{p_\theta\left(\mathrm{z}_{i, k} \mid \mathrm{G}_i\right)} p_\theta\left(s\left(\mathrm{z}_{i, k}\right) \mid \mathrm{G}_i, \mathrm{z}_{i, k}\right)
$$</p>
<p>旨在区分不同NOI graph的 $Z_I$，使得 $Z_I$可以为不同的图捕获不同的架构需求，同时要让同一个图的invariant和variant表示被区分。</p>
<h2 id="invariant-guided-architecture-customization">Invariant-guided Architecture Customization</h2>
<p>接下来就是要构建不变表示和图架构之间的映射关系。 Invariant representation $Z_I$要可以映射到正确的架构上，对于一个GFM来说，之前的方法是定义一个GNN backbone，这个工作把backbone定义为 $|O|$个候选backbone的组合 $\{GCN, GAT, GIN, \ldots, SAGE\}$，每个GNN都有自己的参数，被联合训练，如下图所示。</p>
<p><img loading="lazy" src="/posts/2025-10-26-autogfm/4.png#center" alt="autogfm"  />
</p>
<p>这些GNN组成的超网络表示为：</p>
<p>$$
\mathrm{H}^{(l)} \leftarrow \sum_{i=1}^{|\mathcal{O}|} \alpha_{l, i} \mathrm{GNN}_i^{(l-1)}\left(\mathrm{H}^{(l-1)}, \mathbf{A}\right),
$$</p>
<p>也就是当前NOI graph得到的表示是一堆候选GNN的组合。其中 $\alpha_{l, i}$决定了每个GNN操作对给定数据集的贡献。</p>
<p>架构预测器（Architecture Predictor）：对于一个图的表示 $z$（不变表示），invariant mapping predictor 定义为 $\psi: z \to \{\alpha_{l,i}\}$。用于将invariant 表示映射为选择每个架构的概率：</p>
<p>$$
\begin{gathered}\hat{\alpha}_{l, i}=\mathrm{z} \cdot \frac{\mathrm{p}_{l, i}}{\left|\left|\mathrm{p}_{l, i}\right|\right|_2} \\ \alpha_{l, i}=\frac{\exp \left(\hat{\alpha}_{l, i}\right)}{\sum_{j=1}^{|\mathcal{O}|} \exp \left(\hat{\alpha}_{l, j}\right)},\end{gathered}
$$</p>
<p>其中 $\mathrm{p}_{l, i}$是可学习的prototype，表示第$i$层第$i$个操作的表示，可以看作是architecture representation。若 $\mathrm{H}^{(l)}$可以最好的匹配标签 $\mathcal{Y}$，那么等价于最大化 $I\left(\mathrm{Z}_I, \mathrm{~A}\right)$。</p>
<h2 id="invariant-guided-customization">Invariant-guided Customization</h2>
<p>上面的优化目标已经可以最大化 $I\left(\mathrm{Z}_I, \mathrm{~A}\right)$以及最小化 $I\left(\mathrm{Z}_I, \mathrm{Z}_V\right)$。最后还有一项，需要在给定 $Z_I$的情况下， $Z_V$不会对架构的选择产生影响，即最小化条件互信息 $I\left(\mathrm{~A}, \mathrm{Z}_V \mid \mathrm{Z}_I\right)$。具体来说，首先用不变pattern $Z_I$，基于架构预测器 $\psi_I$来预测架构 $A_I$。并且用 $Z_I$和 $Z_V$的混合通过辅助预测器 $\psi_E$来预测架构为 $A_E$：</p>
<p>$$
\mathrm{A}_I=\psi_I\left(\mathrm{Z}_I\right), \quad \mathrm{A}_E=\psi_E\left(\mathrm{Z}_I, \mathrm{Z}_V\right) .
$$</p>
<p>然后遍历所有图数据，优化目标是使得 所有$A_I$和 $A_E$的差异尽可能小，也就是加上 $Z_V$后，对架构的预测改变要尽可能小：</p>
<p>$$
\begin{aligned}\mathcal{L}_{\mathrm{inv}} &amp; =\sum_i^{||\mathcal{D}||} \sum_j^{||\mathcal{D}||}\left|\left|\mathrm{A}_{I, i}-\mathrm{A}_{E,(i, j)}\right|\right|, \\ \text { s.t. } \quad \mathrm{A}_{I, i} &amp; =\psi_I\left(\mathrm{z}_{I, j}\right), \mathrm{A}_{E, i, j}=\psi_E\left(\mathrm{z}_{I, i}, \mathrm{z}_{V, j}\right),\end{aligned}
$$</p>
<p>架构的预测的任务目标是使得最后一层输出 $\mathrm{H}^{(L)}$ 可以做出最好的预测：</p>
<p>$$
\mathcal{L}_{\text {task }}=\ell\left(F_{\psi\left(\mathrm{Z}_I\right)}(\mathrm{G}), \mathrm{y}\right) .
$$</p>
<p>AutoGFM的最终loss为：</p>
<p><img loading="lazy" src="/posts/2025-10-26-autogfm/5.png#center" alt="autogfm"  />
</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>NeurIPS2023《Prodigy：Enabling In-context Learning Over Graphs》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/prodigy-icl/</link>
      <pubDate>Mon, 28 Jul 2025 15:19:07 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/prodigy-icl/</guid>
      <description>NeurIPS2023 &amp;#34;Prodigy：Enabling In-context Learning Over Graphs&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p>在llm里面，In-Context Learning就是用一些新任务的问答例子来提示LLM，使得LLM不需要更新参数，也能基于这些例子来对新的任务生成输出。</p>
<p><img loading="lazy" src="/posts/2025-07-28-prodigy/1.png#center" alt="icl"  />
</p>
<p>为LM的预训练任务实际上是next token prediction的任务，由于prompt和回答只是相邻的tokens，因此 Transformer 的自注意力可以计算要补全的句子和之前token之间的关系，从而让模型动态推断出新的决策规则。In-Context Learning实际上也是一种next token prediction的任务，所以In-Context Learning是和预训练任务相关的。</p>
<p><img loading="lazy" src="/posts/2025-07-28-prodigy/2.png#center" alt="icl"  />
</p>
<p>Prodigy和All in One (KDD 2023)是同期工作，目的都是为了去提示Pretrained graph model。 All in One 是已经有一个Pretrained graph model，然后用meta learning基于冻结的pretrained model，去学一个prompt graph，使得这个prompt graph和原图结合起来之后可以使预训练模型泛化到新的任务上。</p>
<p>All in One 存在的问题是，All in one要对测试图做finetune。但实际上我们知道foundation model是不需要fine tune的。遇到一个新任务，因为支持in-context learning，可以基于给出的prompt example 来对新任务直接做出预测。而Prodigy就是不需要fine tune的graph prompt方法，它是直接以in-context learning的方式来预训练模型。Prodigy在预训练图上构造一堆prompt example和queries，预训练的优化目标是使在给定prompt examples和query set的情况下，query set的预测损失最小，也就是说<strong>模型的参数由prompt examples来调整，优化目标是使得query set的损失最小</strong>。</p>
<p><img loading="lazy" src="/posts/2025-07-28-prodigy/3.png#center" alt="icl"  />
</p>
<h2 id="prompt-graph-representation">Prompt Graph Representation</h2>
<p>首先要基于预训练的图构造一个支持in-context learning的prompt graph。然后在这个prompt graph上以in-context learning的方式来预训练模型。具体来说，在预训练图上构造一个 $m$-way $k$-shot的分类任务。预训练图为MAG240M，该图中有122M个节点，1.3B条边，153个类。 在每次训练epoch中，采样 $m=30$个class，每个class选择 $k=3$个样本作为prompt examples $\mathcal{S}$，也就是每个epoch有90个prompt examples。每个类别取4个样本作为query set $\mathcal{Q}$。也就是 $\mathcal{S} = \{(x_i, y_i)\}^{mk}_{i = 1}$ 作为预训练阶段的support set。 $\mathcal{Q} = \{x_i\}^n_{i = 1}$作为预训练阶段的query set，也就是预训练阶段的优化目标是要在query set上的损失最小。</p>
<p><strong>Data Graphs</strong>：若预训练任务是node-level的任务，那么每个数据点集 $\mathcal{V}_i$是一个目标节点，如果是edge level的任务，那么每个数据点集 $\mathcal{V}_i$是一对节点。然后，通过采样每个数据点集的 $k$跳局部子图来contextualize每个数据点集，从而为所有prompt examples和query set构造Data Graphs：
$$
\mathcal{G}_i^{\mathrm{D}}=\left(\mathcal{V}_i^{\mathrm{D}}, \mathcal{E}_i^{\mathrm{D}}\right) \sim \bigoplus_{i=0}^k \operatorname{Neighbor}\left(\mathcal{V}_i, \mathcal{G}, i\right)
$$</p>
<p><strong>Message Passing on Data Graphs</strong>：然后每个Data Graph有一个Super Node $v_{x_i}$，来得到上下文化的目标节点表示。具体来说，在Data Graph上做message，然后把目标节点的embedding拿出来作为super node的node feature。</p>
<p><strong>Task Graph</strong>：在每次预训练迭代中，有30个class参与预训练，那么就有30个label nodes $v_y$。然后将所有super nodes和label nodes 连接起来，用边来反映数据点和label之间的关系，具体来说，每条边的特征有2个binary value构成，如果目标数据点是来自prompt set的节点，那么第一个属性为 $0$，如果是来自query set的数据点，那么第一个属性为 $1$。在task graph中，每个超节点和所有label node连接，如果prompt example的超节点连接到正确的label node，那么第二个属性为 $1$，如果连到错误的label，那么边的第二个属性为 $-1$。</p>
<p><img loading="lazy" src="/posts/2025-07-28-prodigy/4.png#center" alt="icl"  />
</p>
<p><strong>Message Passing on Task Graph</strong>：在得到每条边的feature $e_{ij}$后，在Task Graph上做attention-based message passing。也就是每个label node要聚合所有super nodes，每个super nodes也要聚合所有label nodes。
$$
\begin{aligned}\beta_{i j} &amp; =M L P\left(W_q^T H_i^l\left|\left|W_k^T H_j^l\right|\right| e_{i j}\right) \\ \alpha_{i j} &amp; =\frac{\exp \left(\beta_{i j}\right)}{\sum_{k \in \mathcal{N}(i) \cup{i}} \exp \left(\beta_{i k}\right)} \\ H_i^{l+1} &amp; =\operatorname{ReLU}\left(B N\left(H_i^l+W_o^T \sum_{j \in \mathcal{N}(i) \cup{i}} \alpha_{i j} W_v^T H_j^l\right)\right)\end{aligned}
$$</p>
<h2 id="pretraining-task-generation">Pretraining Task Generation</h2>
<p>2个预训练任务：<strong>Neighbor Matching</strong>和<strong>Multi-Class Classification</strong>。</p>
<p><strong>Neighbor Matching</strong>：在每次training epoch，随机采样 $m=30$个节点作为 $30$个way，然后每个采样的节点选择 $k=3$个邻域内节点作为这个类的prompt examples。然后所有label nodes的特征从Uniform distribution上初始化：</p>
<p>$$
\begin{gathered}\mathcal{C}=\left\{c_i\right\}_{i=1}^m \quad c_i \sim \operatorname{Uniform}\left(\mathcal{V}_{\text {pretrain }}\right) \\ N_i=\text { Neighbor }\left(c_i, \mathcal{G}_{\text {pretrain }}, l\right) \\ \mathcal{S}_i=\left\{\left(x_j, y_j=c_i\right)\right\}_{j=1}^k \quad x_j \sim \operatorname{Uniform}\left(N_i\right) \\ \mathcal{Q}_i=\left\{\left(x_j, y_j=c_i\right)\right\}_{j=1}^{\left\lceil\frac{n}{m}\right\rceil} \quad x_j \sim \operatorname{Uniform}\left(N_i\right)\end{gathered}
$$</p>
<p><strong>Multi-Class Classification</strong>：用原始label来构造预训练任务，label node的feature依旧从uniform distribution中采样：</p>
<p>$$
\begin{gathered}\mathcal{C}=\left\{c_i\right\}_{i=1}^m \quad c_i \sim \operatorname{Uniform}(\mathcal{Y}) \\ \mathcal{S}_i=\left\{\left(x_j, y_j=c_i\right)\right\}_{j=1}^k \quad x_j \sim \operatorname{Uniform}\left(\left\{x_i \mid f\left(x_i\right)=c_i\right\}\right) \\ \mathcal{Q}_i=\left\{\left(x_j, y_j=c_i\right)\right\}_{j=1}^{\left\lceil\frac{n}{m}\right\rceil} \quad x_j \sim \operatorname{Uniform}\left(\left\{x_i \mid f\left(x_i\right)=c_i\right\}\right)\end{gathered}
$$</p>
<p>通过计算每个super node和所有label node的cosine similarity 来得到预测的logits：</p>
<p>$$
O_i=\left[\operatorname{cosine} \_ \text {similarity }\left(H_{x_i}, H_y\right), \forall y \in \mathcal{Y}\right]
$$</p>
<p>模型的优化目标是在NM和MT这两个预训练任务的query set上的损失最小：</p>
<p>$$
\mathcal{L}=\underset{x_i \in \mathcal{Q}_{\mathrm{NM}}}{\mathbb{E}} \operatorname{CE}\left(O_{\mathrm{NM}, i}, y_{\mathrm{NM}, i}\right)+\underset{x_i \in \mathcal{Q}_{\mathrm{MT}}}{\mathbb{E}} \operatorname{CE}\left(O_{\mathrm{MT}, i}, y_{\mathrm{MT}, i}\right)
$$</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ICML2024《LLaGA：Large Language and Graph Assistant》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/llaga/</link>
      <pubDate>Mon, 28 Jul 2025 15:09:11 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/llaga/</guid>
      <description>ICML2024 &amp;#34;LLaGA：Large Language and Graph Assistant&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p>目的：将图结构调整为适配LLM的输入。具体来说，将图节点表示为<strong>图结构感知</strong>和<strong>属性感知</strong>的序列，然后将序列映射到token embedding space中，从而使LLM可以用处理text tokens的方式来对Graph token embeddings进行处理。为了实现这个目标，就要求node sequence必须充分保存中心节点的结构信息。</p>
<h2 id="structure-aware-graph-translation">Structure-Aware Graph Translation</h2>
<p>LLaGA的目的是将graph翻译成可被LLM理解的token embedding sequence的形式。同时，这可以利用LLM固有的推理能力来处理图的任务，并且无需改变LLM的参数（foundation model）。为了实现这个目标，LLaGA将图结构转化为node embedding sequences，这些sequences融合了图的局部和更大范围的结构信息，然后将node embedding sequences通过一个projector转化为LLM可以处理的token embedding sequence。</p>
<p>第一步是将图转换为node embedding sequences。由于图分析的基本单位是节点，所以本工作开发了2个节点级templates，这些templates是多功能的，不仅可以用于节点级任务，也可以用于边级任务。分别是一个<strong>Neighborhood Detail Template</strong>，提供对中心节点及其周围环境的深入观察；<strong>Hop-Field Overview Template</strong>，提供了一个节点邻居的总结视角，可以拓展到更大的域。<strong>这两个模板都旨在编码节点周围的结构信息</strong>，为分析提供不同的视角。</p>
<h3 id="neighborhood-detail-template"><strong>Neighborhood Detail Template</strong></h3>
<p>Neighborhood Detail Template用于描述节点和其周围邻居的详细信息。给定一个中心节点 $v$，需要构造一个形状固定的tree。对于中心节点 $v$的每跳邻居，定义一组邻居采样的size： $n_1$, $n_2$, …，其中 $n_i$表示第 $i$跳邻居的采样数量。对于 $1$-hop邻居集合 $\mathcal{N}_v^1$，从其中随机采样 $n_1$个邻居，表示为 $\widetilde{\mathcal{N}}_v^1$。如果 $\left|\mathcal{N}_v^1\right|&lt;n_1$，那么用placeholder nodes来补全 $n_1$个邻居。注意，这里定义的每跳邻居的采样数量 $n_1, n_2, \cdots$是应用于所有节点的。得到的 $v$-centered tree如下图所示：</p>
<p><img loading="lazy" src="/posts/2025-07-28-llaga/0.png#center" alt="icl"  />
</p>
<p>这里定义 $n_2 = 3$，如果2跳邻居不满3个节点，那么用 placeholder node  $[\text{pad}]$来占位。然后我们从tree的中心节点开始遍历，可以把这棵计算树转换为一个固定长度的node sequence。这个node sequence描述了以 $A$为中心的局部邻域内的节点相对结构位置（从近到远）。</p>
<p>上面的步骤将中心节点和它的结构信息编码成一个节点序列，然后我们需要把这个节点序列映射到embedding space中。对于TAG（Text-Attributed Graph），使用现成的语言模型 $\phi$，例如SBERT，RoBERTa或SimTeG来编码文本信息，placeholder node的特征被编码为 $0$向量。然后进一步融合结构信息，每个节点在tree中的结构信息用Laplacian Embedding来表示，也就是拉普拉斯矩阵的特征向量在node id的位置来表示这个node在Tree中的结构信息，也就是相邻的节点有相似的embedding：</p>
<p>$$
L=I-\mathcal{D}^{-\frac{1}{2}} \mathcal{A}_{\text {tree }} \mathcal{D}^{-\frac{1}{2}}=U^T \Lambda U
$$</p>
<p>其中 $U$的每行表示对应节点的Laplacian Embedding。注意到，我们预训练的时候，只需要计算一次Laplacian Embedding，以为对于任何图中的任何节点，都为它构造一样的computational tree，所以Laplacian Embedding是不变的。对于计算树induced node sequence $v_1, v_2, \cdots, v_n$，那么这个计算树中的节点 $v_i$的最终node embedding表示为：</p>
<p>$$
h_{v_i}= \begin{cases}\mathbf{0} || U_i, &amp; \text { if } v_i=[p a d] ; \ \phi\left(x_{v_i}\right) || U_i, &amp; \text { otherwise }\end{cases}
$$</p>
<p>它结合了文本信息和节点与领域内其他节点的相对位置信息。</p>
<h3 id="hop-field-overview-template">Hop-Field Overview Template</h3>
<p><img loading="lazy" src="/posts/2025-07-28-llaga/1.png#center" alt="icl"  />
</p>
<p>Hop-Field Overview Template提供的是一个关于中心节点和其邻居的总结视角。**Neighborhood Detail Template中sequence的每个元素是一个节点，Hop-Field Overview Template中每个元素是一跳节点的总结。**首先，用LM来初始话每个节点的特征，节点 $v$的初始特征为 $h_x^0=\phi\left(x_v\right)$。定义parameter-free message passing on encoded text features：</p>
<p>$$
h_v^i=\frac{1}{\left|\mathcal{N}_v^1\right|} \sum_{v^{\prime} \in \mathcal{N}_v^1} h_{v^{\prime}}^{i-1}
$$</p>
<p>$h_v^1=\frac{1}{\left|\mathcal{N}_v^1\right|} \sum_{v^{\prime} \in \mathcal{N}_v^1} h_{v^{\prime}}^{0}$表示节点 $v$的 $1$-hop邻居的summarized embedding，即直接聚合邻居的原始特征。 $h_v^i$表示聚合邻居的 $i-1$阶特征，也就是 $v$的 $i$hop以内邻居的summarized embedding。那么可以依据中心节点和hop顺序关系构造一个序列 $h_v^1, h_v^2,\cdots$，用来表示中心节点和它的相对结构信息。这个方法牺牲了更多细节，但是保留了更广的感受野。</p>
<h3 id="mapping-node-embeddings-into-llms-token-space">Mapping Node Embeddings into LLM’s token space</h3>
<p>用于对齐节点的embedding space和LLM的token space，使得节点序列可以作为LLM的输入。定义一个可训练的projector $f_\theta$：</p>
<p>$$
e_i=f_\theta\left(h_i\right)
$$</p>
<p>用来将序列中的每个节点embedding映射到token space。然后，node embedding sequence $h_1, h_2,\cdots, h_n$可以被转换成token embeddings $e_2, e_2,\cdots, e_n$。LLaGA中唯一的训练参数就是这个projector $f_\theta$。</p>
<h3 id="alignment-tuning">Alignment Tuning</h3>
<p><img loading="lazy" src="/posts/2025-07-28-llaga/2.png#center" alt="icl"  />
</p>
<p>LLaGA采用3个预训练任务：节点分类，链路预测和<strong>节点描述（Node description）。<strong>其中，Node description任务用于将node embedding和特定文本描述对齐。这个特殊任务能够提供图的丰富语义解释，从而更深入地了解基于图的预测背后的逻辑。将这些预训练projector的任务统一成</strong>Questions and Answers</strong>的形式：</p>
<p>Questions: Please describe the center node: <!-- raw HTML omitted -->.</p>
<p>Answers: The center node represents a [paper / products /&hellip;], it’s about [node description].</p>
<p>在训练过程中，以chat的形式在组织问答，Vicuna-v1.5 (Chiang et al., 2023) 作为LLaGA的LLM模型。如上图step 2所示，在处理Freezed LLM的输入阶段，将SYSTEM MESSAGE，USER: [Give you a node] 都tokenize，然后将node sequence 替换为projected node embedding $e_1, e_2, \cdots$，然后将后面描述任务的prompt也tokenize，训练的优化目标是最大化生成正确答案的概率：</p>
<p>$$
\underset{\theta}{\operatorname{maximize}} \quad p\left(X_{\text {answer }} \mid X_{\text {graph }}, X_{\text {question }}, X_{\text {system }}\right)
$$</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>NeurIPS2024《GFT：Graph Foundation Model with Transferable Tree Vocabulary》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/gft/</link>
      <pubDate>Mon, 28 Jul 2025 14:49:00 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/gft/</guid>
      <description>NeurIPS2024 &amp;#34;GFT：Graph Foundation Model with Transferable Tree Vocabulary&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p>本文的目的是在预训练图上训练一组通用的图词汇表（vocabulary）作为图上可迁移的通用pattern，这些词汇表可应用于跨领域的多任务中。</p>
<h2 id="gnn的可迁移性">GNN的可迁移性</h2>
<p>可迁移性指的是模型从source task中提取模式，这些模式的知识可以增强对目标任务的预测。近期的工作通过识别与各种任务相关的关键子结构，来研究图上可迁移的词汇表。例如，三元闭包（triadic closure），同质性，异质性对于节点分类至关重要；一些motif，比如三角形，k-cliques，和star，是图分类的基本组成成分，这些子结构可以作为通用可迁移的pattern，基于这些子结构在不同图中的形式，或者研究图具有怎样的子结构组成，可以推断图在各种任务上的表现。</p>
<p>拿自然语言来类比，positive sub-vocabulary 可以是 [happy, nice, great, … ]；negative sub-vocabulary 可以是[upset, bad, worse, … ]，对于一个句子，只需要用它来检索这个词汇表，就可以对这个句子是积极或者消极做出分类。</p>
<p>对于Graph也是一样，构建一些通用的子结构，下游graph去检索这些子结构，基于子结构的性质来对图的性质做出推理。</p>
<h2 id="计算树computation-tree作为可迁移的graph-pattern">计算树（computation tree）作为可迁移的graph pattern</h2>
<p>Computation Tree：对于一个图 $\mathcal{G}(\mathcal{V}, \mathcal{E})$，关于节点 $v$，它的 $L$ 层计算树为 $\mathcal{T}_v^L$，且 $\mathcal{T}_v^1 = v$。这个tree通过递归融合邻居的子树得到。对于图 $\mathcal{G}$，它的 $L$层子树的集合可以表示为一个multiset： $\mathcal{T}_{\mathcal{G}}^L:=\left\{\mathcal{T}_v^L\right\}_{v \in \mathcal{V}}$ 。</p>
<h3 id="为什么计算树比其他子结构如motif更适合做通用的vocabulary">为什么计算树比其他子结构（如motif）更适合做通用的vocabulary？</h3>
<p>首先，节点级、边级、图级任务都可以表示为计算树的分类任务。如下图所示：</p>
<p><img loading="lazy" src="/posts/2025-07-28-GFT/0.png#center" alt="icl"  />
</p>
<p>计算树可以捕获图中重要的局部子树模式。如果两个节点的 $L$层计算树相似（同时考虑节点和特征），那么表明这两个节点共享相似的邻域信息，则这两个节点具有类似现象（analogous phenomena）。</p>
<p><strong>两个具有相似计算树的图，是否以为这模型在这两个图上的迁移性更好？（Yes）</strong></p>
<p>两个图具有相似的其他子结构（如motif），并<strong>不一定</strong>意味着两个图之间模型的迁移性更好</p>
<p>Theorem 2.2：</p>
<p>$$
\Delta \triangleq\left|\left|\phi\left(\mathcal{T}_{v_1}\right)-\phi\left(\mathcal{T}_{v_2}\right)\right|\right|_2 \leq \mathcal{C}_1 \left| \left| \mathbf{x}_{v_1}-\mathbf{x}_{v_2}\right|\right|_2+\mathcal{C}_2 \sum_{j \in \mathcal{N}(v)} \Delta_{v_1, v_2, j}^{L-1} \leq 2 \mathcal{B}_{\mathbf{x}}\left(\mathcal{C}_1+\sum_{l=1}^L \mathcal{C}_2^l D_l\right)
$$</p>
<p>上面定理表示，一个GNN模型 $\phi$对两个计算树计算embedding的相似度，一定会被两个计算树的子树相似度bound，也就是说，<strong>如果两个计算树相似，那么GNN一定可以为他们计算相似的embedding，从而做出相似度预测，所以GNN在这两个子树上具有较好的可迁移性</strong>。如下图所示，motif的相似度并不意味着更高的准确率，99.01的motif相似度，实际上的准确率很低，但计算树的相似度可以反映相似度，所以可以作为图上可迁移的vocabulary，下游图可以检索vocabulary计算树来推测性质。</p>
<p><img loading="lazy" src="/posts/2025-07-28-GFT/1.png#center" alt="icl"  />
</p>
<h2 id="pre-training-with-computation-tree-reconstruction">Pre-training with Computation Tree Reconstruction</h2>
<p>GFT采用Vector Quantization (VQ, 参考VQ-VAE)来开发计算树词汇表。对于一个图数据库 $\mathcal{D} = \{\mathcal{G}_i\}^n_{i = 1}$，从中提取一个集合的计算树 $\mathcal{T}=\left\{\mathcal{T}_i\right\}_{i=1}^m$。通过GNN $\phi$可以得到 $m$个computation tree的embedding： $\mathcal{Z}=\left\{\mathbf{z}_i\right\}_{i=1}^m$。然后定义一组codebooks为可学习的tokens $\mathbf{C}=\left\{\mathbf{c}_1, \ldots, \mathbf{c}_K\right\}$，那么tree embedding space被量化为将每个tree embedding分配给最近的codebook token（类似于k-means，但没有明确的k）。那么对于tree embedding $\mathbf{z}_i$，它所属的codebook token 为 $\mathbf{q}_i=\mathbf{c}_j$，其中 $j=\arg \min _j\left|\left|\mathbf{z}_i-\mathbf{c}_j\right|\right|_2 .$ 那么对于 $m$个数，可以将他们分配給 $K$个codebook tokens 作为长度为 $K$的词汇表。通过vocabulary loss和commitment loss来优化tree embedding和codebook tokens，可以得到预训练目标函数：</p>
<p>$$
\mathcal{L}_{\text {pretrain }}=\mathcal{L}_{\text {tree }}+\underbrace{\frac{1}{m} \sum_{i=1}^m\left|\left|\operatorname{sg}\left[\mathbf{z}_i\right]-\mathbf{c}_i\right|\right|_2^2}_{\text {vocabulary loss }}+\beta_1 \cdot \underbrace{\frac{1}{m} \sum_{i=1}^m\left|\left|\mathbf{z}_i-\operatorname{sg}\left[\mathbf{c}_i\right]\right|\right|_2^2}_{\text {commitment loss }}
$$</p>
<p>先看后面两项，目的是可微地将 $m$个tree embedding压缩为 $K$个向量， $\mathrm{sg}[\mathbf{z}_i]$是stop-gradient的意思，即前向传播得到 $\mathbf{z}_i$后，block $\mathbf{z}_i$回传的梯度，也就是把 $\mathrm{sg}[\mathbf{z}_i]$视为constant来优化 $\mathbf{c}_j$。commitment loss同理。</p>
<p><strong>Computation Tree Reconstruction.</strong> 除了vocabulary loss和commitment loss联合训练codebooks和tree embedding外，本文还引入了一个树重建任务使得学习到的词汇表可以深入理解计算树的结构和语义属性。</p>
<ol>
<li>对于每个计算树 $\mathcal{T}_i$所属的token $\mathbf{q}_i \in \mathbf{C}$，它应当具备重构计算树root node 特征 $\mathbf{x}_i$的能力（codebook token要充分学习它包含的计算树的结构和属性信息）：</li>
</ol>
<p>$$
\mathcal{L}_{\text {feat }}=\frac{1}{m} \sum_{i=1}^m\left|\left|\hat{\mathbf{q}_i^2}-\mathbf{x}_i\right|\right|_2^2
$$</p>
<ol>
<li>计算树token $\mathbf{q}_i$ 要能够重构树 $\mathcal{T}_i$的总体语义信息 $\mathbf{z}_i$：</li>
</ol>
<p>$$
\mathcal{L}_{s e m}=\frac{1}{m} \sum_{i=1}^m\left(1-\frac{\hat{\mathbf{q}}_i^{1^T} \hat{\mathbf{z}_i}}{\left|\left|\hat{\mathbf{q}_i^1}\right|\right|\left|\left|\hat{\mathbf{z}}_i\right|\right|}\right)^\gamma
$$</p>
<ol>
<li>对于有边连接的节点，他们的两个计算树 $\mathcal{T}_i$ 和 $\mathcal{T}_j$所属的codebook token $\mathbf{q}_i$和 $\mathbf{q}_j$要相似：</li>
</ol>
<p>$$
\mathcal{L}_{\text {topo }}=\sum_{(i, j) \in \mathcal{E},\left(i, j^{\prime}\right) \in \hat{\mathcal{E}}}-\frac{1}{|\mathcal{E}|} \log \left(\sigma\left(\hat{\mathbf{q}}_i^{\mathbf{3}^T} \hat{\mathbf{q}}_j^3\right)\right)-\frac{1}{|\hat{\mathcal{E}}|} \log \left(1-\sigma\left(\hat{\mathbf{q}}_i^{\mathbf{3}^T} \hat{\mathbf{q}}_{j^{\prime}}^3\right)\right)+\frac{1}{|\mathcal{E}|}\left|\left|\left[\mathbf{q}_i^4 || \mathbf{q}_j^4\right]-\mathbf{e}_{i j}\right|\right|_2^2
$$</p>
<p>所以预训练loss $\mathcal{L}_{\text {pretrain }}$中的 $\mathcal{L}_{\text {tree }}$定义为如下形式：</p>
<p>$$
\mathcal{L}_{\text {tree }}=\beta_2 \cdot \mathcal{L}_{\text {feat }}+\beta_3 \cdot \mathcal{L}_{\text {sem }}+\beta_4 \cdot \mathcal{L}_{\text {topo }}
$$</p>
<p>为了增强tree vocabulary的质量，不同的词汇应具备一定的区分性，所以regularize the tree vocabulary space by intentionally <strong>increasing the distance between distinct tokens</strong>：</p>
<p>$$
\mathcal{L}_{\text {ortho }}=\lambda \frac{1}{K^2}\left|\left|\mathbf{C C}^T-\mathbf{I}_K\right|\right|_F^2, \quad \mathbf{C}=\left[\mathbf{c}_1, \ldots, \mathbf{c}_K\right]^T \in \mathbb{R}^{K \times d^{\prime}}
$$</p>
<h2 id="fine-tuning-with-computation-tree-classification">Fine-tuning with Computation Tree Classification</h2>
<p>预训练阶段将通用知识编码到Tree vocabulary中，Fine-tuning阶段将这些知识应用于特定的预测任务。首先将节点级、边级、图级任务全部统一成tree-level task。</p>
<ul>
<li>节点分类：任务特定的树表示为 $\mathcal{T}_{node}  =\mathcal{T}_i$，embedding为 $\mathbf{z}=\phi\left(\mathcal{T}_i\right)$。</li>
<li>链接预测：任务特定的树表示为 $\mathcal{T}_{\text {link }}=\operatorname{Combine}\left(\mathcal{T}_s, \mathcal{T}_t\right)$， embedding为 $\mathbf{z}=\operatorname{mean}\left(\phi\left(\mathcal{T}_s\right), \phi\left(\mathcal{T}_t\right)\right)$。</li>
<li>图级分类：任务特定的树表示为 $\mathbf{z}=\operatorname{mean}\left(\phi\left(\mathcal{T}_s\right), \phi\left(\mathcal{T}_t\right)\right)$。</li>
</ul>
<p>然后，任务特定的计算树通过查询tree vocabulary来做出预测，从而将词汇表中的通用知识用于各种任务和领域。</p>
<p><strong>Prototype Classifier</strong>. 给定一组任务特定的计算树 $\left\{\left(\mathcal{T}_i, y_i\right)\right\}_{i=1}^n$包含 $|C|$个类别，需要预测这个计算树的类别。对于一个预训练好的GNN $\phi$，可以为这些计算树生成embeddings $\mathcal{Z}=\left\{\mathbf{z}_i\right\}_{i=1}^n$。这些embedding用于查询tree vocabulary 然后可以得到每个计算树所属的codebook token $\mathcal{Q}=\left\{\mathbf{q}_i\right\}_{i=1}^n$。然后，对于每个类别有一定数量的计算树用于训练，对于训练计算树，构造一个memory bank $\mathbb{S}=\left\{\mathbb{S}^1, \ldots, \mathbb{S}^{|C|}\right\}$用来保存构构成每个类别的codebook token，其中 $\mathbb{S}^k = \{\mathbf{q}_i \in \mathcal{Q} | y_i = k\}$，表示那些用于构成类别 $k$的codebook tokens。那么，class prototype就是用于表示这些类的tokens的结合：
$$
\mathbf{p}_k=\frac{1}{ \left|\mathbb{S}^k\right|} \sum_{\mathbf{q}_i \in \mathbb{S}^k} \mathbf{q}_i
$$</p>
<p>这些类prototype可以用于对测试计算树的预测。若测试计算树的GNN embedding为 $\mathbf{z}$，那么它的第 $k$个类别的预测结果如下：</p>
<p>$$
p(y=k \mid \mathbf{z})=\frac{\exp \left(-\operatorname{sim}\left(\mathbf{z}, \mathbf{p}_k\right) / \tau\right)}{\sum_c \exp \left(-\operatorname{sim}\left(\mathbf{z}, \mathbf{p}_c\right) / \tau\right)}
$$</p>
<p>通过上面的概率在下游图的训练集上fine-tuning模型。为什么要fine tuning，因为对于不同的图，同一个计算树可能的作用也是不一样的，所以要通过这种方式来让计算树的embedding变得task specific，使得每个类别有最适合它的计算树。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ICLR2025《GOFA：A Generative One-For-All Model for Joint Graph Language Modeling》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/gofa/</link>
      <pubDate>Mon, 28 Jul 2025 14:35:16 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/gofa/</guid>
      <description>ICLR2025 &amp;#34;GOFA：A Generative One-For-All Model for Joint Graph Language Modeling&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p>GOFA是OFA（ICLR 2024）的后续工作，用来解决OFA中存在的一些问题。</p>
<p><img loading="lazy" src="/posts/2025-07-28-Gofa/6.png#center" alt="icl"  />
</p>
<p>OFA用NOI Prompt Node来统一不同的分类任务，也就是用不同的NOI Prompt Node来表示不同的分类任务，然后用任务的文本描述作为这些表示任务的节点的文本特征，LLM 编码来数值化这个节点的初始特征，任务对应的label也用节点（Class Node）来表示，然后用每个class的文本描述作为这个Class Node的特征。GNN的训练目标就是训练NOI Prompt node的embedding 和class node的embedding，对于某个节点，如果我们要预测它关于某个任务的标签，只需要把它和这个任务对应的NOI Prompt Node连接起来，根据输出就可以知道这个节点在该任务下的标签。</p>
<p>但是，OFA存在以下问题：必须是已知任务，无法泛化到新的任务，因为新的任务NOI Prompt Node 未知，也不知道新任务的Class Node是什么， 因此下游任务必须得是预训练阶段见过的任务，不能是一个全新的任务。此外，可以看出由于OFA是一个supervised foundation model，所以他和参与训练的任务标签是强相关的，很难泛化到训练阶段没有见过的任务，GOFA就是用来解决OFA存在的问题，GOFA认为foundation model的训练过程应该不能有标签信息加入的，也就是需要是自监督的。</p>
<h2 id="unified-task-formats">Unified Task Formats</h2>
<p>模型的输入必须要统一，所以和过去的很多方法一样，GOFA用TAG来统一所有graph：</p>
<p>$$
G=\left\{V, E, X_V, X_E\right\}
$$</p>
<p>自监督语言模型里面，模型训练的目标叫next-token prediction 通常是补全句子，比如给定一个句子，自监督语言模型的训练目标是基于这个句子来预测生下来的tokens，假设剩下来的token是apple，参数优化的目标就是使生成apple的likelihood要最大， 如下图所示：</p>
<p><img loading="lazy" src="/posts/2025-07-28-Gofa/1.png#center" alt="icl"  />
</p>
<p>GOFA提出的自监督图模型，也继承这种做法，模型学习的目标是补全TAG图，有个目标节点，叫node of generation，也就是自监督学习要补全的节点，把它的文本属性截断，然后自监督学习的目标就是要生成这个NOG node 的剩下内容。但是，如果要生成这个节点剩下的内容的话，不能无视这种图中的边信息，因为图的结构可以帮助这个自监督任务生成正确的信息，所以自监督图模型需要充分理解图结构。比如上图中的Target就需要在理解边关系的情况下补全句子，因此，模型需要充分学习图结构。</p>
<h2 id="gofa-generative-one-for-all-model">GOFA: Generative One-For-All Model</h2>
<p>怎么才能在充分学习图结构的情况下，补全目标节点的text，是GOFA的主要目标。</p>
<p><img loading="lazy" src="/posts/2025-07-28-Gofa/2.png#center" alt="icl"  />
</p>
<p>GOFA主要由2个模块组成，一个是Graph Language Encoder，还有一个是LLM Decoder。其中Graph Language Encoder的目的是用来学习节点的表示向量， 其中交替训练了LLM compressor和GNNlayer，LLM compressor用来学习TAG graph中的语义信息，GNN用来学习结构关系信息（也就是NOG Node和其他节点的交互）。因为GNN已经可以学到图的结构信息了，LLM compressor的作用就是把文本信息压缩到GNN学习的节点表示中。 第二个模块是一个LLM decoder，它的训练目标是，基于节点的向量表示，预测下一个token。</p>
<h3 id="graph-language-encoder">Graph Language Encoder</h3>
<p>Graph Language Encoder 包含LLM compressors和GNN Layers。对于一个NOG Node的text attribute，若它由 $l$个tokens组成 $\{x_i\}_{i = 1}^l$，通过一个pretrained LLM 比如Mistral-7B，可以将每个token映射为一个token embedding $q(x_i)$。那么将NOG Node的所有token $\left\{q\left(x_i\right)\right\}_{i=1}^l$ pooling成一个向量可以作为NOG Node的node feature vector。但是这种做法丢失太多semantic information。</p>
<p><strong>Solution:</strong> 将NOG Node的text attribute压缩为 $K$个向量，且 $K &laquo;l$。具体来说，首先定义 $K$个memory tokens $\{m_1, \cdots. m_K \}$ with their lookup initial embeddings $\left\{q\left(m_j\right)\right\}_{j=1}^K$用于接收压缩后的text tokens。</p>
<p><img loading="lazy" src="/posts/2025-07-28-Gofa/3.png#center" alt="icl"  />
</p>
<p>然后把 $l$个text tokens和 $K$个memory tokens 拼起来输入到LLM Compressor Layer1，由于LLM的是<strong>multiple transformer layers</strong> (self-attention mechanisms)，因此可以捕获memory tokens和text tokens之间的dependencies。所以通过这种方式，text tokens的信息可以被压缩到memory tokens中。</p>
<p><img loading="lazy" src="/posts/2025-07-28-Gofa/4.png#center" alt="icl"  />
</p>
<p>此时，这个目标节点（NOG Node）的特征向量就被压缩到 $K$个token embeddings，但是这个时候 $K$个memory tokens并没有学到图的结构信息。为了编码图的结构信息，将这 $K$个memory token embeddings作为node features输入GNN中，做一个 $K$通道的聚合GNN。通过上图中的Token-level Message Passing，可以将图的结构信息编码到 NOG Node的 $K$个memory tokens中，然后将GNN处理过的memory token embeddings再和text token embeddings拼起来，用LLM compressors将文本信息压缩到 memory token embeddings中。经过 $L$次的交替LLM压缩和训练GNN后，这里得到的 $K$个memory token可以认为是充分节点的text 信息和图的结构信息。</p>
<h3 id="llm-decoder">LLM Decoder</h3>
<p><strong>The memory tokens $Q_{m,x}$ ( $m$:memory; $x$: 节点 $x$) of every node contain information about the text on the node, the surrounding node text, and the graph structure due to the message-passing process in the GNN layers.</strong> 然后，对于NOG节点 $v$，它的completion target 是 $y$，GOFA将NOG Node的memory tokens $Q_{m,x}$插入到target text tokens的前面，然后输入LLM Decoder中来生成下一个token。优化目标是最大化completion target 的log likelihood，也就是生成正确tokens的概率。</p>
<p>$$
\operatorname{CrossEntropy}\left(\left\{l\left(m_K\right), l\left(x_1\right), \ldots, l\left(x_{l-1}\right)\right\},\left\{x_1, \ldots, x_l\right\}\right) .
$$</p>
<p>在GOFA的influence阶段，输入一个新图和每个节点的text attribute，并且给出目标节点NOG Node，就可以补全该NOG Node。</p>
<p><img loading="lazy" src="/posts/2025-07-28-Gofa/5.png#center" alt="icl"  />
</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ICLR2024《One for All：Towards Training One Graph Model for All Classification Tasks》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/ofa/</link>
      <pubDate>Wed, 21 May 2025 11:57:35 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/ofa/</guid>
      <description>ICLR2024 &amp;#34;One for All：Towards Training One Graph Model for All Classification Tasks&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><strong>What is in-context learning?</strong></p>
<p>“In-Context Learning is a way to use LLMs to learn tasks given only a few examples. During in-context learning, we give the LM a prompt that consists of a list of input-output pairs that demonstrate how to perform a task. At the end of the prompt, we append a test input and allow the LM to make a prediction just by conditioning on the prompt and predicting the next tokens. For example, to answer the two prompts below, the model needs to examine the training examples to figure out the input distribution (financial or general news), output distribution (Positive/Negative or topic), input-output mapping (sentiment or topic classification), and the formatting. “</p>
<p><img loading="lazy" src="/posts/2025-05-21-OFA/1.gif#center" alt="icl"  />
</p>
<p>如上图所示，在prompt中包含一些上下文input-output pairs来演示（demonstrate）如何执行任务。在这些prompt的最后添加text input token来让LLM学习上下文中的演示来执行text input token的任务。</p>
<h2 id="challenge"><strong>Challenge</strong></h2>
<p>Foundation Model指用单一模型来解决多个任务。但是Graph Foundation Model面临以下挑战：（1）不同来源的图数据在feature表征上通常完全不同。比如molecular graph中的节点特征是其中原子nominal feature的索引，e-commerce networks中的节点特征通常用Bag-of-Word来编码。这些不同来源的图数据特征维度、语义信息和尺度的差别都很大，几乎不可能用同一个模型来学习他们的表示。（2）不同的下游任务涉及图的不同部分（节点级、边级、图级）需要不同的策略和方法来学习表示。（3）如何设计统一的模型来实现跨领域和in-context learning是不确定的。</p>
<h1 id="ofa">OFA</h1>
<h2 id="用tag来统一不同领域的图都转化为tag形式">用TAG来统一不同领域的图（都转化为TAG形式）</h2>
<p><strong>将不同Domian的图转化为统一的TAG形式</strong></p>
<p>用human-interpretable language来描述节点和边的属性，从而使LLM可以将这些text attribute编码到同一个空间。具体来说，通过以下方式来生成每个节点的text feature:
将不同domain的graph的节点属性用统一形式的文本来描述，如上图中，对于一个节点的特征，它的文本描述以<strong>Feature node</strong>开头，后面的每个</p>
<p><img loading="lazy" src="/posts/2025-05-21-OFA/node_text_feature.jpg#center" alt="node_text_feature.jpg"  />
</p>
<p>将不同domain的graph的节点属性用统一形式的文本来描述，如上图中，对于一个节点的特征，它的文本描述以<strong>Feature node</strong>开头，后面的每个 $&lt;\text{feature describe}&gt;:&lt;\text{feature content}&gt;$是该节点的一个type-content文本对。例如对于一个molecule graph，其中的一个节点是原子，那么它的type是<strong>Atom</strong>，它的content是该原子的属性文本描述<strong>Carbon, Atomic number 6, helix chirality</strong>。如果是Citation Network， type是“Paper title and abstract”，content是“Attention is all you need. balabala”  （该文章具体的标题和摘要）
同理，边的text feature以<strong>Feature edge</strong>开头进行文本描述。</p>
<p>在用以上方式得到节点 $v_i$的text feature $s_{v_i}$和边 $e_{ij}$的text feature $s_{e_{ij}}$后，用LLM（sentence transformer, e5-large-v2, or Llama2）来将每个节点和边的text feature编码为vector embeddings：</p>
<p>$$
x_i = \operatorname{LLM}(s_{v_i}), \quad x_{ij} = \operatorname{LLM}(s_{e_{ij}})
$$</p>
<h2 id="用nodes-of-interest-noi来统一不同的图任务">用Nodes-of-Interest (NOI)来统一不同的图任务</h2>
<p>图上的任务主要分为3中：node-level tasks，link-level tasks和graph-level tasks。如果要用一个模型来处理这些任务的话，<strong>需要将这些任务统一为一个任务以便于在图数据上训练</strong>。</p>
<p><img loading="lazy" src="/posts/2025-05-21-OFA/NOI.jpg#center" alt="NOI.jpg"  />
</p>
<p>Nodes-of-Interest (<strong>NOI</strong>)指的是一个任务的<strong>目标节点（任务感兴趣的节点）</strong>，如上图的蓝色节点所示，表示为 $\mathcal{T}$。</p>
<ol>
<li>对于节点级任务，NOI是待预测节点集合。</li>
<li>边级任务NOI是待预测是否有边的节点对。</li>
<li>图级任务NOI是待预测图中的所有节点。</li>
</ol>
<p>待训练的有很多图，有的图要做节点分类，有的图做链路预测，有的图做图分类，通过构造NOI subgraph的方式，无论是什么任务，都把每个图中所有的 <strong>与任务相关的节点</strong> （nodes-of-interest）提取出来。</p>
<p>若一个NOI节点 $v$的 $h$-hop局部子图表示为 $\mathcal{S}_h(v)$，那么NOI中所有目标节点的局部子图共同构成了一个<strong>NOI subgraph</strong>，表示为 $\mathcal{G}_h (\mathcal{T})$：</p>
<p>$$
\mathcal{G}_h(\mathcal{T})=\bigcup_{v \in \mathcal{T}} \mathcal{S}_h(v)=\left\{\bigcup_{v \in \mathcal{T}} \mathcal{V}_v^h, \bigcup_{v \in \mathcal{T}} \mathcal{E}_v^h, \bigcup_{v \in \mathcal{T}} \mathcal{R}_v^h\right\} \quad \text{NOI中所有节点的局部子图共同构成}
$$</p>
<p><strong>NOI prompt node</strong>：定义NOI prompt node，该节点的文本信息用来描述任务，比如某个数据集上的节点分类、图分类等。NOI prompt node的节点text feature以如下形式构建：</p>
<p><img loading="lazy" src="/posts/2025-05-21-OFA/NOI_prompt_node.jpg" alt="NOI_prompt_node.jpg"  />
</p>
<p>NOI prompt node的节点特征以 “Prompt node.” 开头，该节点的文本表述为需要在NOI上进行的task，如果需要对NOI做node classification，那么Prompt node的文本特征为：“Node classification on the literature category of the paper.”。通过这种方式，即使是图上任务有不同，只需要用不同的NOI prompt node就可以描述不同的任务。</p>
<h2 id="graph-in-context-learning的图提示范式graph-prompting-paradigm">Graph In-Context Learning的图提示范式（Graph Prompting Paradigm）</h2>
<p>LLM的一大特性就是它可以通过prompt来实现in-context learning，使得模型可以在不用fine-tuning的情况下适应于不同的任务。比如在few-shot场景下，目标是基于一篇paper的摘要和内容预测它的类别，我们可以为LLM提供每个类别的 $k$篇papers作为context加入prompt中，来指导模型基于这些提供的context来生成目标摘要和内容的类别预测。（通过一些<strong>任务相关的其他信息</strong>来指导模型对目标样本的预测）</p>
<p>本文发现实现图上in-context learning的核心在于操作输入图使其和下游任务对齐。<strong>Graph Prompting Paradigm (GPP)</strong> 即图提示范式旨在操作输入图使其可以从输入数据本身获得任务相关的信息。如图2中的虚线所示，用来描述任务的NOI prompt node与所有NOI node建立连接（任务的目标节点），表示在这些NOI nodes上执行对应prompt的任务（如节点分类，链路预测，图分类等）。</p>
<p><strong>Zero-shot Learning:</strong> 对于一个NOI $q$，若是节点分类任务 $q$是一个节点；若是边分类任务 $q$是一条边的两端节点；若是图分类任务， $q$是图中的所有节点，如Figure 2中的蓝色节点所示。 $q$中节点构成的局部子图，即NOI subgraph 表示为 $\mathcal{G}^q_h (\mathcal{T}^q) = (\mathcal{V}^h_q, \mathcal{E}^h_q, \mathcal{R}^h_q)$。</p>
<p>对于一个NOI subgraph $\mathcal{G}^q_h (\mathcal{T}^q)$, 该子图的NOI的任务可能是节点级任务也可能是边级或图级任务，根据该NOI subgraph的目标任务不同，将对应任务的NOI prompt node $p_q$与该NOI subgraph中的所有NOI节点 $q$相连。如Figure 2中的虚线所示，任务描述节点NOI prompt node与该任务的目标节点用<strong>虚线</strong>相连。</p>
<p>除此之外，定义class node与NOI prompt node相连，class node用于描述NOI prompt node的分类任务的类别信息，有多少个类别就有多少个class nodes。最终可以得到所有NOI的prompt graph，如Figure 2的左边框中3个prompt graph所示。用同一个GNN模型来训练不同分类任务的Prompt Graph （任务仅仅通过NOI prompt nodes 和class nodes来做区分）。在半监督训练完成后，我们可以得到一个GNN模型，3种任务的NOI prompt nodes的embedding，以及每种任务的class nodes的embedding，以及一个从embedding映射到label的MLP。对于一个新的节点/边，首先提取他的NOI subgraph，如Figure 2的彩色框中所示，然后将新的NOI nodes连接到NOI prompt nodes，再将NOI prompt nodes连接到任务的class nodes。先用训练好的GNN应用在这个新的prompt graph上，然后可以得到每个class node的embedding, 再用训练好的MLP将class node embeddings映射到label space，从而得到该NOI属于不同类别的概率。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>KDD2023《All in One：Multi-Task Prompting for Graph Neural Networks》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/allinone/</link>
      <pubDate>Tue, 20 May 2025 14:22:08 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/allinone/</guid>
      <description>KDD2023 &amp;#34;All in One：Multi-Task Prompting for Graph Neural Networks&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p>图神经网络的预训练任务和下游任务之间可能存在较大gap，直接将预训练模型应用在下游任务上可能会产生负迁移现象（“negative transfer”）。例如，binary edge prediction经常用于pretrain graph model。这样的预训练模型使得有边连接的节点在representation space中接近。但是下游任务可能是node-level 或graph-level tasks，下游的任务如果是节点分类任务，那么预训练模型需要针对额外的节点类别标签搜索更高维度的参数空间。如果图中相连节点的类别不同（heterophilic），那么基于edge prediction pretrained的模型会对下游任务参数负面效果。</p>
<p>为了解决上述问题，一个潜在的方向是将“pretraining and fine-tuning”拓展为“pretraining, <strong>prompting</strong>, and fine-tuning”。例如在自然语言处理中，如果要赋予预训练语言模型预测句子情感的能力（sentiment analysis），可以通过prompt来完成，而不需要优化pretrained model。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/image.png#center" alt="你想输入的替代文字"  />
</p>
<p>以上图为例，对于一个fronzen LLM（参数固定），如果要为这个模型赋予情感分析的能力，我们可以额外训练一个最佳的prompt，训练数据为prompt parameters，要求这个prompt tokens在tasker $\phi$的优化下，生成的下一个token是正确的情感（label为excited）。即训练得到一个最佳的prompt tokens，比如训练得到的最佳prompt tokens是“I feel so [mask]”，使得frozen LLM应用在“KDD2023 will witness many high-quality papers. I feel so ” 这个句子上时，可以将下一个词预测为情感词，这样LLM在输入包含prompt tokens的情况下，可以具备预测句子情感的能力。也就是说， <strong>Prompt Learning的目的是训练得到一堆tokens，使得这些tokens与原来的context拼起来可以使得LLM具备新的能力。</strong></p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/1.png#center" alt="你想输入的替代文字"  />
</p>
<p><strong>这篇文章的目的是在图上做Prompt Learning，也就是在训练一个prompt graph，使得现有图拼上这个prompt graph后，预训练的GNN可以在新的任务上（预训练阶段没有接触过的任务上）也表现的较好。</strong> 但是在graph上做Prompt Learning存在以下挑战：</p>
<ul>
<li>自然语言处理中，prompt tokens是一个一维线性的句子，可以放在content的开头或结尾，但是在graph中，节点是非欧结构，因此如何组织prompt tokens，以及如何将graph prompts与input graph结合是一个挑战。</li>
<li>在自然语言处理中，类似于情感分析，和问答任务，这些任务都可以简单的重构为next token prediction（单词预测）的任务，所以只需要使用单词预测来训练prompt就可以。但是在图中，节点级任务、边级任务和图级任务难以统一成一种形式。因此如何将各种prompt任务统一来训练graph prompt也是一个挑战。</li>
</ul>
<p>训练好prompt token的向量化信息、连接结构、以及插入到原图的方式，然后Frozen Pretrained Model应用在这个combined graph上后，就可以为Pretrained Model赋予处理新任务的能力。</p>
<h2 id="reformulating-downstream-tasks">Reformulating Downstream Tasks</h2>
<p>将节点级和边级的下游任务统一为induced graph的标签预测问题。</p>
<p>对于节点预测任务，将它重构为图分类任务：</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/2.png#center" alt="你想输入的替代文字"  />
</p>
<p>将节点标签设置为它的 $k$-hop诱导子图的标签。</p>
<p>将边预测（存在性预测和类别预测都可以，即二分类和多分类）任务也重构为图分类任务，如下：</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/3.png#center" alt="你想输入的替代文字"  />
</p>
<h2 id="prompt-graph-design">Prompt Graph Design</h2>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/4.png#center" alt="你想输入的替代文字"  />
</p>
<p><strong>Prompt Tokens</strong> 首先Prompt graph 定义为 $\mathcal{G}_p(\mathcal{P},\mathcal{S})$，其中每个token $p_i \in \mathcal{P}$是Prompt graph中的节点，它的特征是 $\mathbf{p}_i$，维度与node features相同。</p>
<p><strong>Token Structures</strong> 每个tokens的特征 $\mathbf{p}_i$是随机初始化可学习的，然后可以通过计算相似度并用sigmoid和相应的阈值来控制 $\mathcal{G}_p$的结构。然后可以计算 $\mathbf{p}_k$和节点 $\mathbf{x}_i$之间的相似度来确定该prompt node如何将自身信息与节点 $\mathbf{x}_i$的信息结合，来赋予预训练模型处理节点 $i$相应任务的能力。
$$
w_{i k}= \begin{cases}\sigma\left(\mathrm{p}_k \cdot \mathrm{x}_i^T\right) &amp; \sigma\left(\mathrm{p}_k \cdot \mathrm{x}_i^T\right)&gt;\delta \\ 0 &amp; \text { otherwise }\end{cases}
$$</p>
<p>通过 $\hat{\mathbf{x}}_i=\mathbf{x}_i+\sum_{k=1}^{|\mathcal{P}|} w_{i k} \mathbf{p}_k$ 来为节点 $i$添加提示。</p>
<h2 id="如何训练-prompt-graph使其可以作为预训练模型的有效提示multi-task-prompting-via-meta-learning">如何训练 Prompt Graph，使其可以作为预训练模型的有效提示：Multi-task Prompting via Meta Learning</h2>
<p>学习最好的Prompt，使得该Prompt可以帮助Pretrained Model更好的适应下游任务。</p>
<p><strong>Phase 1</strong> 有一些 Source Task去训练Prompt 的初始值。</p>
<p><strong>Phase 2</strong> 对Target Task做测试。</p>
<p>具体来说，首先对于要训练的prompt graph $\theta$ （即所有token的特征）让它在多个training task上训练，如下图所示，又3个节点分类的tasks，每个tasks里又自己的训练集（support set）和测试集（query set）。每个task都有一个共同的起点，在几个tasks上训练上训练后，每个tasks上有个优化后的task-specific prompt (Prompt 1, Prompt 2, Prompt 3)。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/5.png#center" alt="你想输入的替代文字"  />
</p>
<p>在更新了之后，评估组合起来的Prompt是否会让整体的性能更好，如下图所示，把所有task-specific prompt组合起来，来看组合后的prompt是不是足够好。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/6.png#center" alt="你想输入的替代文字"  />
</p>
<p>如果当前的Initial prompt训练出来的模型在三个tasks上不够好，那么换一个Initial Prompt，直到某个Initial Prompt在所有training tasks经过训练后都表现的较好时，就说明这是一个 <strong>较好的初始prompt (训练起点)</strong>，它适合做training tasks的初始化prompt。</p>
<p>在Meta Training 结束后，我们可以得到一个较好的prompt初始化值，即上图中的Adapt prompt initialization。</p>
<p>在Meta Testing阶段，将我们通过Training Tasks学到的最佳初始Prompt在Test tasks的support set上做微调，然后在Test Task的query set上验证prompt initialization的效果。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/7.png#center" alt="你想输入的替代文字"  />
</p>
<p>通过上面方式得到的prompt可以作为graph prompt与input graph 结合，使其具备link prediction和node classification的能力。</p>
<p><strong>可以看作时学习一个图增强，使得预训练的图模型在这个增强图上可以适用于更多任务。</strong></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>LLMs and Graphs</title>
      <link>https://JhuoW.github.io/posts/graphllm/</link>
      <pubDate>Sat, 25 May 2024 01:04:50 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/graphllm/</guid>
      <description>Large Language Model, GNNs, and Foundation Models</description>
      <content:encoded><![CDATA[<h1 id="1-harnessing-explanations-llm-to-lm-interpreter-for-enhanced-text-attributed-graph-representation-learning-tape">1. Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning (TAPE)</h1>
<p><strong>Shallow model:</strong> Encoding the textual attributes using shallow or hand-crafted features such as skip-gram or bag-of-words (BoW) which used in PgG and DGL <strong>are limited in the complexity of the semantic features they can capture.</strong></p>
<p><strong>LM:</strong> 指相对较小并且可以被fine-tune的模型。GIANT <strong>fine-tune</strong> an LM using neighborhood prediction task （在neighborhood prediction task上来微调LM模型）. GLEM <strong>fine-tune</strong> an LM to predict the label distribution from GNN&rsquo;s output (GLEM 用GNN预测的伪标签作为监督信号，让LM来fine tune 节点的文本表示)。这些工作需要大量的计算资源，并且由于要微调模型的参数，所以选取的LM相对较小，比如BERT和DeBERTa，因此缺乏LLM的推理能力。</p>
<p>LLMs refer to very large language models such as GPT-3/4.</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/TAPE.png#center" alt="TAPE"  />
</p>
<p><strong>The present work: LLM augmentation using explanations:</strong> 使用解释作为node feature。通过LLM来解释它的预测，这些解释传达了text与prediction的相关知识和LLM的推理步骤，这些解释信息更易于小LM模型吸收消化。如上图所示，首先绿框中的节点text属性通过自定义的prompt来询问LLM，比如GPT-3.5，让GPT来生成关于文本类别的<strong>预测排名list</strong>（黄色框所示），并且<strong>提供这些得到这些预测的解释理由</strong>。接着，原始text，LLM的预测，以及解释共同用来fine-tune LM，比如BERT或DeBERTa。然后，LM将他们转化为节点的features用于下游预测。</p>
<h2 id="formalization">Formalization</h2>
<p><strong>LM for text classification</strong>
$$
h_n=\mathbf{L M}\left(s_n\right) \in \mathbb{R}^d
$$
其中$s_n \in \mathcal{D}^{L_n}$是节点$n$的文本属性。LM是已经被预训练的模型如BERT和DeBERTa。LM可以将文本属性编码为文本的表示向量$h_n$。</p>
<p><strong>LLM and prompting</strong></p>
<p>输入token序列 $x=\left(x_1, x_2, \ldots, x_q\right)$，目标是输出token序列 $y=\left(y_1, y_2, \ldots, y_m\right)$。并且在输入token序列中加入prompt $p$来对输出施加约束。LLM旨在优化一下条件概率：
$$
p(y \mid \hat{x})=\prod_{i=1}^m p\left(y_i \mid y_{&lt;i}, \hat{x}\right)
$$
其中$\hat{x}=\left(p, x_1, x_2, \ldots, x_q\right)$是使用prompt约束的input token sequence。</p>
<h2 id="tape">TAPE</h2>
<h3 id="使用llms生成预测和解释">使用LLMs生成预测和解释</h3>
<p>LLMs的prompt包括文章的title和abstract，并要求LLMs预测paper的一个或多个类别标签，并且将这些类别标签按从高到低的概率排序，并且要求LLMs提供预测的解释理由，完整prompt如下图所示：</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/tape_prompt.png#center" alt="TAPE"  />
</p>
<p>Abstract输入节点对应paper的摘要，Title输入paper的题目，question则要求模型输出一个或多个paper的预测类别标签并按照可能性排序，同时给出预测的解释。</p>
<h3 id="fine-tuning-lm-interpreter-and-node-feature-extraction">Fine-Tuning LM Interpreter and Node Feature Extraction</h3>
<p>将LM作为LLM得到文本解释的“理解器”。给定两个预训练好的LMs $\mathrm{LM}_{\text {orig }}$ 和$\mathrm{LM}_{\text {expl }}$，他们的输入分别是原始文本特征$s^{\text {orig }}$和该文本特征的解释$s^{\text {expl }}$，这样我们可以分别得到原始文本和解释的text embeddings:
$$
h_{\text {orig }}=\mathrm{LM}_{\text {orig }}\left(s^{\text {orig }}\right) \in \mathbb{R}^{N \times d}, \quad h_{\text {expl }}=\mathrm{LM}_{\text {expl }}\left(s^{\text {expl }}\right) \in \mathbb{R}^{N \times d}
$$
然后要对LM进行Fine-tuning使其与下游任务。首先使用MLP将原始文本和解释的text embedding分别映射到标签空间：
$$
y_{\text {orig }}=\operatorname{MLP}_{\text {orig }}\left(h_{\text {orig }}\right) \in \mathbb{R}^{N \times C}, \quad y_{\text {expl }}=\operatorname{MLP}_{\text {expl }}\left(h_{\text {expl }}\right) \in \mathbb{R}^{N \times C}
$$
通过最小化分类的cross-entropy loss来对LM进行fine-tuning，从而使$\mathrm{LM}_{\text {orig }}$ 和$\mathrm{LM}_{\text {expl }}$可以分别学习到文本和解释与标签之间的关联（什么样的原始文本对应于什么样的标签、什么样的解释对应于什么样的标签）。</p>
<p><strong>Ranked prediction features</strong> LLM同时也给出了对于每个节点文本的类别可能性排名，同样也是有价值的信息。假设每个节点有$C=5$个可能的类别数，对这些类别分别做one-hot编码，节点$i$排名第1的类别为类别4，那么$p_{i,1} = [0,0,0,1,0]$，那么LLM为节点$i$预测的top-$k$个label可以拼接成一个$kC$维的向量。然后通过一个线性变换:
$$
h_{\text{pred}} = \operatorname{MLP}_{\text {pred }}(\operatorname{Concat}(p_{i,1}, \cdots, p_{i,k})) \in \mathbb{R}^{N\times d_P}
$$
可以得到每个节点的排序预测特征，如Figure 1中的$h_{\text{pred}}$所示。</p>
<p><strong>TAPE node feature: $\{[h_{\text {orig }}, h_{\text {expl }}, h_{\text{pred}}]\}$</strong>。其中$h_{\text {orig }}$和$h_{\text {expl }}$是通过LM 对下游任务标签做fine-tuning后的文本特征和解释特征，用来简历原始文本和解释与label之间的联系，$h_{\text{pred}}$是LLMs预测类别标签编码。</p>
<h3 id="gnn-training-with-tape-features">GNN Training with TAPE features</h3>
<p>对于TAPE的三种特征：LM fine-tuning的原始text embedding $h_{\text {orig }}$, LM fine-tuning的解释text embedding $h_{\text {expl }}$，以及LLM的prediction embedding $h_{\text{pred}}$，使用3个GNN模型分别预测labels:
$$
\begin{aligned}
\hat{y}_{\text{orig}} &amp;= \operatorname{GNN}_{\text{orig}}(h_{\text {orig }}, A) \in \mathbb{R}^{N \times C}, \\
\hat{y}_{\text{expl}} &amp;= \operatorname{GNN}_{\text{expl}}(h_{\text {expl }}, A) \in \mathbb{R}^{N \times C}, \\
\hat{y}_{\text{pred}} &amp;= \operatorname{GNN}_{\text{pred}}(h_{\text {pred }}, A) \in \mathbb{R}^{N \times C}
\end{aligned}
$$</p>
<p>然后基于不同特征得到的预测取平均可以得到模型最终的预测label：
$$
\hat{y}=\operatorname{mean}\left(\hat{y}_{\text {orig }}, \hat{y}_{\text {expl }}, \hat{y}_{\text {pred }}\right) \in \mathbb{R}^{N \times C}
$$</p>
<h1 id="2-exploring-the-potential-of-large-language-models-llms-in-learning-on-graphs">2. Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs</h1>
<p><a href="https://arxiv.org/abs/2307.03393">paper</a></p>
<p>Q1: 能否利用LLMs来弥补图神经网络对contextualized knowledge和semantic comprehension理解不足的缺陷？</p>
<p>Q2: LLM能否独立运行于图结构任务？</p>
<h2 id="llms">LLMs</h2>
<h3 id="embedding-visible-llms">Embedding-visible LLMs</h3>
<p>可以获得words, sentences, documents的具体representations（embeddings），如BERT, Sentence-BERT和Deberta。</p>
<h3 id="embedding-invisible-llms">Embedding-invisible LLMs</h3>
<p>用户无法获取和操作embeddings，通常部署在web服务上，如ChatGPT，只能通过text来进行交互</p>
<h3 id="detailed-four-types-of-llms">Detailed four types of LLMs</h3>
<p><strong>Pre-trained Languagge Models (PLMs):</strong> 指相对较小的LLMs，比如Bert和Deberta，并且可以根据下游数据集进行fine-tuning，比如在下游数据集上fine-tune  Deberta然后取最后一个hidden state的embeddings作为text embedding。</p>
<p><strong>Deep Sentence Embedding Models:</strong> 使用PLMs作为base encoders，并且将训练好的PLMs进一步进行监督或对比学习<strong>预训练</strong>。这样的模型通常不需要Fine-tuning。</p>
<p><strong>Large Language Models:</strong> 与PLM相比，LLMs具有更强的能力和更多数量级的参数。</p>
<h2 id="llms-as-enhancers">LLMs-as-Enhancers</h2>
<p><strong>利用LLMs来增强节点的文本属性特征，然后用GNN生成预测。</strong></p>
<p>How LLMs can enhance GNNs by leveraging their <strong>extensive knowledge</strong> and <strong>semantic comprehension</strong> capability?</p>
<p>Challenge: 不同的LLMs能力不同，越强大的模型有更多使用限制，因此需要对不同的LLMs针对性设计使用策略来充分利用他们的能力。</p>
<h3 id="feature-level-enhancement">Feature-level Enhancement</h3>
<h4 id="1-cascading-structure-级联结构">1. Cascading Structure 级联结构</h4>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/cascading.png#center" alt="Cascading Structure"  />
</p>
<p>先试用embedding-visible的LLMs来对dataset中的text attribute做fine-tuning，然后生成每个节点的文本特征的embeddings，然后将这些embeddings作为node features，与图结构一起数据GNN中来训练GNN模型。</p>
<h4 id="2-iterative-structure-迭代结构">2. Iterative Structure 迭代结构</h4>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/iterative.png#center" alt="iterative Structure"  />
</p>
<p>如GLEM[1]，在E步根据真实标签和GNN预测的伪标签来训练PLM，在M步根据真实标签和PLM预测的伪标签和PLM学到的text embedding作为node feature来训练GNN模型，然后训练好的GNN模型和PLM模型都可以用来作为节点标签预测器。</p>
<h4 id="node-classification-comparison">Node Classification Comparison</h4>
<p>实验结果来看，</p>
<ol>
<li>在下游数据集上fine-tuned PLM模型取最后一层作为text embedding，然后GNN作为predictor的效果来看，fine-tuned PLM并不比简单点TF-IDF强。对于不同的text embedding方式（Fine-tuned PLM，PLM without fine-tuning，online sentence embedding）GNN的表现各不相同。</li>
<li>在监督训练数据较少的情况下，fine-tuned PLM和迭代结构的GLEM学习到的text embedding用到GNN后，得到的结果比普通的TF-IDF差。</li>
<li>使用Deep Sentence Embedding Models 如sentence-bert学习到的text embedding + GNN predictor的效果较好。</li>
<li>LLama的效果弱于deep sentence embedding models，说明简单的增加参数并不能生成对GNN有用的text embedding。</li>
</ol>
<h3 id="text-level-enhancement">Text-level Enhancement</h3>
<h4 id="1-tape">1. TAPE</h4>
<p>使用文本和LLM解释来fine-tuning PLM，LLM的分类解释和分类排序作为增强text embedding。</p>
<h4 id="2-knowledge-enhanced-augmentation-kea">2. Knowledge-Enhanced Augmentation (KEA)</h4>
<p>使用额外的knowledge来增强PLM。</p>
<h4 id="node-classification-comparison-1">Node Classification Comparison</h4>
<p>实验结果来看，</p>
<ol>
<li>TAPE的效果主要受益于LLMs生成的文本解释。</li>
<li>TAPE原文中采用PLM （Deberta）作为LM，将text attribute和explanation以及任务的label用来fine-tune PLM。而local sentence embedding model e5-large不fine-tune 直接用text attribute以及LLM的explanation来输出embeddings，相比于TAPE中使用的fine-tuned PLM，e5得到了更好的效果。</li>
</ol>
<h2 id="llms-as-predictors">LLMs-as-Predictors</h2>
<p><strong>LLMs作为独立的predictor</strong></p>
<p>How LLMs can be adapted to explicit graph structures as a <strong>predictor</strong>?</p>
<p>Challenge: 如何设计prompt使得LLM可以处理图中的structure和attribute信息。</p>
<p>直接使用LLM来预测节点类别标签可以使用以下几种prompt策略：</p>
<ol>
<li><strong>Zero-shot prompts:</strong> 给定单一节点的文本信息，让LLM预测它的类别标签，如下面的prompt所示。</li>
</ol>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/zero_shot_prompt.png#center" alt="zero-shot prompt"  />
</p>
<p>​       其中，Paper是一个节点的text attribute，Task提供可能的类别标签，然后prompt要求LLM输出一个最可能的类别。</p>
<ol start="2">
<li><strong>Few-shot prompts:</strong> 如下图所示，先按照zero-shot的形式给出一些node samples的 prompts，<strong>以及这些samples的ground-truth标签</strong>。最后，给出目标节点的prompt，要求LLMs输出节点的类别。</li>
</ol>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/few_shot_prompt.png#center" alt="few-shot prompt"  />
</p>
<ol start="3">
<li><strong>Zero-shot prompts with CoT (Chain-of-Thoughts):</strong> 基于zero-shot prompt，在prompt中进一步要求LLM生成思考过程，也就是<strong>Think it step by step and output the reason in one sentence</strong>  (用一句话来概括推理步骤)。</li>
</ol>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/zero_shot_cot.png#center" alt="zero-shot cot"  />
</p>
<ol start="4">
<li><strong>Few-shot prompts with CoT:</strong> 使用第三个prompt的zero-shot prompts with CoT来分别为多个sample生成推理步骤的sentences，然后将这些这些samples的文本内容、Ground-truth标签和CoT process共同作为prompt，并且要求LLM为当前的目标node输出预测标签以及CoT。</li>
</ol>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/few_shot_cot.png#center" alt="few-shot cot"  />
</p>
<h1 id="3-one-for-all-towards-training-one-graph-model-for-all-classification-tasks">3. One for All: Towards Training One Graph Model for All Classification Tasks</h1>
<p><strong>What is in-context learning?[2]</strong></p>
<p>&ldquo;In-Context Learning is a way to use LLMs to learn tasks given only a few examples. During in-context learning, we give the LM a prompt that consists of a  list of input-output pairs that demonstrate how to perform a task. At  the end of the prompt, we append a test input and allow the LM to make a prediction just by conditioning on the prompt and predicting the next  tokens. For example, to answer the two prompts below, the model needs to examine the training examples to figure out the input distribution  (financial or general news), output distribution (Positive/Negative or  topic), input-output mapping (sentiment or topic classification), and  the formatting. &quot;</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/icl.gif#center" alt="ICL"  />
</p>
<p>如上图（from [2]）所示，在prompt中包含一些上下文input-output pairs来演示（demonstrate）如何执行任务。在这些prompt的最后添加text input token来让LLM学习上下文中的演示来执行text input token的任务。</p>
<h2 id="challenge">Challenge</h2>
<p>Foundation Model指用单一模型来解决多个任务。但是Graph Foundation Model面临以下挑战：（1）不同来源的图数据在feature表征上通常完全不同。比如molecular graph中的节点特征是其中原子nominal feature的索引，e-commerce networks中的节点特征通常用Bag-of-Word来编码。这些不同来源的图数据特征维度、语义信息和尺度的差别都很大，几乎不可能用同一个模型来学习他们的表示。（2）不同的下游任务涉及图的不同部分（节点级、边级、图级）需要不同的策略和方法来学习表示。（3）如何设计统一的模型来实现跨领域和in-context learning是不确定的。</p>
<h2 id="ofa-one-for-all">OFA (One-for-All)</h2>
<h3 id="将不同domian的图转化为统一的tag形式">将不同Domian的图转化为统一的TAG形式</h3>
<p>用human-interpretable language来描述节点和边的属性，从而使LLM可以将这些text attribute编码到同一个空间。具体来说，通过以下方式来生成每个节点的text feature:</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/node_text_feature.png#center" alt="text feature"  />
</p>
<p>将不同domain的graph的节点属性用统一形式的文本来描述，如上图中，对于一个节点的特征，它的文本描述以<strong>Feature node</strong>开头，后面的每个$&lt;\text{feature describe}&gt;:&lt;\text{feature content}&gt;$是该节点的一个type-content文本对。如对于一个molecule graph，其中的一个节点是原子，那么它的type是<strong>Atom</strong>，它的content是该原子的属性文本描述<strong>Carbon, Atomic number 6, helix chirality</strong>。同理，边的text feature以<strong>Feature edge</strong>开头进行文本描述。</p>
<p>在用以上方式得到节点$v_i$的text feature $s_{v_i}$和边$e_{ij}$的text feature $s_{e_{ij}}$后，用LLM（这里用sentence transformer）来将每个节点和边的text feature编码为vector embeddings：
$$
x_i = \operatorname{LLM}(s_{v_i}), \quad x_{ij} = \operatorname{LLM}(s_{e_{ij}})
$$</p>
<h3 id="用nodes-of-interest-noi来统一不同的图任务">用Nodes-of-Interest (NOI)来统一不同的图任务</h3>
<p>图上的任务主要分为3中：node-level tasks，link-level tasks和graph-level tasks。如果要用一个模型来处理这些任务的话，<strong>需要将这些任务统一为一个任务以便于在图数据上训练</strong>。</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/NOI.png#center" alt="NOI"  />
</p>
<p>Nodes-of-Interest (<strong>NOI</strong>)指的是一个任务的<strong>目标节点</strong>，如上图的蓝色节点所示，表示为$\mathcal{T}$。对于节点级任务，NOI是待预测节点集合，边级任务NOI是待预测是否有边的节点对，图级任务NOI是待预测图中的所有节点。若一个NOI节点$v$的$h$-hop局部子图表示为$\mathcal{S}_h(v)$，那么NOI中所有目标节点的局部子图共同构成了一个<strong>NOI subgraph</strong>，表示为$\mathcal{G}_h (\mathcal{T})$。
$$
\mathcal{G}_h(\mathcal{T})=\bigcup_{v \in \mathcal{T}} \mathcal{S}_h(v)=\left\{\bigcup_{v \in \mathcal{T}} \mathcal{V}_v^h, \bigcup_{v \in \mathcal{T}} \mathcal{E}_v^h, \bigcup_{v \in \mathcal{T}} \mathcal{R}_v^h\right\}   \quad \text{NOI中所有节点的局部子图共同构成}
$$
<strong>NOI prompt node</strong>：定义NOI prompt node，该节点的文本信息用来描述任务，比如某个数据集上的节点分类、图分类等。NOI prompt node的节点text feature以如下形式构建：</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/NOI_prompt_node.png#center" alt="NOI"  />
</p>
<p>即每个数据集的一个task对应于一个prompt node，该node用来描述task。这样，把不同的图任务都用节点的text feature这种统一的形式来表达。</p>
<h3 id="graph-in-context-learning的图提示范式graph-prompting-paradigm">Graph In-Context Learning的图提示范式（Graph Prompting Paradigm）</h3>
<p>LLM的一大特性就是它可以通过prompt来实现in-context learning，使得模型可以在不用fine-tuning的情况下适应于不同的任务。比如在few-shot场景下，目标是基于一篇paper的摘要和内容预测它的类别，我们可以为LLM提供每个类别的$k$篇papers作为context加入prompt中，来指导模型基于这些提供的context来生成目标摘要和内容的类别预测。（通过一些<strong>任务相关的其他信息</strong>来指导模型对目标样本的预测）</p>
<p>本文发现实现图上in-context learning的核心在于操作输入图使其和下游任务对齐。<strong>Graph Prompting Paradigm (GPP)</strong> 即图提示范式旨在操作输入图使其可以从输入数据本身获得任务相关的信息。如图2中的虚线所示，用来描述任务的NOI prompt node与所有NOI node建立连接（任务的目标节点），表示在这些NOI nodes上执行对应prompt的任务（如节点分类，链路预测，图分类等）。图中的$p2t$和$t2p$ edge表示NOI节点和prompt node之间的边。下一步建立NOI prompt node和具体类别之间的联系，如图2中的<strong>Class Node</strong>用来描述该分类任务的每个类别的类信息，任务有多少个类，就有多少个Class Node。Class Node的Text feature如下图所示：</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/class_node.png#center" alt="NOI"  />
</p>
<p><strong>Zero-shot Learning:</strong> 对于NOI中的一个节点$q$，用于描述它的任务的NOI prompt node $p_q$，以及Class Node $\{c_i | i \in [N]\}$ ，其中$N$为任务的类别数。prompt node，class node，以及和prompt node 连接的所有边（包括与NOI连接的边）共同构成了<strong>prompt graph</strong> $\mathcal{P}=\left(\mathcal{V}_p, \mathcal{E}_p, \mathcal{R}_p\right)$。</p>
<p>然后，prompt graph $\mathcal{P}=\left(\mathcal{V}_p, \mathcal{E}_p, \mathcal{R}_p\right)$和NOI subgraph (即NOI节点的局部子图)相结合为<strong>通用graph model</strong>的输入图$\mathcal{G}_m=\left(\mathcal{V}_q^h \cup \mathcal{V}_p, \mathcal{E}_q^h \cup \mathcal{E}_p, \mathcal{R}_q^h \cup \mathcal{R}_p\right)$。如图2中的（a）(b)（c）都是graph model的输入图。通过模型的学习，可以得到每个Class node 的embeddings，如类别$c_i$的Class node embedding为$h_{c_i}$。因为$c_i$与任务相关的prompt node 连接，而prompt node与目标NOI node 连接，因此可以用$h_{c_i}$来推断NOI node属于类别$c_i$的概率：
$$
P[\text { NOI belongs to class } i]=\sigma\left(\operatorname{MLP}\left(h_{c_i}\right)\right)
$$</p>
<h1 id="4-talk-like-a-graph-encoding-graphs-for-large-language-models">4. Talk like a Graph: Encoding Graphs for Large Language Models</h1>
<p>prompt engineering的目的是找到一个合适的方式使LLM $f$可以解析问题$Q$，并且得到他的Answer $\mathcal{A}$，即$\mathcal{A} = f(Q)$。本工作的目标是为LLM$f$提供图$G$，使得LLM可以对图做推理QA，即$\mathcal{A} = f(G,Q)$。在该工作中，固定LLM $f$的参数不变，并引入一个图编码函数（graph encoding function）$g(G): G \to W$用于将图结构数据编码成text，以及一个问题重解析函数$q(Q): W \to W$。训练数据$D$有图$G$，问题$Q$和回答$S$组成，即每个训练数据$(G,Q,S) \in D$。训练目标是固定大语言模型$f$不变，找到最佳的图编码函数$g$和问题重解析函数$q$，使得给定训练$G$和$Q$，得到回答$S$的分数最高：
$$
\max _{g, q} \mathbb{E}_{G, Q, S \in D} \operatorname{score}_f(g(G), q(Q), S)
$$</p>
<h3 id="graph-encoding-function-gg">Graph encoding function $g(G)$</h3>
<p>$g(G)$用于将$G$映射为LLM可以处理的token：首先，encode图中的节点，然后encode图中的边。具体编码技术如下图所示：</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/encoding_graph.png#center" alt="NOI"  />
</p>
<p><strong>Encoding Nodes</strong>:</p>
<ol>
<li>
<p>整型节点编码：$G$ describes a graph among nodes 0,1,2,3,4,5,6,7</p>
</li>
<li>
<p>使用well-known English first names：$G$ describes a friendship among James, Robert, Michael, Mary.</p>
</li>
<li>
<p>使用电视剧《权力的游戏》和《南方公园》中流行的角色名字。</p>
</li>
<li>
<p>包括美国政治家的名字。</p>
</li>
<li>
<p>用字母表示的。</p>
</li>
</ol>
<p><strong>Representing Edges</strong>:</p>
<ol>
<li>用括号表示边：The edge in $G$ given as (0,1), (0,2), &hellip;, (6,7), (7,8)</li>
<li>Friendship: source node and target node are friends. 如 We have the following edges in $G$: James and Robert are friends, &hellip; Jennifer and Linda are friends。对应于上面的well-known English first name表示节点</li>
<li>Coauthorship: 比如 James and Robert wrote a paper together 来表示一条边</li>
<li>Social network: James and Robert are connected来表示一条边</li>
<li>Arrows: A-&gt;B 来表示边</li>
<li>Incident: Node 8 is connected to nodes 3,7 来表示每个节点的<strong>邻域</strong>。</li>
</ol>
<h2 id="experiments">Experiments</h2>
<p>使用PaLM 62B作为LLM，在不同图任务以及不同图编码器下的准确率比较，最有效的prompt (zero-shot、zero-cot、few-show、cot、cot-bag)用下划线标出，最佳图编码器用加粗标出。实验使用ER Graph作为数据集，ER Graph的统计数据如下表所示，可以看出平均节点数为12.37，平均边数为39.79，平均度为5.70。对于边存在任务，有53.96%的情况不存在边，对于cycle check任务，有81.96%的情况存在cycle（因为ER graph很可能存在cycle）。</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/graphqa_dataset.png#center" alt="graphqa_datase"  />
</p>
<p>从下面的实验结果可以看出，LLM在所有prompt heuristic的所有graph encoding function上预测的最高边存在概率为44.5%，76%的情况存在cycle。而在Node degree 任务上，均与真实平均度5.7差距较大，平均边数也与真实情况差距较大。</p>
<p>简单的Prompt比如zero-shot 在简单的任务上比复杂的prompt比如zero-cot效果更好，因为简单的任务无需多跳推理。</p>
<p>graph encoding function对LLM影响巨大。</p>
<p>整型节点编码可以提升算数性能，比如node degree、node count和edge count的预测。</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/graphqa_exp.png#center" alt="graphqa_exp"  />
</p>
<h1 id="5-can-language-models-solve-graph-problems-in-natural-language">5. Can Language Models Solve Graph Problems in Natural Language?</h1>
<p>[1] Learning on Large-scale Text-attributed Graphs via Variational Inference.</p>
<p>[2] <a href="https://medium.com/@francescofranco_39234/in-context-learning-icl-a775cd8b7261">https://medium.com/@francescofranco_39234/in-context-learning-icl-a775cd8b7261</a></p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
