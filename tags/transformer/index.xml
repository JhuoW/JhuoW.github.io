<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Transformer on JhuoW‘s Notes</title>
    <link>https://JhuoW.github.io/tags/transformer/</link>
    <description>Recent content in Transformer on JhuoW‘s Notes</description>
    <image>
      <url>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 May 2025 13:45:31 +0800</lastBuildDate><atom:link href="https://JhuoW.github.io/tags/transformer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>NeurIPS2023《Evaluating GNN Performance On Unseen Graphs Without Labels》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/gnn-evaluator/</link>
      <pubDate>Tue, 20 May 2025 13:45:31 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/gnn-evaluator/</guid>
      <description>NeurIPS2023 &amp;#34;Evaluating GNN Performance On Unseen Graphs Without Labels&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2310.14586">Paper</a></p>
<p>目的：在一个图上训练好的GNN，在未知的testing graph上的结果由于training和test数据分布的不同，可能存在很大的不确定性。通常来说，in-service的GNN在已知graph with labels的图上训练好后，需要部署在label未知的testing graph上，但是由于label未知，无法估计GNN在testing graph上的效果。</p>
<p><img loading="lazy" src="/posts/2025-05-20-GNNEvaluator/1.png#center" alt="你想输入的替代文字"  />
</p>
<p>如上图所示，对于一个已经在训练图 $\mathcal{S}=(\mathbf{X}, \mathbf{A}, \mathbf{Y})$上well-trained &amp; fixed GNN model  $\mathrm{GNN}_{\mathcal{S}}^\star$，并且将它deploy in service。对于一个不知道label的测试图 $\mathcal{T}$，由于不知道label，如何评估GNN在该测试图上的性能是一个挑战。由于可见的训练graph和不可见的test graph的分布差异可能很大，因此GNN评估器<strong>GNNEvaluator</strong>需要充分学习多样化的图结构with diverse node context and graph structure distributions，从而可以评估不同数据分布的测试图潜在的效果。</p>
<p>假设：<strong>Covariate shift</strong> between the training graph $\mathcal{S}$ and the label-unlabeled graph $\mathcal{T}$ with respect to the label space。 即无论输入图是什么样的，输出的label space相同。</p>
<h3 id="如何生成数量足够的graph-set来训练gnnevaluator-f_theta">如何生成数量足够的graph set来训练GNNEvaluator $f_\theta$?</h3>
<p>Solution：采样一个seed subgraph $\mathcal{S}_{seed}$ from the observed training graph $\mathcal{S}$。采样原则是seed graph 要和 training graph之间满足相同的label space，所以原图中采样可以使采样图$\mathcal{S}_{seed}$的分布尽可能少的偏离原图，从而满足Covariate shift。如下图左边所示。</p>
<p><img loading="lazy" src="/posts/2025-05-20-GNNEvaluator/2.png#center" alt="你想输入的替代文字"  />
</p>
<p>在得到采样seed graph $\mathcal{S}_{seed}$后，对 $\mathcal{S}_{seed}$做 $K$次增强，其中涉及的增强包括 $\texttt{EdgeDrop}$， $\texttt{NodeDrop(Subgraph)}$， $\texttt{AttrMask}$和 $\texttt{NodeMix}$。选择哪种增强有特定的概率 $\epsilon$。基于seed graph  $\mathcal{S}_{seed}$，可以得到一个 meta-graph集合 $\mathcal{G}_{\text{meta}}=\left\{g_{\text {meta }}^i\right\}_{i=1}^K$，其中的每个meta-graph都是由seed graph 扰动而来，和原图具有相同的label space。每个meta-graph $g_{\text {meta }}^i=\left\{\mathbf{X}_{\text {meta }}^i, \mathbf{A}_{\text {meta }}^i, \mathbf{Y}_{\text {meta }}^i\right\}$，分别表示meta-graph的节点特征，结构和标签。通过这种方式可以为原图生成label space相同，但结构/特征都不相同图，拓展了差异性，基于这些图学习到的GNNEvaluator可以评估不同分布图的效果。</p>
<h3 id="如何学习well-trained-gnn在不同分布图上的差异">如何学习well-trained GNN在不同分布图上的差异？</h3>
<p>给定一个在 training graph $\mathcal{S}$上 well-trained的GNN模型 $\mathbf{Z}_{\mathcal{S}}^\star=\operatorname{GNN}_{\mathcal{S}}^\star(\mathbf{X}, \mathbf{A})$， $\mathbf{Z}_{\mathcal{S}}^\star$是学习到的原图embeddings。将这个well-trained GNN  $\operatorname{GNN}_{\mathcal{S}}^\star(\cdot, \cdot)$直接应用在每个meta graph $g_{\text {meta }}^i$上：</p>
<p>$$ \mathbf{Z}_{\text {meta }}^{(i, \star)}, \hat{\mathbf{Y}}_{\text {meta }}^{(i, \star)}=\operatorname{GNN}_{\mathcal{S}}^\star\left(\mathbf{X}_{\text {meta }}^i, \mathbf{A}_{\text {meta }}^i\right)$$</p>
<p>可以得到$\operatorname{GNN}_{\mathcal{S}}^\star(\cdot, \cdot)$为meta graph $g_{\text{meta}}^i$学习到的节点embedding和预测值，可以用来评估在$\operatorname{GNN}_{\mathcal{S}}^\star(\cdot, \cdot)$该分布的图上的效果。若 $g_{\text {meta }}^i$中有 $M_i$个节点，那么 $\operatorname{GNN}_{\mathcal{S}}^\star(\cdot, \cdot)$对该图的准确率为：
$$
y_{\mathrm{disc}}^i=\operatorname{Acc}\left(g_{\text {meta }}^i\right)=\frac{\sum_{j=1}^{M_i}\left(\hat{y}_{\operatorname{meta}(i, *)}^j==y_{\operatorname{meta}(i)}^j\right)}{M_i},
$$
表示 $\operatorname{GNN}_{\mathcal{S}}^\star(\cdot, \cdot)$为该图中节点预测的平均准确率。</p>
<p>那么对于meta graph集合  $\mathcal{G}_{\text {meta }}=\left\{g_{\text {meta }}^i\right\}_{i=1}^K$中的所有图，由于这些图来组training graph，有明确的节点标签信息，因此$\operatorname{GNN}_{\mathcal{S}}^\star(\cdot, \cdot)$可以计算在每个meta graph上的准确率。由于不同的meta graph的数据分布不同，所以我们可以得到 $\operatorname{GNN}_{\mathcal{S}}^*(\cdot, \cdot)$对不同数据分布图的适用性。</p>
<p>此外，在well-trained模型下，meta graph $g_{meta}^i$的表示 $\mathbf{Z}_{\text {meta }}^{(i, \star)}$和训练图表示 $\mathbf{Z}_{\mathcal{S}}^\star$之间差异用下式衡量：
$$
\mathbf{X}_{\mathrm{disc}}^i=D\left(\mathbf{Z}_{\text {meta }}^{(i, \star)}, \mathbf{Z}_{\mathcal{S}}^\star\right)=\frac{\mathbf{Z}_{\text {meta }}^{(i, \star)} \mathbf{Z}_{\mathcal{S}}^{\star \mathrm{~T}}}{\left|\left|\mathbf{Z}_{\text {meta }}^{(i, \star)}\right|\right|_2 \cdot\left|\left|\mathbf{Z}_{\mathcal{S}}^\star\right|\right|_2}
$$</p>
<h3 id="gnnevaluator如何估计无标签图的准确率">GNNEvaluator如何估计无标签图的准确率？</h3>
<p>训练GNNEvaluator:
$$
\min_\phi \sum_{i=1}^K \mathcal{L}_{\mathrm{reg}}\left(f_{\boldsymbol{\phi}}\left(\mathbf{X}_{\mathrm{disc}}^i, \mathbf{A}_{\mathrm{disc}}^i\right), y_{\mathrm{disc}}^i\right)
$$
对于每个meta graph $g_{\text {meta }}^i=\left\{\mathbf{X}_{\text {meta }}^i, \mathbf{A}_{\text {meta }}^i, \mathbf{Y}_{\text {meta }}^i\right\}$，基于结构 $\mathbf{A}_{\text {meta }}^i$和差异属性 $\mathbf{X}_{\text {meta }}^i$使用逻辑回归来预测准确率 $y_{\mathrm{disc}}^i$。损失函数采用MSE回归损失。</p>
<p>测试阶段，对于一个label不可见的预测图 $\mathcal{T} = (\mathbf{X}^\prime, \mathbf{A}^\prime)$，将其带入 $\operatorname{GNN}_{\mathcal{S}}^\star(\cdot, \cdot)$得到它的表示 $\mathbf{Z}_{\mathcal{T}}^\star$，并与 $\mathbf{Z}_{\mathcal{S}}^\star$一同计算得到差异节点特征$\mathbf{X}_{\text {disc }}^{\mathcal{T}}$。再将$\mathbf{X}_{\text {disc }}^{\mathcal{T}}$和 $\mathbf{A}^\prime$带入 $f_\phi (\cdot,\cdot)$中，得到估计准确率 $\operatorname{Acc}(\mathcal{T})=\hat{y}_{\text {dist }}^{\mathcal{T}}$。该过程无需任何测试集标签参与评估。</p>
<p>图的差异与图的准确率匹配，所以可以用图差异来衡量与真实准确率的差异。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>NeurIPS2021 《Representing Long-Range Context for Graph Neural Networks with Global Attention》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/graphtrans/</link>
      <pubDate>Wed, 30 Mar 2022 10:37:41 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/graphtrans/</guid>
      <description>NeurIPS2021 &amp;#34;Representing Long-Range Context for Graph Neural Networks with Global Attention&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/pdf/2201.08821.pdf">Paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>加深GNN层数来增加感受野会导致优化不稳定性，比如梯度消失和oversmoothing。 因此本文采用Transformer-based self-attention来学习成对节点间的长距离关系，并且提出一种新型的readout池化机制来学习global graph embedding。即在一个GNN模块后接一个置换不变（permutation-invariant）Transformer, GNN模块捕获local信息，Transformer捕获global信息。</p>
<p>GNN作为一种专门的架构医学系节点<strong>直接邻域结构的局部表示</strong>， 而Transformer作为全局推理模块以位置无关的方式计算所有成对节点的交互。作者认为，一个没有positional encoding的Transformer是置换不变的，因此很适合图。</p>
<h1 id="motivation">Motivation</h1>
<p>强关系Inductive bias(我的理解是Homophily假设) 鼓励学习局部短距离的关联性。 而对于长距离相关性，结构化较低的模块（不需要过于考虑图的结构信息）更受欢迎。</p>
<p><strong>GraphTrans leaves learning long-range dependencies to Transformer</strong>, 通过Transformer来学习图中所有节点对的依赖关系而不是只关注局部邻居。</p>
<p>下图中展示了一个子图的attention map。一共有17个节点，横坐标表示目标节点，纵坐标表示源节点，第$i$行第$j$列表示节点$i$在Transformer中聚合$j$的attention权重。第18行为一个特殊的$&lt;CLS&gt;$token 作为图的readout embedding。结合本文的SOTA效果，表面在学习长距离依赖时不考虑图结构先验（spatial priors）对Graph summarization（graph-level representation）是有必要的</p>
<p><img loading="lazy" src="/posts/2022-03-30-GraphTrans/pic2.png#center" alt="你想输入的替代文字"  />
</p>
<h1 id="model">Model</h1>
<p><img loading="lazy" src="/posts/2022-03-30-GraphTrans/pic1.png#center" alt="你想输入的替代文字"  />
</p>
<h2 id="gnn-module">GNN Module</h2>
<p>一个通用的GNN模块：
$$
\boldsymbol{h}_{v}^{\ell}=f_{\ell}\left(\boldsymbol{h}_{v}^{\ell-1},\left\{\boldsymbol{h}_{u}^{\ell-1} \mid u \in \mathcal{N}(v)\right\}\right), \quad \ell=1, \ldots, L_{\mathrm{GNN}}
$$</p>
<h2 id="transformer-module">Transformer Module</h2>
<p>通过上面的GNN模块，我们可以得到每个节点的embedding $h_{v}^{L_{\mathrm{GNN}}}$, 将所有节点作为Transformer的Input。传统Transformer中输入先计算Self-attention（当前输入的$Q$向量和所有节点的$K$向量做内积得到输入节点和其他节点的att值，再用这个att值来为当前输入节点加权聚合所有节点的$V$向量），聚合后再和自身相加做residual,然后在做Layer Norm, 即对节点$i$的表示做Layer Norm 为$x_i^\prime = \frac{x_i-m}{\sigma}$, 其中$m$为$x_i$的均值， $\sigma$为$x_i$的标准差。</p>
<p>这里的Transformer不同的是， 先对所有节点做一次MLP，然后直接计算Layer Norm:
$$
\overline{\boldsymbol{h}}_{v}^{0}=\operatorname{LayerNorm}\left(\boldsymbol{W}^{\text {Proj }} \boldsymbol{h}_{v}^{L_{\mathrm{GNN}}}\right)
$$
其中$\boldsymbol{W}^{\text {Proj }} \in \mathbb{R}^{d_{\mathrm{TF}} \times d_{L_{\mathrm{GNN}}}}$， 把GNN的输出维度转为TF的输入维度$d_{\mathrm{TF}}$。将所有节点的GNN node embeddings作为Transformer的输入（无positional encoding）。 每个节点的$Q$, $K$和$V$向量分别用$\boldsymbol{W}_{\ell}^{Q}, \boldsymbol{W}_{\ell}^{K}, \boldsymbol{W}_{\ell}^{V} \in \mathbb{R}^{d_{\mathrm{TF}} / n_{\text {head }} \times d_{\mathrm{TF}} / n_{\text {head }}}$计算， 对于第$\ell$层 Transformer,  节点$v$ 的$Q$向量$Q_v = \boldsymbol{W}_{\ell}^{Q} \overline{\boldsymbol{h}}_{v}^{\ell-1}$和节点$u$的$K$向量$K_u = \boldsymbol{W}_{\ell}^{K} \overline{\boldsymbol{h}}_{u}^{\ell-1}$做内积，得到两个节点之间的attention。然后用$\alpha_{v, u}^{\ell}$来为节点$v$聚合其他所有节点的$V$向量$V_u = \boldsymbol{W}_{\ell}^{V} \overline{\boldsymbol{h}}_{u}^{\ell-1}$, 如下所示:
$$
a_{v, u}^{\ell}=\left(\boldsymbol{W}_{\ell}^{Q} \overline{\boldsymbol{h}}_{v}^{\ell-1}\right)^{\top}\left(\boldsymbol{W}_{\ell}^{K} \overline{\boldsymbol{h}}_{u}^{\ell-1}\right) / \sqrt{d_{\mathrm{TF}}} \tag{1}
$$</p>
<p>$$
\alpha_{v, u}^{\ell}=\operatorname{softmax}_{u \in \mathcal{V}}\left(a_{v, u}^{\ell}\right) \tag{2}
$$</p>
<p>$$
\overline{\boldsymbol{h}}_{v}^{\prime \ell}=\sum_{w \in \mathcal{V}} \alpha_{v, u}^{\ell} \boldsymbol{W}_{\ell}^{V} \overline{\boldsymbol{h}}_{u}^{\ell-1} \tag{3}
$$</p>
<h2 id="cls--embedding-as-a-gnn-readout-method">&lt;CLS&gt;  embedding as a GNN “readout” method</h2>
<p>Graph Pooling 部分旨在基于node embedding，得到整个图的一个global embedding. 大多数pooling方法为简单的mean,sum, 或者构造一个virtual node连接到所有节点并参与训练，这个virtual node聚合所有节点的信息作为global embedding。</p>
<p>本文提出special-token readout module。具体来说，对Transformer的输入$[\overline{\boldsymbol{h}}_{v}^{0}]_{v\in V}$, where $\overline{\boldsymbol{h}}_{v}^{0} \in \mathcal{R}^{d_{TF}}$我们添加一个额外的可学习embedding （可以被认为是一个额外virtual node）$\bar{h}_{\langle\mathrm{CLS}\rangle} \in \mathbb{R}^{d_{\mathrm{TF}}}$, 这样 Transformer 的输入就变为$[\overline{\boldsymbol{h}}_{v}^{0}]_{v \in V} \cup \bar{h}_{\langle\mathrm{CLS}\rangle}$, 因为训练过程中$\overline{\boldsymbol{h}}_{v}^{0}$回聚合来自所有节点的信息，所以用它来作为readout embedding。 最终Transformer输出的token embedding $\overline{\boldsymbol{h}}_{&lt;\mathrm{CLS}&gt;}^{L_{\mathrm{TF}}}$ 再过一层MLP后用Softmax输出图的prediction:
$$
y=\operatorname{softmax}\left(\boldsymbol{W}^{\mathrm{out}} \overline{\boldsymbol{h}}_{&lt;\mathrm{CLS}&gt;}^{L_{\mathrm{TF}}}\right)
$$</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
