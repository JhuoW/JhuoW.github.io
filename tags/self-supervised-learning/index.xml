<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Self-Supervised Learning on JhuoW‘s Notes</title>
    <link>https://JhuoW.github.io/tags/self-supervised-learning/</link>
    <description>Recent content in Self-Supervised Learning on JhuoW‘s Notes</description>
    <image>
      <url>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Apr 2022 22:54:10 +0800</lastBuildDate><atom:link href="https://JhuoW.github.io/tags/self-supervised-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>NeurIPS2021 《From Canonical Correlation Analysis to Self-supervised Graph Neural Networks》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/cca-ssg/</link>
      <pubDate>Thu, 14 Apr 2022 22:54:10 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/cca-ssg/</guid>
      <description>NeurIPS2021 &amp;#34;From Canonical Correlation Analysis to Self-supervised Graph Neural Networks&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2106.12484">paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>本文提出了一种新型的Graph Contrastive Learning构造Contrastive pairs的方式，即将跨图的同纬度特征作为positive pairs， 不同维度特征作为negative pairs。 和过去的GCL方法相比，本文无需互信息估计器（MI Estimator），映射头（Projector），不对称结构（asymmetric structures）。 并且理论证明了该方法可以看做Information Bottleneck 原则在自监督设置下的实例。</p>
<p>具体来说，受典型相关分析（From Canonical Correlation Analysis）的启发，本文提出了一种简单有效的GCL框架，从而是模型避免复杂难以理解多模块设计。 和过去的方法<strong>相同</strong>的是，为输入图以随机增强的方式生成两个view， 目的是为两个view学习共享的 node representations 通过共享的GNN Encoder。<strong>不同</strong>在于，本文利用了典型相关分析（CCA），具体来说，新目标旨在最大化同一输入的两个增强views之间的相关性，同时对单个视图表示的不同（特征）维度进行去相关（避免不同维度捕获相同信息，即同一个view内的不同维度channel互为negative pairs）。 这么做的目的是 1）本质上追求的是丢弃增强后变化的信息，同时保留增强后不变的信息，以及 2）防止维度崩溃（即不同维度捕获相同的信息）。</p>
<p><img loading="lazy" src="/posts/2022-04-15-CCA-SSG/1.png#center" alt=""  />
</p>
<p>和其他方法的对比如上图所示， 本文提出的CCA-SSG无需negative pairs， 参数化的互信息估计器， projection head或者不对称结构。对比对的数量仅为$O(D^2)$, 其中$D$为输出维度。</p>
<h1 id="canonical-correlation-analysis">Canonical Correlation Analysis</h1>
<p>CCA: Identify and Quantify the associations between  two sets of variables， 即CCA用来衡量两组随机变量的相关性，每组可能有很多Random Variables.</p>
<p>从相关系数引入：</p>
<p>Pearson 相关系数： 给定两组数据集$X$， $Y$。 其中$X \in \mathbb{R}^{N \times 1}$ 表示只有一个随机变量（属性），样本数为$N$。 $Y \in  \mathbb{R}^{M \times 1}$: 一个随机变量，样本量为$M$。那么Pearson 相关系数$\rho$定义为：
$$
\rho(X,Y)=  \frac{\mathrm{Cov}(X,Y)}{\sigma_X \sigma_Y}
$$
其中$\sigma_X$，$\sigma_Y$分别为$X$和$Y$的标准差。$\mathrm{Cov}(X,Y)$为$X$, $Y$的协方差。$\rho \in [-1,1]$。 $\rho$越接近1， $X$和$Y$的线性相关性越高。$\rho$越接近0，$X$和$Y$的线性相关性月底。</p>
<p><strong>相关系数存在问题</strong>：相关系数不适用于高维数据。 如果$X$是2维的（2个属性，例如身高和体重）， $Y$也是2维的，属性为(跑步，跳远)， $X \in \mathbb{R}^{N \times 2}$, $Y \in  \mathbb{R}^{M \times 2}$。此时，相关系数$\rho$無法計算2維隨機變量的相關程度。</p>
<h2 id="cca-基本思想">CCA 基本思想</h2>
<p>$X$和$Y$ 为两个变量集合， 例如$X$中有两个随机变量（2维）， $Y$中也有两个随机变量。 要衡量变量间的相关性： 现将高维随机变量（即多个随机变量）降到一维（一个随机变量），再用相关系数计算相关性。</p>
<p>令$X = \{\boldsymbol{x}_1,\boldsymbol{x}_2\} \in \mathbb{R}^{n_1\times m}$， 表示$n_1=2$个随机变量，$m$个样本。 $Y = \{\boldsymbol{y}_1,\boldsymbol{y}_2\} \in \mathbb{R}^{n_2\times m}$表示$n_2=2$个随机变量，$m$个样本。</p>
<p>$U$为随机变量集合$X$的线性组合：
$$
U = a_1 \boldsymbol{x}_1 + a_2 \boldsymbol{x}_2 = [a_1, a_2]\begin{bmatrix} \boldsymbol{x}_1 \\ \boldsymbol{x}_2\end{bmatrix} = a^\top X
$$
$V$为随机变量集合$Y$的线性组合：
$$
V = b_1 \boldsymbol{y}_1 + b_2\boldsymbol{x}_2 = b^\top Y
$$
<strong>CCA</strong>的优化目标： 找到一组最优解$a$和$b$， 使得$\rho_{U,V}$最大：
$$
\arg \max_{a,b} \rho_{U,V} = \frac{\mathrm{Cov}(U,V)}{\sigma_U \sigma_V}
$$
得到的$a$, $b$是使得$X$与$Y$有最大关联的权重。</p>
<h2 id="cca的表示与求解">CCA的表示与求解</h2>
<p>输入：两个随机变量集合$X = \{\boldsymbol{x}_1 , \cdots, \boldsymbol{x}_n\}$, $Y= \{\boldsymbol{y}_1 , \cdots, \boldsymbol{y}_m\}$。 分别有$n$个和$m$个随机变量。</p>
<p>$X$是一个$n \times L$的矩阵， 即有$L$个样本， $n$个属性（$n$个随机变量）。</p>
<p>$Y$是一个$m \times L$的矩阵， $L$个样本， $m$个属性。</p>
<p>$U = a^\top X \in \mathbb{R}^{1 \times L}$, $V= b^\top Y \in \mathbb{R}^{1\times L}$, 分别将组高维随机变量转为一维。 目标函数为
$$
\arg \max_{a,b} \rho_{U,V} =\arg \max_{a,b}  \frac{\mathrm{Cov}(U,V)}{\sigma_U \sigma_V}
$$
设 $\Sigma_{XX} = \mathrm{Cov}(X,X) = \mathrm{Var}(X)$， $\Sigma_{YY} = \mathrm{Cov}(Y,Y) = \mathrm{Var}(Y)$， $\Sigma_{XY} = \mathrm{Cov}(X,Y)$， $E[X] = \mu_X \in \mathbb{R}^{n \times 1}$ （样本均值）， $E[Y] = \mu_Y \in \mathbb{R}^{m \times 1}$。</p>
<p>定义$X$ 为一个$n$个随机变量stack成的列向量：
$$
X= \begin{bmatrix} \boldsymbol{x}_1 \\ \cdots \\ \boldsymbol{x}_n\end{bmatrix} \in \mathbb{R}^{n \times L}
$$
$C$ 为$n$个scalars $c_1, \cdots, c_n$ stack成的列向量：
$$
C= \begin{bmatrix} \boldsymbol{c}_1 \\ \cdots \\ \boldsymbol{c}_n\end{bmatrix}
$$
$C^\top X$是这$n$个Random Variables的线性组合。 $C^\top X$的方差为：
$$
\mathrm{Var}(C^\top X) = C^\top \Sigma_{XX} C = C^\top \mathrm{Var}(X) C
$$
那么$\mathrm{Var}(U) = \mathrm{Var}(a^\top X) = a^\top \mathrm{Var}(X) a$。</p>
<p>每个随机变量$\boldsymbol{x}_i$为数据的第$i$个特征，每列为一个样本$X \in \mathbb{R}^{n \times L}$。 有$L$个样本， 对特征维度做标准化，也就是对每个维度$\boldsymbol{x}_i$做标准化， 可得$E(\boldsymbol{x}_i) = 0$, $\mathrm{Var}(\boldsymbol{x}_i) = 1$。
$$
\begin{aligned}
\mathrm{Var}(X) &amp;= E(X-E(X))^2 \\
&amp;= E(\begin{bmatrix} \boldsymbol{x}_1 \\ \cdots \\ \boldsymbol{x}_n\end{bmatrix} -\begin{bmatrix} \boldsymbol{\mu}_1 \\ \cdots \\ \boldsymbol{\mu}_n\end{bmatrix} )^2   \\
&amp;= E (\begin{bmatrix} \boldsymbol{x}_1 \\ \cdots \\ \boldsymbol{x}_n\end{bmatrix}^2) \\
&amp;= E(XX^\top)
\end{aligned}
$$
所以$\mathrm{Var}(U) = a^\top E(XX^\top) a$， 同理$\mathrm{Var}(V) = b^\top E(YY^\top) b$。另外：
$$
E(a^\top X) = E(a_1\boldsymbol{x}_1 + \cdots + a_n\boldsymbol{x}_n) = a_1E(\boldsymbol{x}_1) + \cdots + a_n E(\boldsymbol{x}_n) = 0
$$
那么：
$$
\begin{aligned}
\mathrm{Cov}(U,V) &amp;= \mathrm{Cov}(a^\top X, b^\top Y) \\
&amp;= E\left[ \langle a^\top X - E(a^\top X), b^\top Y- E(b^\top Y) \rangle  \right] \\
&amp;= E[\langle a^\top X,  b^\top Y \rangle] \\
&amp;= E[(a^\top X)(b^\top Y)^\top] \\
&amp;= E[a^\top X Y^\top b] \\
&amp;= a^\top E[XY^\top]b
\end{aligned}
$$</p>
<p>$$
\begin{aligned}
\mathrm{Var}(X) &amp;= \mathrm{Cov}(X,X) = E[XX^\top] \\
\mathrm{Var}(Y) &amp;= \mathrm{Cov}(Y,Y) = E[YY^\top] \\
\mathrm{Cov}(X,Y) &amp;= E[\langle X-\mu_X, Y-\mu_Y \rangle] = E[XY^\top] = \Sigma_{XY}\\
\mathrm{Cov}(Y,X) &amp;=E[YX^\top]
\end{aligned}
$$</p>
<p>优化目标转化为：
$$
\begin{aligned}
\arg \max_{a,b} \rho_{U,V} &amp;=\arg \max_{a,b}  \frac{\mathrm{Cov}(U,V)}{\sigma_U \sigma_V}  \\
&amp;=\arg \max_{a,b} \frac{a^\top \Sigma_{XY}b}{\sqrt{a^\top \Sigma_{XX} a} \sqrt{b^\top \Sigma_{YY}b}}
\end{aligned}
$$
若对$a$， $b$同时放缩， 即$a$放缩$k$倍， $b$放缩$l$倍， 公式的值不会改变：
$$
\frac{ka^\top \Sigma_{XY}lb}{\sqrt{ka^\top \Sigma_{XX} ka} \sqrt{lb^\top \Sigma_{YY}lb}} =  \frac{a^\top \Sigma_{XY}b}{\sqrt{a^\top \Sigma_{XX} a} \sqrt{b^\top \Sigma_{YY}b}}
$$
所以， 可以直接对$a$做放缩，使得$a^\top \Sigma_{XX} a=1$, 对$b$做放缩，使得$b^\top \Sigma_{YY}b=1$（类似于SVM）。 那么优化目标转化为：
$$
\begin{aligned}
&amp;\max_{a, b} a^{\top} \Sigma_{X Y} b, \\ &amp;\text{ s.t. } a^{\top} \Sigma_{X X} a=b^{\top} \Sigma_{Y Y} b=1
\end{aligned}
$$
对于两个向量集合$X_1$和$X_2$， CCA 寻求两组向量最大化它们的相关性，并受到它们彼此不相关的约束。 后来的研究通过用神经网络代替线性变换，将 CCA 应用于具有深度模型的多视图学习。 具体来说，假设 $X_1$和$X_2$作为输入数据的两个视图，CCA的优化目标为：
$$
\max_{\theta_{1}, \theta_{2}} \operatorname{Tr}\left(P_{\theta_{1}}^{\top}\left(X_{1}\right) P_{\theta_{2}}\left(X_{2}\right)\right) \quad \text { s.t. } P_{\theta_{1}}^{\top}\left(X_{1}\right) P_{\theta_{1}}\left(X_{1}\right)=P_{\theta_{2}}^{\top}\left(X_{2}\right) P_{\theta_{2}}\left(X_{2}\right)=I \text {. }  \tag{1}
$$
其中， $P_{\theta_{1}}$和$P_{\theta_{2}}$为两个Neural Network。尽管上式很精确，但这种计算确实很昂贵。Soft CCA 通过采用以下拉格朗日松弛, 消除了hard decorrelation constraint：
$$
\min_{\theta_{1}, \theta_{2}} \mathcal{L}_{\text {dist }}\left(P_{\theta_{1}}\left(X_{1}\right), P_{\theta_{2}}\left(X_{2}\right)\right)+\lambda\left(\mathcal{L}_{S D L}\left(P_{\theta_{1}}\left(X_{1}\right)\right)+\mathcal{L}_{S D L}\left(P_{\theta_{2}}\left(X_{2}\right)\right)\right)
$$
其中$\mathcal{L}_{\text {dist }}$用于衡量两个view的representations之间的相关性，$\mathcal{L}_{S D L}$ (stochastic decorrelation loss)计算$P_{\theta_{i}}\left(X_{i}\right)$和identity matrix之间的$L_1$距离。</p>
<h1 id="approach">Approach</h1>
<p><img loading="lazy" src="/posts/2022-04-15-CCA-SSG/2.png#center" alt=""  />
</p>
<p>模型包含3个模块 1. 随机图增强器$\mathcal{T}$，2. GNN encoder $f_\theta$, 3. 基于CCA的feature-level对比损失。</p>
<h2 id="graph-augmentations">Graph Augmentations</h2>
<p>本文利用 edge droping和 node feature masking两种graph corruption方式来对输入图做增强。 $\mathcal{T}$是所有可能的转换操作，$t \sim \mathcal{T}$表示图$G$的一种特定的转换。比如删除一条边的操作$t_r$就是$\mathcal{T}$中的一个变换。</p>
<h2 id="training">Training</h2>
<p>从$\mathcal{T}$随机采样两种图变换 $t_A$和$t_B$。 生成两个View: $\tilde{\mathbf{G}}_{A}=\left(\tilde{\mathbf{X}}_{A}, \tilde{\mathbf{A}}_{A}\right)$和$\tilde{\mathbf{G}}_{B}=\left(\tilde{\mathbf{X}}_{B}, \tilde{\mathbf{A}}_{B}\right)$，经过共享的GNN后，得到输出$\mathbf{Z}_{A}=f_{\theta}\left(\tilde{\mathbf{X}}_{A}, \tilde{\mathbf{A}}_{A}\right)$，$\mathbf{Z}_{B}=f_{\theta}\left(\tilde{\mathbf{X}}_{B}, \tilde{\mathbf{A}}_{B}\right)$。然后对feature dimensionzuo normalization (列标准化)， 是的每个特征维度均值为0， 标准差为$1 / \sqrt{N}$：</p>
<p>$$
\tilde{\mathbf{Z}}=\frac{\mathbf{Z}-\mu(\mathbf{Z})}{\sigma(\mathbf{Z}) * \sqrt{N}}
$$</p>
<h1 id="inference">Inference</h1>
<p>基于公式（1）,使用公式(1)中的CCA目标函数，将向量集定义为输出$\tilde{\mathbf{Z}}$的列向量， 最终CCA-SSG的目标函数定义如下：
$$
\mathcal{L}=\underbrace{\left|\left|\tilde{\mathbf{Z}}_{A}-\tilde{\mathbf{Z}}_{B}\right|\right|_{F}^{2}}_{\text {invariance term }}+\lambda \underbrace{\left(\left|\left|\tilde{\mathbf{Z}}_{A}^{\top} \tilde{\mathbf{Z}}_{A}-\mathbf{I}\right|\right|_{F}^{2}+\left|\left|\tilde{\mathbf{Z}}_{B}^{\top} \tilde{\mathbf{Z}}_{B}-\mathbf{I}\right|\right|_{F}^{2}\right)}_{\text {decorrelation term }}
$$
第二项中，要求不同特征之间的相似度尽可能低， 从而使得不同特征捕获不同的语义信息。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ICML2020 《Contrastive Multi-View Representation Learning on Graphs》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/mvgrl/</link>
      <pubDate>Tue, 12 Apr 2022 22:21:29 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/mvgrl/</guid>
      <description>ICML2020 &amp;#34;Contrastive Multi-View Representation Learning on Graphs&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2006.05582">paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>本文旨在通过多视图Contrastive Learning 来学习节点表示和图表示。其中对比视图为结构视图（structural view）。本文发现，两个以上的对比视图不会提升性能（我觉得仅是针对本文的Diffusion-based view吧~）。 本文实验性的表明了基于一阶邻居和图扩散视图做CL可以达到最好的效果。</p>
<p>为了将对比学习应用到图表示学习任务，本文提出通过最大化图的不同结构视角的互信息来作为监督信号。通过对提出框架的系统研究，本文展示了一些GCL和visual CL上的不同： （1）将view数量（即增强）增加到两个以上不会提高性能，最好的性能是通过对比来自一阶邻居view的embedding和graph diffusion的embedding，(2) 与对比图编码或多尺度编码相比，跨视图对比节点和图编码在node classification 和 graph classification上都能获得更好的结果。 (3) 与分层图池化方法（例如DiffPool相比）一个简单的Readout在这node classification 和 graph classification上实现了更好的性能，以及 (4) 应用正则化（early stopping除外） 或归一化层对性能有负面影响。</p>
<h1 id="method">Method</h1>
<p><img loading="lazy" src="/posts/2022-04-13-MVGRL/1.png" alt=""  />
</p>
<p>MVGRL通过最大化一个view的node embedding和另一个view的graph embedding之间的 互信息来学习节点和图表示。如上图所示，MVGRL由以下几个部分构成</p>
<ul>
<li><strong>增强机制</strong>：将样本图转化为同一个图的相关view， 这个view只是structural view， 不会改变原图中的node feature，然后对两个增强图中的相同节点（identical node）进行子采样，类似于CV中的域剪裁。</li>
<li><strong>两个专用的GNNs</strong>， 每个view一个GNN，再接一个共享的MLP作为projection head，来为两个view学习representation。</li>
<li><strong>图池化层</strong>， 在MLP后学习两个图的graph-level representation。</li>
<li><strong>判别器</strong> 来对比一个图的embedding和另一个图的节点embedding,并对他们的一致性（agreement）评分。</li>
</ul>
<h2 id="augmentations">Augmentations</h2>
<p>考虑两种类型的图增强：(1) 对初始节点特征进行操作的特征空间增强，例如，mask或添加高斯噪声，以及 (2) 通过添加或删除连通性、子采样或使用最短路径或diffusion matrix生成全局视图来对做图结构增强。 前一种增强可能是有问题的，因为许多数据集不带有初始节点特征。 此外，观察到在任一空间上屏蔽或添加噪声都会降低性能。 因此，本文选择生成全局视图，然后进行子采样。</p>
<p>实验表明，在大多数情况下，最好的结果是通过将邻接矩阵转化为扩散矩阵，并将这两个矩阵视为同一图的结构的两个一致view。因为<strong>邻接矩阵和扩散矩阵分别提供了图结构的局部和全局视图</strong>，从这两种view中学习到的表示之间最大一致性，从而鼓励模型同时编码的局部和全局信息。</p>
<p>Diffusion matrix从全局角度提供了任意节点对之间的相关性，其中$\mathbf{T} \in \mathbb{R}^{n \times n}$是通用转移矩阵，$\Theta$是权重系数，决定了全局和局部信息的比例，即对于每个节点，不同层次信息的比重， $\Theta_{k}$越大，表示全局信息权重越大。 令$\sum_{k=0}^{\infty} \theta_{k}=1, \theta_{k} \in[0,1]$，$\lambda_{i} \in[0,1]$,其中$\lambda$是$\mathbf{T}$的特征向量，  这样来保证$\mathbf{S}$可以收敛到一个固定矩阵。扩散用快速近似值和稀疏化方法计算：
$$
\mathbf{S}=\sum_{k=0}^{\infty} \Theta_{k} \mathbf{T}^{k} \in \mathbb{R}^{n \times n}
$$
给定一个邻接矩阵$\mathbf{A} \in \mathbb{R}^{n \times n}$和一个对角度矩阵$\mathbf{D} \in \mathbb{R}^{n \times n}$, Personalized PageRank (PPR)和Heat Kernel分别为两种不同的Diffusion matrix实例。对于PPR和HK，转移概率矩阵定义为$\mathbf{T}=\mathbf{A} \mathbf{D}^{-1}$。PPR将第$k$层的权重系数设置为$\theta_{k}=\alpha(1-\alpha)^{k}$, 而HK将第$k$层的权重系数设置为$\theta_{k}=e^{-t} t^{k} / k !$。</p>
<p>PPR的封闭阶如下所示：
$$
\mathbf{S}^{\mathrm{PPR}}=\alpha\left(\mathbf{I}_{n}-(1-\alpha) \mathbf{D}^{-1 / 2} \mathbf{A} \mathbf{D}^{-1 / 2}\right)^{-1}
$$
HK的封闭解如下所示：
$$
\mathbf{S}^{\text {heat }}=\exp \left(t \mathbf{A} \mathbf{D}^{-1}-t\right)
$$</p>
<h2 id="sub-sampling">Sub-Sampling</h2>
<p>从一个view中<strong>随机采样节点及其边</strong>，并从另一个view中<strong>选择exact的的节点和边</strong> (如示意图所示， 从第一个图中采样节点和边的子图作为一个view，从第二个图中采样相同节点以及这些节点之间的边作为另一个view，来做对比学习)。这个过程允许MVGRL应用于具有图数据不适合GPU内存的inductive任务，也可以通过将子样本视为独立的图来考虑transductive任务。</p>
<h2 id="encoder">Encoder</h2>
<p>和其他GCL方法不同的是，这里不同视图使用的是各自的GNN编码器， 邻接矩阵和Diffusion matrix是同一个图的两个一致视角，分别反映了局部和全局性质。首先，为两种view采样之后的子图分别定义GNN encoder：$g_{\theta}(.), g_{\omega}(.): \mathbb{R}^{n \times d_{x}} \times \mathbb{R}^{n \times n} \longmapsto \mathbb{R}^{n \times d_{h}}$， 使用最简单的GCN，传播矩阵分别为normalized adjacency matrix $\sigma(\tilde{\mathbf{A} }X \boldsymbol{\Theta})$ 和 Diffusion Matrix:  $\sigma(\mathbf{S} X \boldsymbol{\Theta})$。学习到的embedding输入projection head （MLP）$f_{\psi}(.): \mathbb{R}^{n \times d_{h}} \longmapsto \mathbb{R}^{n \times d_{h}}$中， 得到两个view的输出node embedding matrix: $\mathbf{H}^{\alpha}, \mathbf{H}^{\beta} \in \mathbb{R}^{n \times d_{h}}$。</p>
<p>接下来使用pooling $\mathcal{P}(.): \mathbb{R}^{n \times d_{h}} \longmapsto \mathbb{R}^{d_{h}}$ 输出两个view的graph representations。 本文采用JKnet中的跳连机制，即GNN的每层输出做sum pooling, 然后将所有层拼起来做特征变换：
$$
\vec{h}_{g}=\sigma\left(||_{l=1}^{L}\left[\sum_{i=1}^{n} \vec{h}_{i}^{(l)}\right] \mathbf{W}\right) \in \mathbb{R}^{h_{d}}
$$
其中$\vec{h}_{i}^{(l)}$是节点$i$的第$l$层输出，$||$是concatenation， $\mathbf{W} \in \mathbb{R}^{\left(L \times d_{h}\right) \times d_{h}}$是特征变换参数，$\sigma$是PReLU非线性激活。最终，将图表示输入到一个projection head $f_{\phi}(.): \mathbb{R}^{d_{h}} \longmapsto \mathbb{R}^{d_{h}}$ 中，得到最终的图表示：$\vec{h}_{g}^{\alpha}, \vec{h}_{g}^{\beta} \in \mathbb{R}^{d_{h}}$。</p>
<p>在推理阶段， 由于两个view来自同一个图，可以把两个view的表示结合起来作为原图的表示：两个view的graph embedding直接相加，作为原图 embedding.。 两个view的node embedding 直接相加，作为原图的node embedding $\vec{h}=\vec{h}_{g}^{\alpha}+\vec{h}_{g}^{\beta} \in \mathbb{R}^{n}$ 。 $\mathbf{H}=\mathbf{H}^{\alpha}+\mathbf{H}^{\beta} \in \mathbb{R}^{n \times d_{h}}$。 这里得到的原图embedding可以应用于下游任务。</p>
<h2 id="training">Training</h2>
<p>为了端到端训练encoder并学习与下游任务无关的丰富节点和图级表示，本文利用 Deep InfoMax 方法并通过对比一个视图的节点表示与图表示来最大化两个视图之间的 互信息。 实验表明，这种方法在节点和图分类上始终优于对比图-图或多尺度编码。 目标定义如下：
$$
\max_{\theta, \omega, \phi, \psi} \frac{1}{|\mathcal{G}|} \sum_{g \in \mathcal{G}}\left[\frac{1}{|g|} \sum_{i=1}^{|g|}\left[\operatorname{MI}\left(\vec{h}_{i}^{\alpha}, \vec{h}_{g}^{\beta}\right)+\operatorname{MI}\left(\vec{h}_{i}^{\beta}, \vec{h}_{g}^{\alpha}\right)\right]\right]
$$
其中$\theta, \omega, \phi, \psi$为是GNN encoder和projection head的参数, $|\mathcal{G}|$是图数量，$|\mathcal{g}|$是图中节点数， $\vec{h}_{i}^{\alpha}, \vec{h}_{g}^{\beta}$分别表示view $\alpha$中的节点$i$的representation， 和view $\beta$的 graph representation。</p>
<p>互信息判别器： $\mathcal{D}(., .): \mathbb{R}^{d_{h}} \times \mathbb{R}^{d_{h}} \longmapsto \mathbb{R}$简单的设置为表示向量间的内积相似度：
$$
\mathcal{D}\left(\vec{h}_{n}, \vec{h}_{g}\right)=\vec{h}_{n} \cdot \vec{h}_{g}^{T}
$$
作者发现当判别器和projection head集成到双线性层中时，节点分类基准略有改进。 为了确定 MI 估计器，实验中调查了四个估计器并为每个基准选择了最好的一个。</p>
<p>正样本采样自联合分布$x_{p} \sim p\left(\left[\mathbf{X}, \tau_{\alpha}(\mathbf{A})\right],\left[\mathbf{X}, \tau_{\beta}(\mathbf{A})\right]\right)$， 从边际乘积中采样负样本 $x_{p} \sim p\left(\left[\mathbf{X}, \tau_{\alpha}(\mathbf{A})\right]\right) p\left(\left[\mathbf{X}, \tau_{\beta}(\mathbf{A})\right]\right)$。利用小批量随机梯度下降法对模型参数进行优化。 MVGRL算法如下：</p>
<p><img loading="lazy" src="/posts/2022-04-13-MVGRL/2.png" alt=""  />
</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>WWW2022 《SimGRACE:A Simple Framework for Graph Contrastive Learning without Data Augmentation》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/simgrace/</link>
      <pubDate>Sat, 09 Apr 2022 14:47:57 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/simgrace/</guid>
      <description>WWW2022 &amp;#34;SimGRACE:A Simple Framework for Graph Contrastive Learning without Data Augmentation&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2202.03104">paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>图对比学习（GCL）已经成为图表示学习的主要技术，它最大化了共享相同语义的成对图增强之间的互信息。鉴于图数据的多样性，在增强过程中很难很好地保留语义。目前，GCL 中选择图增强方式的途径通常有以下三种。 1.  适用于不同数据集的图增强方式可能是不同的，需要在每个数据集上做验证，手动选择最适用于每个数据集的增强。2. 通过繁琐的搜索来选择增强方式。3. 通过邻域只是来选择增强方式。所有这些都限制了现有 GCL 方法的效率和通用性。为了解决该问题，本文提出了一种不需要对图做编辑， 而是对GNN编码器做扰动的增强方式： <strong>SimGRACE</strong>。并且对SimGRACE设计了对抗训练的方案：<strong>AT-SimGRACE</strong>。</p>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/1.png#center" alt="图1"  title="123"  />
</p>
<p>上图的实验中，两类图用不同的颜色标出，三种GCL模型分别在三个数据集上训练，训练完成后的分类效果如第一行所示。 对于GraphCL, 对边做扰动后再输入GraphCL 训练好的encoder,可以看出GraphCL的encoder对于扰动后的图数据集无法很好的保留分类语义。而对于SIMGRACE，不对图做扰动，而对训练好的encoder做扰动，扰动后的encoder对数据集的分类效果可以很好地保留语义信息。由此实验性表明了对encoder扰动可以保留比直接对图扰动更多的语义信息。</p>
<p>GraphCL 表明 GNN 可以使用他们提出的框架获得鲁棒性。 但是，（1）他们没有解释为什么 GraphCL 可以增强鲁棒性； (2) GraphCL 似乎对随机攻击具有很好的免疫力，而对对抗性攻击的表现却不尽如人意。为了弥补这些缺陷，本文基于SimGRACE提出了一种新的算法 AT-SimGRACE通过对抗的方式来扰动编码器，从而是实现对抗训练的效果，它引入了更少的计算开销，同时显示出更好的鲁棒性。</p>
<h1 id="method">Method</h1>
<h2 id="simgrace">SimGRACE</h2>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/2.png#center" alt="图1"  />
</p>
<h3 id="编码器扰动encoder-perturbation">编码器扰动（Encoder perturbation）</h3>
<p>给定一个GNN编码器$f(\cdot;\theta)$,它的参数扰动版本表示为$f(\cdot;\theta^\prime)$。如图中所示，参数扰动版本的编码器不需要梯度反传训练参数，每次训练过程更新$f(\cdot;\theta)$，而$f(\cdot;\theta^\prime)$的参数$\theta^\prime$只通过对$\theta$扰动得到。第$l$层GNN的参数表示为$\theta_l$，那么它的扰动后参数$\theta^\prime_l$有下式得到：
$$
\theta_{l}^{\prime}=\theta_{l}+\eta \cdot \Delta \theta_{l} ; \quad \Delta \theta_{l} \sim \mathcal{N}\left(0, \sigma_{l}^{2}\right)
$$
其中$\eta$用来控制扰动的缩放，$\Delta \theta_{l}$是扰动项，扰动值采样自0均值$\sigma_{l}^{2}$的Gaussian Distribution。$f(\cdot;\theta)$和$f(\cdot;\theta^\prime)$的输出分别为$\mathbf{h}$和$\mathbf{h}^{\prime}$：
$$
\mathbf{h}=f(\mathcal{G} ; \boldsymbol{\theta}), \mathbf{h}^{\prime}=f\left(\mathcal{G} ; \boldsymbol{\theta}^{\prime}\right)
$$
从下图可以看出，如果不对编码器施加扰动，即超参数$\eta=0$，效果会很差，扰动太多效果也会很差。</p>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/3.png#center" alt="图1"  />
</p>
<h3 id="映射头-projection-head">映射头 （Projection Head）</h3>
<p>和其他大多数GCL方法一样，该方法也要一个projection head来对GNN的output representation做一次变换，通常就是个MLP，得到输出$z$和$z^\prime$：
$$
z=g(\mathbf{h}), z^{\prime}=g\left(\mathbf{h}^{\prime}\right)
$$</p>
<h3 id="对比损失contrastive-loss">对比损失（Contrastive loss）</h3>
<p>和GraphCL一样，使用NT-Xent作为损失函数。具体来说，用$z_n$和$z_n^\prime$分别表示表示图$n$在$f(\cdot;\theta)$和$f(\cdot;\theta^\prime)$两个编码器下的输出， 用$z_n$和$z_{n^\prime}$表示一个batch中两个不同图$n$和图$n^\prime$在未扰动编码器$f(\cdot;\theta)$下的输出。在一个batch内，最大化同一个图的两个编码器（$f(\cdot;\theta)$和$f(\cdot;\theta^\prime)$）输出间的相似度，同时最小化不同图在未扰动编码器$f(\cdot;\theta)$下输出的相似度：
$$
\ell_{n}=-\log \frac{\left.\exp \left(\operatorname{sim}\left(z_{n}, z_{n}^{\prime}\right)\right) / \tau\right)}{\sum_{n^{\prime}=1, n^{\prime} \neq n}^{N} \exp \left(\operatorname{sim}\left(z_{n}, z_{n^{\prime}}\right) / \tau\right)}
$$
即同一个图的两个输出为positive pair, 不同图的$f(\cdot;\theta)$输出为negative pair.</p>
<h2 id="why-can-simgrace-work-well">Why can SimGRACE work well?</h2>
<p>[1] 提供了两个属性来衡量对比学习学到的representation的质量： <em>Alignment和Uniformity</em>。其中Alignment metric直接定义为positive pairs之间的距离：
$$
\ell_{\text {align }}(f ; \alpha) \triangleq \underset{(x, y) \sim p_{\text {pos }}}{\mathbb{E}}\left[||f(x)-f(y)||_{2}^{\alpha}\right], \quad \alpha&gt;0
$$
其中$p_{\text {pos }}$为positive pairs的分布，也就是positive pairs之间的距离越小，说明CL越好。 基于SimGRACE构造contrastive pairs的方式，alignment metric 可以定义为如下形式：
$$
\ell_{\text {align }}(f ; \alpha) \triangleq \underset{x \sim p_{\text {data }}}{\mathbb{E}}\left[\left|\left|f(x ; \theta)-f\left(x ; \theta^{\prime}\right)\right|\right|_{2}^{\alpha}\right], \quad \alpha&gt;0
$$
另一个衡量指标是Uniformity， 定义为成对高斯势函数（Gaussian Potential）：
$$
\ell_{\text {uniform }}(f ; \alpha) \triangleq \log \underset{x, y_{\sim}^{i . i . d .} p_{\text {data }}}{\mathbb{E}}\left[e^{-t||f(x ; \theta)-f(y ; \theta)||_{2}^{2}}\right] . \quad t&gt;0
$$
它要求随机样本的embedding应尽可能分散在hypersphere上， 即随机采样两个图在未扰动编码器输出的embedding距离要尽可能大。从下图可以看出，随着training epoch的增加，三种方法都呈现出正确的趋势。</p>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/4.png#center" alt="图1"  />
</p>
<h2 id="at-simgrace">AT-SimGRACE</h2>
<p>通过对抗训练（Adversarial Training， AT）来提升SimGRACE的鲁棒性。 对抗训练的优化问题定义如下：
$$
\min_{\theta} \mathcal{L}^{\prime}(\theta), \quad \text { where } \quad \mathcal{L}^{\prime}(\theta)=\frac{1}{n} \sum_{i=1}^{n} \max_{ | |\mathrm{x}_{i}^{\prime}-\mathrm{x}_{i} | |_{p} \leq \epsilon} \ell_{i}^{\prime}\left(f\left(\mathrm{x}_{i}^{\prime} ; \theta\right), y_{i}\right)
$$
其中$n$是训练样本数，$\mathrm{x}_{i}^{\prime}$是对抗样本， 其中对抗样本在训练样本的$\epsilon$-ball中，即$| |\mathrm{x}_{i}^{\prime}-\mathrm{x}_{i} | |_{p} \leq \epsilon$, 表示对抗样本和原样本的变化不能超过$\epsilon$。Adversarial Training: 优化$\theta$，使得$f$可以在$\mathrm{x}_{i}$的对抗样本$\mathrm{x}_{i}^{\prime}$上可以预测准确。其中$\ell^{\prime}(\cdot)$为监督分类损失，$\mathcal{L}^{\prime}(\theta)$为对抗损失。AT不能直接应用于CL上，因为（1）CL任务无标签，（2）对数据集中的每个样本扰动计算量太大。 为了解决这个问题，本文将AT loss中的损失函数部分换成NT-Xent对比学习损失，然后用对抗的方式来扰动encoder，从而无需对数据集中的所有样本扰动。</p>
<p>假设$\Theta$为GNN的权重空间(weight space)， 对于任意$\mathbf{w}$任意正实数$\epsilon$, 为$\theta$定义半径为$\epsilon$,中心为$\mathbf{w}$的norm ball:
$$
\mathbf{R}(\mathbf{w} ; \epsilon):=\{\boldsymbol{\theta} \in \boldsymbol{\Theta}:||\boldsymbol{\theta}-\mathbf{w}|| \leq \epsilon\}
$$
$\theta \in \Theta$表示权重空间$\Theta$中任意一组可能的GNN权重$\theta$, $\mathbf{R}(\mathbf{w} ; \epsilon)$表示GNN所有与$\mathbf{w}$相似的权重，即所有与$\mathbf{w}$的差距小于$\epsilon$的权重。</p>
<p>那么AT-SimGRACE的优化问题定义如下：
$$
\begin{gathered}
\min_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta}+\Delta) \\
\text { where } \mathcal{L}(\boldsymbol{\theta}+\Delta)=\frac{1}{M} \sum_{i=1}^{M} \max_{\Delta \in \mathrm{R}(0 ; \epsilon)} \ell_{i}\left(f\left(\mathcal{G}_{i} ; \boldsymbol{\theta}+\Delta\right), f\left(\mathcal{G}_{i} ; \boldsymbol{\theta}\right)\right)
\end{gathered}
$$
这里$\mathrm{R}(0 ; \epsilon)=\{\Delta \in \Theta: ||\Delta|| \leq \epsilon\}$ ，$\mathcal{L}(\boldsymbol{\theta}+\Delta)$表示在对GNN参数施加扰动$\Delta$，使得GNN的效果最差，换句话说，找到一个扰动$\Delta$，使得GNN的参数在被$\Delta$扰动后（变为$\theta+\Delta$）两个图最不匹配（对比学习损失达到最大）。 $min_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta}+\Delta)$表示训练GNN参数，使得对比学习可以适应该扰动。算法如下：</p>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/5.png#center" alt="图1"  />
</p>
<p>对抗训练：</p>
<p>内层： 固定GNN参数，训练扰动参数$\Delta$，使得GNN的对比学习loss上升</p>
<p>外层： 固定扰动参数$\Delta$， 训练GNN参数$\theta$， 使得$\theta$加上扰动$\Delta$后的对比学习loss最小化。</p>
<h1 id="reference">Reference</h1>
<p>[1] Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere. ICML (2020)</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ICML2020 《When Does Self-Supervision Help Graph Convolutional Networks?》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/2020-04-03-ssgcns/</link>
      <pubDate>Fri, 08 Apr 2022 14:04:49 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/2020-04-03-ssgcns/</guid>
      <description>ICML2020 &amp;#34;When Does Self-Supervision Help Graph Convolutional Networks?&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2006.09136v4">Paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>本文是自监督方法在GCNs上首次系统的探索，设计了3种自监督任务来将分析自监督在GCN中起到的作用。自监督旨在充分利用unlabeled数据中的知识来设计前置任务（pretext task），来帮助模型学习更具迁移性和泛化能力的表示。前置任务可以认为是对目标任务有帮助的辅助正则化网络，设计用于帮助原任务学习到更多下游任务相关的语义信息。</p>
<p>GCN任务通常是直推半监督的（transductive semi-supervised）,含有大量unlabeled数据，而self-supervision(SSL)可以充分利用unlabeled data， 那么就产生了一个值得探索的问题：<strong>将自监督学习应用到GCN上是否也可以达到提升泛化能力和鲁棒能力的效果？</strong></p>
<p>先给结论</p>
<p>Q1: 自监督学习可否在分类任务中提升GCN？ 如果可以，如何将其合并到 GCN 中以最大化增益？</p>
<p>A1: 本文证明了通过多任务学习将自监督学习融入 GCN 是有效的，即多任务损失作为 GCN 训练中的正则化项。 这种作为自监督作为正则化项的方法，强于用自监督来预训练或者self-training。</p>
<p>Q2: 前置任务的设计重要吗？ GCN 有哪些有用的自监督前置任务？</p>
<p>A2: 本文研究了三个基于图属性的自监督任务。 分别是节点聚类node clustering, 图划分graph partitioning 和图补全graph completion。 并且进一步说明不同的模型和数据集倾向于不同的自监督任务。</p>
<p>Q3: 自监督也会影响 GCN 的对抗鲁棒性吗？ 如果是，如何设计前置任务？</p>
<p>A3: 本文进一步将上述发现推广到对抗性训练环境中。提供了广泛的结果，以表明自监督还可以提高 GCN 在各种攻击下的鲁棒性，而不需要更大的模型或额外的数据。</p>
<h1 id="method">Method</h1>
<p>GCNs $\boldsymbol{Z}=\hat{\boldsymbol{A}} \operatorname{ReLU}\left(\hat{\boldsymbol{A}} \boldsymbol{X} \boldsymbol{W}_{0}\right) \boldsymbol{W}_{1}$可以分为两块来看 (1) 特征提取模块$f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) = \hat{\boldsymbol{A}} \operatorname{ReLU}\left(\hat{\boldsymbol{A}} \boldsymbol{X} \boldsymbol{W}_{0}\right)$ 参数为$\theta = \{\boldsymbol{W}_{0}\}$和（2）线性变换模块$\boldsymbol{Z}=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta}$ 其中 参数$ \boldsymbol{\Theta} = \boldsymbol{W}_{1}$。 半监督GCN优化任务的目标函数为：
$$
\begin{aligned}
\boldsymbol{Z} &amp;=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta} \\
\theta^{*}, \boldsymbol{\Theta}^{} &amp;=\arg \min_{\theta, \boldsymbol{\Theta}} \mathcal{L}_{\mathrm{sup}}(\theta, \boldsymbol{\Theta}) \\
&amp;=\arg \min_{\theta, \boldsymbol{\Theta}} \frac{1}{\left|\mathcal{V}_{\text {label }}\right|} \sum_{v_{n} \in \mathcal{V}_{\text {label }}} L\left(\boldsymbol{z}_{n}, \boldsymbol{y}_{n}\right)
\end{aligned} \tag{1}
$$
其中$L(\cdot, \cdot)$是每个labeled node的损失函数。</p>
<h2 id="three-schemes-self-supervision-meets-gcns">Three Schemes: Self-Supervision Meets GCNs</h2>
<p>研究三种将SSL配置到GCNs的方式。 其中 给定输入$\boldsymbol{X}_{ss}$, $\hat{\boldsymbol{A}}_{\mathrm{ss}}$, label $\boldsymbol{Y}_{ss}$和节点集$\mathcal{V}_{ss}$。</p>
<h3 id="pretraining--fintuning">Pretraining &amp; Fintuning</h3>
<p>预训练过程：
$$
\begin{aligned}
\boldsymbol{Z}_{\mathrm{ss}} &amp;=f_{\theta}\left(\boldsymbol{X}_{\mathrm{ss}}, \hat{\boldsymbol{A}}_{\mathrm{ss}}\right) \boldsymbol{\Theta}_{\mathrm{Ss}} \\
\theta_{\mathrm{ss}}^{*}, \boldsymbol{\Theta}_{\mathrm{ss}}^{*} &amp;=\arg \min_{\theta, \boldsymbol{\Theta}_{\mathrm{ss}}} \mathcal{L}_{\mathrm{ss}}\left(\theta, \boldsymbol{\Theta}_{\mathrm{ss}}\right) \\
&amp;=\arg \min_{\theta, \boldsymbol{\Theta}} \frac{1}{\left|\mathcal{V}_{\mathrm{ss}}\right|} \sum_{v_{n} \in \mathcal{V}_{\mathrm{ss}}} \underbrace{L_{\mathrm{ss}}\left(\boldsymbol{z}_{\mathrm{ss}, n}, \boldsymbol{y}_{\mathrm{ss}, n}\right)}_{\text{loss of other task}}<br>
\end{aligned} \tag{2}
$$
也就是在另一个任务训练好的模型参数$\theta_{\mathrm{ss}}^{*}, \boldsymbol{\Theta}_{\mathrm{ss}}^{*}$迁移到新任务（如半监督节点分类任务）上作为初始化参数训练新模型。</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/1.png#center" alt=""  />
</p>
<p>上表中，可以看出用graph partitioning作为预训练任务，得到的模型fine-tuning到节点分类任务上之后，效果仅从79.10变成了79.19,是非常微小的。 本文推测可能原因有两个（1）.两个不同的任务的Loss function不一样，从$\mathcal{L}_{\mathrm{ss}}$变为$\mathcal{L}_{\mathrm{sup}}$会影响实验效果。（2）参数迁移前一句是在多层GCN上的训练结果了，迁移后再训练，相当于深层，易oversmoothing。</p>
<h3 id="self-training">Self-Training</h3>
<p>每次迭代为unlabeled samples分配高度可信的为标签，然后将这些分配了伪标签的节点纳入到下一次迭代的监督训练中，随迭代过程不断更新标签。</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/2.png#center" alt=""  />
</p>
<p>表2可以看出Self-training的方式带来的提升有限</p>
<h3 id="multi-task-learning">Multi-task Learning</h3>
<p>考虑一个目标task和一个自监督task. GCN的目标为公式（1）。该多任务的训练过程如下：
$$
\begin{aligned}
\boldsymbol{Z} &amp;=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta}, \quad \boldsymbol{Z}_{\mathrm{ss}}=f_{\theta}\left(\boldsymbol{X}_{\mathrm{ss}}, \hat{\boldsymbol{A}}_{\mathrm{ss}}\right) \boldsymbol{\Theta}_{\mathrm{ss}} \\
\theta^{*}, \boldsymbol{\Theta}^{*}, \boldsymbol{\Theta}_{\mathrm{ss}}^{*} &amp;=\arg \min_{\theta, \boldsymbol{\Theta}, \boldsymbol{\Theta}_{\mathrm{ss}}} \alpha_{1} \mathcal{L}_{\mathrm{sup}}(\theta, \boldsymbol{\Theta})+\alpha_{2} \mathcal{L}_{\mathrm{ss}}\left(\theta, \boldsymbol{\Theta}_{\mathrm{ss}}\right)
\end{aligned} \tag{3}
$$
其中任务的权重参数$\alpha_{1}, \alpha_{2} \in \mathbb{R}_{&gt;0}$, 半监督目标任务的损失$\mathcal{L}_{\mathrm{sup}}$定义为公式（1）， 辅助自监督损失$\mathcal{L}_{\mathrm{ss}}$定义为公式（2）.其中特征提取器$f_{\theta}(\cdot, \cdot)$对于自监督任务和目标任务是参数共享的，而线性变换参数$\boldsymbol{\Theta}, \boldsymbol{\Theta}_{\mathrm{ss}}$是各自任务的。</p>
<p>在公式(3)中，自监督任务的loss作为一个<strong>regularization term</strong> 与目标任务一同训练。正则化项在图信号处理中是广泛应用的， 常见的有Graph Laplaician Regularization（GLR）， 它用于惩罚相邻节点间的不平滑，用于在学习目标任务的同时保持特征在图结构上的smoothing。虽然GLR可以作为一个自监督任务，但是它是给予不涉及具体数据情况下的平滑先验，SSL的regularization term不用的是，SSL是给予unlabeled data,是一种引入数据驱动的先验知识。综上所述， 多任务学习是3种自监督方式中最通用的。</p>
<h2 id="gcn-specific-self-supervised-tasks">GCN-Specific Self-Supervised Tasks</h2>
<p>本文为 GCN 扩展了一个自监督任务的“工具包”。 通过利用图中的丰富节点和边信息，可以定义各种GCN特定的自监督任务（如表 3 所示），并且进一步证明了不同的自监督任务对不同类型的监督/下游任务有益。这些自监督任务会为节点分配伪标签来构造自监督损失$\mathcal{L}_{ss}$, 如公式（3）所示。</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/4.png#center" alt=""  />
</p>
<h3 id="node-clustering">Node clustering</h3>
<p>第一个任务为节点聚类， 给定节点集$\mathcal{V}$以及feature set $\boldsymbol{X}$, 一个预设值的簇数量$K \in\{1, \ldots,|\mathcal{V}|\}$（是一个超参数）一定要小于等于节点数$|\mathcal{V}|$。 聚类算法输出一个节点集合的集合$\left\{\mathcal{V}_{\text {clu }, 1}, \ldots, \mathcal{V}_{\text {clu }, K} \mid \mathcal{V}_{\text {clu }, n} \subseteq \mathcal{V}, n=1, \ldots, K\right\}$， 其中$\mathcal{V}_{\text {clu }, i}$是一个集合表示在簇$i$中的节点集。
$$
\begin{aligned}
&amp;\mathcal{V}_{\text {clu }, n} \neq \emptyset \quad(n=1, \ldots, K), \quad \cup_{n=1}^{K} \mathcal{V}_{\text {clu }, n}=\mathcal{V} \\
&amp;\mathcal{V}_{\text {clu }, i} \cap \mathcal{V}_{\text {clu }, j}=\emptyset \quad(\forall i, j=1, \ldots, K \text { and } i \neq j)
\end{aligned}
$$
这$K$个簇互相之间没有公共的节点，SSL任务将每个节点所在的簇的index作为伪标签来构造自监督损失$\mathcal{L}_{ss}$：
$$
y_{\mathrm{ss}, n}=k \text { if } v_{n} \in \mathcal{V}_{\mathrm{clu}, k}(\forall n=1, \ldots,|\mathcal{V}|, \forall k=1, \ldots, K)
$$</p>
<h3 id="graph-partitioning">Graph partitioning</h3>
<p>上面的节点聚类任务，是基于特征的，与拓扑无关。 而这里的图划分任务，与feature无关，只与拓扑有关。 具体来说，通过“强”边连接的两个节点很可能属于同一标签类别。 因此，本文提出了一种使用图划分的基于拓扑的自监督任务。</p>
<p>图划分是将图的节点划分为大致相等的子集，使得跨子集间的边数最小化（高聚类，低耦合，同时簇中节点数不能差别太大）。先预定义一个簇数量，$K \in\{1, \ldots,|\mathcal{V}|\}$（超参数）。 和节点聚类任务类似，图划分算法也会输出一个节点集合的集合，用来标识每个节点属于哪个partition: $\left\{\mathcal{V}_{\text {par }, 1}, \ldots, \mathcal{V}_{\text {par }, K} \mid \mathcal{V}_{\text {par }, n} \subseteq \mathcal{V}, n=1, \ldots, K\right\}$, 使得：
$$
\begin{aligned}
&amp;\mathcal{V}_{\text {par }, n} \neq \emptyset \quad(\forall n=1, \ldots, K), \quad \cup_{n=1}^{K} \mathcal{V}_{\text {par }, n}=\mathcal{V} \\
&amp;\mathcal{V}_{\text {par }, i} \cap \mathcal{V}_{\text {par }, j}=\emptyset \quad(\forall i, j=1, \ldots, K \text { and } i \neq j)
\end{aligned}
$$
上面的约束其实和node clustering任务差不多，Graph partitioning任务还需要两个约束，一个是平衡约束来保证簇不要太大：
$$
K \frac{\max_{k}\left|\mathcal{V}_{\text {par }, k}\right|}{|\mathcal{V}|} \leqslant 1+\epsilon, \text { where } \epsilon \in(0,1)
$$
其中$\max_{k}\left|\mathcal{V}_{\text {par }, k}\right|$是节点数最多的簇中的节点数。 另一个约束要保证簇间边要尽可能少，即最小化edgecut:
$$
\text { edgecut }=\frac{1}{2} \sum_{k=1}^{K} \sum_{v_{i} \in \mathcal{V}_{\text {par }, k}} \quad\sum_{\left(v_{i}, v_{j}\right) \in \mathcal{E} ,\text {and } v_{j} \notin \mathcal{V}_{\text {par }, k}} \quad a_{i j}
$$
将每个节点所在的partition index作为label。</p>
<h3 id="graph-completion">Graph completion</h3>
<p>图补全任务如下图所示。</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/5.png#center" alt=""  />
</p>
<p>图补全首先通过删除目标节点的特征来mask目标节点。 然后，通过向 GCN 提供未掩蔽的节点特征（目前仅限于 2 层 GCN 的每个目标节点的二阶邻居）来恢复/预测被mask的节点特征。设计该自监督任务的原因如下：1）标签可以自由获取，也就是节点特征本身； 2）图补全可以帮助网络获得更好的特征表示，这可以教会网络从上下文中提取特征。</p>
<p>最终多任务自监督GCN模型的框架如下图所示：</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/3.png#center" alt=""  />
</p>
<h2 id="self-supervision-in-graph-adversarial-defense">Self-Supervision in Graph Adversarial Defense</h2>
<p>本文专注于Evasion Attack，在模型训练好后对目标节点$v_n$扰动， 实际上对于Evasion Attack，对扰动图重新训练或许可以纠正扰动的影响，但是本文这里不考虑重新训练。一个attacker $g$生成新的特征和邻接矩阵：
$$
\boldsymbol{X}^{\prime}, \boldsymbol{A}^{\prime}=g\left(\boldsymbol{X}, \boldsymbol{A}, \boldsymbol{Y}, v_{n}, \theta^{*}, \boldsymbol{\Theta}^{*}\right)
$$
其中$ \theta^{*}, \boldsymbol{\Theta}^{*}$是在clean 图上训练好的模型参数。</p>
<p>对抗训练的目标函数定义为:
$$
\begin{aligned}
\boldsymbol{Z} &amp;=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta}, \quad \boldsymbol{Z}^{\prime}=f_{\theta}\left(\boldsymbol{X}^{\prime}, \boldsymbol{A}^{\prime}\right) \boldsymbol{\Theta} \\
\theta^{*}, \boldsymbol{\Theta}^{*} &amp;=\arg \min_{\theta, \boldsymbol{\Theta}}\left(\mathcal{L}_{\text {sup }}(\theta, \boldsymbol{\Theta})+\alpha_{3} \mathcal{L}_{\mathrm{adv}}(\theta, \boldsymbol{\Theta})\right)
\end{aligned}
$$
表示模型要同时在扰动图和训练图上都保持较好的效果。 本文将基于自监督的对抗训练定义为：
$$
\begin{aligned}
\boldsymbol{Z} &amp;=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta}, \quad \boldsymbol{Z}^{\prime}=f_{\theta}\left(\boldsymbol{X}^{\prime}, \boldsymbol{A}^{\prime}\right) \boldsymbol{\Theta} \\
\boldsymbol{Z}_{\mathrm{ss}}=&amp; f_{\theta}\left(\boldsymbol{X}_ \mathrm{ss}, \boldsymbol{A}_{\mathrm{ss}}\right) \\
\theta^{*}, \boldsymbol{\Theta}^{*}, \boldsymbol{\Theta}_{\mathrm{ss}}^{*}=&amp; \arg \min_{\theta, \boldsymbol{\Theta}, \boldsymbol{\Theta}_{\mathrm{ss}}}\left(\alpha_{1} \mathcal{L}_{\mathrm{sup}}(\theta, \boldsymbol{\Theta})\right.\\
&amp;\left.+\alpha_{2} \mathcal{L}_{\mathrm{ss}}\left(\theta, \boldsymbol{\Theta}_{\mathrm{ss}}\right)+\alpha_{3} \mathcal{L}_{\mathrm{adv}}(\theta, \boldsymbol{\Theta})\right)
\end{aligned}
$$
其中自监督损失被引入到以扰动图数据作为输入的训练中（自监督标签矩阵 $\boldsymbol{Y}_{ss}$ 也是从扰动输入生成的）。</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
