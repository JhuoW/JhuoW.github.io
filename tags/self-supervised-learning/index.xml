<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Self-Supervised Learning on JhuoW‘s Notes</title>
    <link>https://JhuoW.github.io/tags/self-supervised-learning/</link>
    <description>Recent content in Self-Supervised Learning on JhuoW‘s Notes</description>
    <image>
      <url>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 15 Jul 2023 15:43:09 +0800</lastBuildDate><atom:link href="https://JhuoW.github.io/tags/self-supervised-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ICLR2023《MLPInit：Embarrassingly Simple GNN Training Acceleration with MLP Initialization》 Reading Nodes</title>
      <link>https://JhuoW.github.io/posts/mlpinit/</link>
      <pubDate>Sat, 15 Jul 2023 15:43:09 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/mlpinit/</guid>
      <description>ICLR2023 &amp;#34;MLPInit：Embarrassingly Simple GNN Training Acceleration with MLP Initialization&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2210.00102">paper</a></p>
<p>GNN中的层次叠加需要稀疏矩阵乘法计算带来较大的计算开销，而MLP仅使用node feature可以避免此问题。本文发现大多数message-passing通过将训练参数设置为相同shape，可以推导出等效的MLP（PeerMLP），而使用PeerMLP来作为GNN的初始化参数可以相较于仅使用PeerMLP，效果提升极大。</p>
<p><img loading="lazy" src="/posts/2023-07-16-MLPInit/1.png" alt=""  />
</p>
<p>从上图的蓝线可以看出，GNN通常需要更多的训练迭代次数才可以达到收敛，因为其中涉及复杂的稀疏矩阵乘法计算。而MLP不使用结构信息，训练速度更快，因此本文发现MLP和GNN可以有相同的训练权重空间，因此 <strong>Can we train GNNs more efficiently by leveraging the weights ofconverged MLPs?</strong>  本文进一步发现，对于一个GNN和它对应的PeerMLP （相同的weight），在PeerMLP上训练的权重可以优化GNN。基于该发现，图上训练好的PeerMLP作为GNN的权重矩阵$W$, 然后再考虑结构信息，可以发现GNN的效果相较于PeerMLP有很大的提升。 如表2所示，其中PeerMLP和GNN有相同的权重空间，首先在图上训练PeerMLP，得到收敛时的最有参数$w^\star_{mlp}$，PeerMLP的预测结果为$f_{m l p}\left(\mathbf{X} ; w_{m l p}^\star\right)$， 然后直接使用不训练而直接使用$w_{m l p}^\star$作为GNN的参数，即$f_{g n n}\left(\mathbf{X}, \mathbf{A} ; w_{m l p}^\star\right)$,可以看出，在考虑图结构后，GNN即使不训练，直接使用PeerMLP的权重矩阵，效果也有巨大提升。</p>
<p><img loading="lazy" src="/posts/2023-07-16-MLPInit/2.png" alt=""  />
</p>
<p>受此启发，本文提出了用收敛的PeerMLP最优权重矩阵，作为GNN的初始化权重。从图1的红线可以看出，相较于随机初始化的GNN，MLPInit初始化的GNN在更少的epoch到达收敛 并且可以达到和相似的准确率。</p>
<p><img loading="lazy" src="/posts/2023-07-16-MLPInit/3.png" alt=""  />
</p>
<p>从上表可以看出GNN的Propagation操作$AZ$的前向计算和反向梯度传播的耗时都远远超过Feature Transformation操作$WX$。Feature Tran的操作相对与Propagation，计算成本几乎可以忽略不计，所以如果预训练操作得到的$W$可以使得训练GNN时的epoch大幅下降，可以使模型更加高效。如下表所示，训练PeerMLP的时间再加上的权重迁移到GNN后的fine-tuning时间， 远少于在GNN上直接训练随机初始化参数的时间。</p>
<p><img loading="lazy" src="/posts/2023-07-16-MLPInit/5.png" alt=""  />
</p>
<p>从下图同样可以看出PeerMLP的参数$w_{mlp}$的训练趋势，PeerMLP训练过程中每个epoch的$w_{mlp}$直接迁移到GNN上计算CE损失，可以发现使得MLP 的CE Loss下降的$w_{mlp}$同样可以使得GNN以同样的趋势下降。</p>
<p><img loading="lazy" src="/posts/2023-07-16-MLPInit/4.png" alt=""  />
</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ICML2022 《ProGCL：Rethinking Hard Negative Mining in Graph Contrastive Learning》 Reading Note</title>
      <link>https://JhuoW.github.io/posts/progcl/</link>
      <pubDate>Sun, 08 Jan 2023 22:28:43 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/progcl/</guid>
      <description>ICML2022 &amp;#34;ProGCL：Rethinking Hard Negative Mining in Graph Contrastive Learning&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2110.02027">paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>Contrastive Learning 受益于区分hard negatives (最相似的negative pairs)， 但是其他领域的hard negative mining方法不适用于graph。 对于GCL来说大量embedding之后的hard negatives实际上是false negatives。如左图所示，对于CV上的SimCLR，它所学到的高相似度的negatives中，True negatives 和False negatives数量相当，那么从高相似度的negatives中采样到true negatives的概率更大。然而对于GCL方法GCA来说，是每个anchor节点将其他所有（inter/intra）节点作为negatives，使得在训练过程中与它同类的节点也变成anchor的negatives，这些negatives是false negatives。对于GCA，高相似度的negatives中false negatives的数量远多于true negatives，所以直接采样高相似度的negatives作为hard negatives来针对性的判别他们，会导致同类节点的embedding相互远离。这是传统的hard negatives mining方法在graph domain失效的原因。</p>
<p><img loading="lazy" src="/posts/2023-01-15-ProGCL/1.png#center" alt="你想输入的替代文字"  />
</p>
<p>为了解决这个问题， 本文提出利用Beta mixture model来估计对于一个anchor node，它的一个negatve是true negative的概率，结合相似度，来衡量该negative的hardness。即与anchor node相似度越高，且它是true negative的概率越大，那么该节点的hardness越高。</p>
<h1 id="methodology">Methodology</h1>
<h2 id="gcl">GCL</h2>
<p><img loading="lazy" src="/posts/2023-01-15-ProGCL/gcl.png#center" alt="你想输入的替代文字"  />
</p>
<p>如上图所示，InfoNCE将跨图same node视为positives，其他节点对视为negatives，GCL的目标函数如下：
$$
\begin{aligned}
\ell\left(\boldsymbol{u}_{i},\boldsymbol{v}_{i}\right)=
\log \frac{e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{i}\right) / \tau}}{\underbrace{e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{i}\right) / \tau}}_{\text{positive pair }}+\underbrace{\sum_{k\neq i}e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{k}\right) / \tau}}_{\text{inter-view negative pairs}}+\underbrace{\sum_{k\neq i}e^{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{u}_{k}\right) / \tau}}_{\text{intra-view negative pairs}}},
\end{aligned}
$$
Overall objective定义在所有跨图same node pairs上：
$$
\mathcal{J}=-\frac{1}{2 N} \sum_{i=1}^N\left[\ell\left(\boldsymbol{u}_{\boldsymbol{i}}, \boldsymbol{v}_{\boldsymbol{i}}\right)+\ell\left(\boldsymbol{v}_{\boldsymbol{i}}, \boldsymbol{u}_{\boldsymbol{i}}\right)\right]
$$
如果将GCA中的2层shared GNN替换为MLP，那么contrastive learning将不存在Message Passing，这样得到的true/false negative分布如(b)所示，可以看出Message Passing是GCL和CL之间产生区别关键因素。直观上，MP将anchor与相邻的negatives拉近，而相邻的negatives大多为False negatives（Homophily），所以GCL得到的高相似度negatives中false negatives要远多于True negatives。</p>
<p><img loading="lazy" src="/posts/2023-01-15-ProGCL/exp.png#center" alt="你想输入的替代文字"  />
</p>
<p><strong>Theorem 3.1</strong>: $\mathcal{G}$ is a non-bipartile and connected graph with $N$ nodes $\mathcal{V}=\left\{v_1, \ldots, v_N\right\}$ and $\boldsymbol{X}_i^{(\tau)}$ is the embedding of node $v_i$ after $\tau$ tims message passing. For large enough $\tau$,
$$
\left|\left|\boldsymbol{X}_i^{(\tau)}-\boldsymbol{X}_j^{(\tau)}\right|\right|_2 \leq\left|\left|\boldsymbol{X}_i^{(0)}-\boldsymbol{X}_j^{(0)}\right|\right|_2
$$
该定理说明了Message passing之后，不同节点间的距离会变小。</p>
<h2 id="progcl">ProGCL</h2>
<p><img loading="lazy" src="/posts/2023-01-15-ProGCL/exp2.png#center" alt="你想输入的替代文字"  />
</p>
<p>Figure 4描述了negatives相似度的直方图分布，即每个相似度下true/false negatives的相对数量。例如Figure 4（a），对于true negatives，高相似度的true negatives较少，中等相似度的true negatives较多；对于False negatives，大多相似度较高。所以直接采样高相似度的negatives作为hard negatives很容易采样到false negatives。那么随机采样一个相似度$s$的概率有该相似度在true negatives中的采样概率和在false negatives采样概率共同决定。因此相似度分布可以建模为mixture model。本文用Beta distribution来建模true/false negatives的相似度分布。beta distribution的pdf为：
$$
p(s \mid \alpha, \beta)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \Gamma(\beta)} s^{\alpha-1}(1-s)^{\beta-1},
$$
其中$\alpha, \beta &gt;0$ 是beta distribution的参数，$\Gamma(\cdot)$ 是gamma function。对于$C$个beta distribution的mixture model，相似度$s$在该mixture model中的概率为$s$在true negatives 相似度分布中的概率和false negatives相似度分布中的概率的加权：
$$
p(s)=\sum_{c=1}^{C} \lambda_{c} p(s \mid \alpha_c, \beta_c),
$$
其中$\lambda_c$是mixture coefficients。下面要做的就是通过EM算法来优化两beta mixture model的参数，包括两个beta distribution的$\alpha, \beta$参数以及mixture coefficient，<strong>使得GCL学习得到的negatives similarities从改mixture model中采样的概率最大</strong>，即优化mixture model这个混合概率分布，使其符合所有negatives similarity分布。例如总共有10000个negatives（true+false），这一万个similarity分布要符合分布$p(s)$。用EM算法来优化mixture model $p(s)$时，E-step要计算后验：
$$
p(c\mid s)=\frac{\lambda_{c} p\left(s \mid \alpha_{c}, \beta_{c}\right)}{\sum_{j=1}^{C} \lambda_{j} p\left(s \mid \alpha_{j}, \beta_{j}\right)}.
$$
其中$c$为latent variable。然而优化Beta Mixture Model使其你和所有negatives的similarity分布是计算量巨大的，为了解决这个问题每次迭代只采样$M$ ($M \ll N^2$)个相似度来的分布来优化BMM，使其你和这$M$个相似度的分布。首先计算$M$个相似度在每个beta distribution上的weighted average  $\bar{s}_c$以及variance $v_c^2$：
$$
\bar{s}_c=\frac{\sum_{i=1}^M p\left(c \mid s_i\right) s_i}{\sum_{i=1}^M p\left(c \mid s_i\right)}, \quad v_c^2=\frac{\sum_{i=1}^M p\left(c \mid s_i\right)\left(s_i-\bar{s}_c\right)^2}{\sum_{i=1}^M p\left(c \mid s_i\right)} .
$$
在M-step，如下优化BMM的参数 $\alpha_c, \beta_c, \lambda_c$使得BMM符合$M$个similarity的分布：
$$
\alpha_c=\bar{s}_c\left(\frac{\bar{s}_c\left(1-\bar{s}_c\right)}{v_c^2}-1\right), \quad \beta_c=\frac{\alpha_c\left(1-\bar{s}_c\right)}{\bar{s}_c}，\quad \lambda_c=\frac{1}{M} \sum_{i=1}^M p\left(c \mid s_i\right)
$$
这样通过E-step计算后验和average, variance，M-step基于average,variance和后验更新BMM的参数，循环迭代$I=10$次后，可以得到拟合输入negatives similarity的BMM分布的参数。最终，得到关于相似度$s$的BMM$p(s)$后，构成$p(s)$的两个分布即给定negative similarity $s$，该negative是true negative/false negative的概率为：
$$
p(c \mid s)=\frac{\lambda_c p\left(s \mid \alpha_c, \beta_c\right)}{p(s)}
$$</p>
<h2 id="progcl-weight">ProGCL-weight</h2>
<p>对于一对negative pair，$\boldsymbol{u}_i$为anchor和他的inter-view $\boldsymbol{v}_k$，他们的相似度$s_{ik}$在true negative分布中的概率为$p(c_t|s_{ik})$，概率越大越可能是true negative，同时$s_{ik}$越大越hardness。所以在Contrastive loss中，越hard的true negative要被赋予越大的权重，使得被判别区分。negative pair权重为：
$$
w(i, k)=\frac{p\left(c_t \mid s_{i k}\right) s_{i k}}{\frac{1}{N-1} \sum_{j \neq i}\left[p\left(c_t \mid s_{i j}\right) s_{i j}\right]}
$$
在Contrastive objective中对negatives加权：
$$
\ell_w\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{i}\right)=
\log \frac{e^{\frac{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{i}\right)}{ \tau}}}{\underbrace{e^{\frac{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{i}\right)}{\tau}}}_{\text{positive pair }}+\underbrace{\sum_{k\neq i}w(i,k)e^{\frac{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{v}_{k}\right)}{\tau}}}_{\text{inter-view negative pairs}}+\underbrace{\sum_{k\neq i}w(i,k)e^{\frac{\theta\left(\boldsymbol{u}_{i}, \boldsymbol{u}_{k}\right)} {\tau}}}_{\text{intra-view negative pairs}}},
$$</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>WWW2022 《ClusterSCL：Cluster-Aware Supervised Contrastive Learning on Graphs》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/clusterscl/</link>
      <pubDate>Thu, 17 Nov 2022 01:33:20 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/clusterscl/</guid>
      <description>WWW2022 &amp;#34;ClusterSCL：Cluster-Aware Supervised Contrastive Learning on Graphs&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://xiaojingzi.github.io/publications/WWW22-Wang-et-al-ClusterSCL.pdf">paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>对于<strong>监督对比学习</strong>（Supervised Contrastive Learning, SupCon）, SupCon loss旨在表示空间中拉近属于同一个class的数据点，分离不同类的数据点。 但是SupCon难以处理高类内方差，类间相似度较大的数据集。为了解决该问题，本文提出了Cluster-aware supervised contrastive learning loss (ClusterSCL)。什么是高类内方差，高跨类相似度问题？如图1(a)所示，节点$u_1$和$u_3$ 是同类节点，$u_2$和$u_4$是同类节点。他们是同类节点但在不同的社区中，所以类内方差较大，即同一个类内的节点跨越了多个community。 另外$u_1$和$u_2$， $u_3$和$u_4$，是不同类的节点对， 但他们处在同一个社区中，导致在MPNN过程中，这些处在同一个community中的不同类节点被拉近，导致跨类相似度较高的问题。</p>
<p>如果对节点$u_2$计算SupCon时，如图1(b)所示，SupCon会使得同类节点被拉近，如$u_2$和$u_4$会被拉近。但是$u_3$和$u_4$处在同一个社区中（structurally similar）那么MPNN会使得$u_3$和$u_4$被拉近，所以SupCon在拉近$u_2$和$u_4$的同时，会间接拉近不同类节点$u_2$和$u_3$。同时，对于构成negative pairs的不同类节点，例如$u_1$和$u_2$，SupCon会推远$u_1$和$u_2$，但是$u_1$和$u_5$ structurally similar, 因此会推远$u_1$和$u_2$会间接导致$u_2$和$u_5$这两个同类节点被推远。因此对于一个cluster内节点不同类，且不同cluster中存在同类节点的情况，会导致复杂的决策边界，即<strong>在拉近同类但不同社区的节点时，也会间接拉近不同类不同社区的节点</strong>。<strong>在推远不同类同社区的节点时，也可能间接推远同类同社区的节点</strong>。</p>
<p><img loading="lazy" src="/posts/2022-11-15-ClusterSCL/1.png#center" alt=""  />
</p>
<p>为了解决上述问题，最直接的方法是对于每个cluster，如图1(a)的Community 1，不考虑其他cluster，只对当前cluster内节点做SupCon。但是这么做忽略了跨cluster的同类节点交互，如$u_1$和$u_3$，$u_2$和$u_4$，这些跨cluster的positive pairs可能包含有益的信息。为了解决这个问题，本文提出<strong>cluster-aware data augmentation (CDA)</strong> 聚类感知的数据增强，来为每个节点生成augmented positives and negatives，如图1(b)中ClusterSCL所示。对于每个节点$u$，为它生成positive 和negative samples, 生成的samples 位于或接近$u$所在的cluster。Recall SupCon存在的问题：</p>
<ul>
<li>SupCon会使得$u_2$和$u_4$被拉的太近，从而间接导致$u_2$和$u_3$被拉近，所以对于high intra-class variances，要求不同cluster的同类节点如$u_2$和$u_4$不要被拉太近；</li>
<li>SupCon会使得$u_1$和$u_2$被推远，从而间接导致$u_2$和$u_5$被推远，所以对于high inter-class similarity，要求同一个cluster内的不同类节点如$u_1$和$u_2$不要被拉的太远。</li>
</ul>
<h1 id="method">Method</h1>
<h2 id="two-stage-training-with-supervised-contrastive-loss">Two stage training with Supervised Contrastive Loss</h2>
<p><strong>SupCon encourages samples of the same class to have similar representations, while pushes apart samples of different classes in the embedding space.</strong></p>
<p>First Stage: 计算node embeddings $H = g_\theta(G)$， 然后用SupCon Loss来训练 $g_\theta$ 。即已经知道训练集中的节点label，基于这些节点label，SupCon在embedding space中把同label的节点拉近，不同label的节点分开。$g_\theta$用于得到node embeddings.</p>
<p>Second Stage：基于学习好的$g_\theta$， 用$\hat{Y}=f_\phi\left(g_\theta(G)\right)$来得到logits/prediction。即用cross-entropy loss来训练$f_\theta$。</p>
<h2 id="supcon">SupCon</h2>
<p>从同一个类中采样的节点构成positive pairs。batch中随机采样的节点对为negative pairs。给定$N$个随机采样的节点，对于每个节点，从其对应的class中随机采样一个不为它的节点作为positive pairs。所以一个batch有$N$对positive pairs，共$2N$个节点。</p>
<p>用$I \equiv\{1,2, \ldots, 2 N\}$ 表示一个batch中的node indices。$s_i \in I$表示这$2N$个节点中与节点$v_i$属于同一类的节点的indices。如下式所示， 在一个batch中，令$S_i \subset I$表示$2N$个节点中可以与节点$v_i$构成positive pairs的节点集合。相比其他节点，SupCon的objective是拉近positive pairs。
$$
\max \sum_{i \in I} \frac{1}{\left|S_i\right|} \sum_{s_i \in S_i} \log \frac{\exp \left(\mathbf{h}_i^{\top} \mathbf{h}_{s_i} / \tau\right)}{\sum_{j \in I \backslash\{i\}} \exp \left(\mathbf{h}_i^{\top} \mathbf{h}_j / \tau\right)}
$$
但是如果batch中与$v_i$同类的节点$v_j$和它不属于同一个cluster，$v_j$所属的cluster不同类的节点较多，那么拉近他们的距离也会间接拉近$v_i$与不同类节点间的距离。</p>
<h2 id="clusterscl">ClusterSCL</h2>
<p>为了解决上述问题，本文提出ClusterSCL。</p>
<h3 id="cluster-aware-data-augmentation-cda">Cluster-aware Data Augmentation (CDA)</h3>
<p>定义隐变量 $c_i$，该隐变量取值范围为$c_i \in \{1,2, \ldots, M\}$ 表示节点$v_i$属于哪一个cluster。给定两个anchor node $v_i$,$v_j$，CDA使用线性插值法为$v_j$生成augmentation：
$$
\tilde{\mathbf{h}}_j=\alpha \mathbf{h}_j+(1-\alpha) \mathbf{w}_{c_i}     \tag{4}
$$
其中$c_i$指示了节点$v_i$所在的cluster。$\mathbf{w}=\left\{\mathbf{w}_m\right\}_{m=1}^M$ 表示每个cluster的cluster prototypes，即每个cluster的中心，serve to characterize the cluster。$\mathbf{w}_{c_i}$表示节点$v_i$所在<strong>cluster</strong>的中心表示。$\tilde{\mathbf{h}}_j$包含了节点$v_j$的信息。并且，由于$\mathbf{w}_{c_i}$是$v_i$所在cluster的prtotype，所以通过调整$\alpha$，可以使$\tilde{\mathbf{h}}_j$位于$v_i$所在cluster的附近或内部。</p>
<p>（1）如果$(v_i, v_j)$是一个batch中的positive pair，$v_i$是anchor节点，如果$v_j$位于$v_i$所在的cluster $c_i$内，那么就需要学到的$\mathbf{h}_j$与$\mathbf{h}_i$尽可能靠近。在SupCon中，需要设置较大的$\alpha$使得$\tilde{\mathbf{h}}_j$保留更多$\mathbf{h}_j$ 。对于anchor节点$\mathbf{h}_i$，将它与$\tilde{\mathbf{h}}_j$拉近的时候，由于$\tilde{\mathbf{h}}_j$保留了更多$v_j$特征，所以$\mathbf{h}_j$也会被和$\mathbf{h}_i$拉近。如图2(a)所示。</p>
<p>（2）如果$(v_i, v_j)$是positive pair，如果$v_j$位于$v_i$所在的cluster $c_i$外时，如果$v_j$周围有negative samples （不一定在该batch中），那么直接拉近$(v_i, v_j)$会间接导致潜在的negative samples也会被拉近，因此对于位于$v_i$所在cluster外的节点$v_j$，要求它最终的表示$\mathbf{h}_j$不能被拉的太近，此时就需要小一些的$\alpha$，使得$\tilde{\mathbf{h}}_j$保留少一些$v_j$的信息，那么在SupCon拉近$\mathbf{h}_i$和$\tilde{\mathbf{h}}_j$的过程不会导致$\mathbf{h}_j$被拉近太多。因为$ \mathbf{w}_{c_i}$占据了$\tilde{\mathbf{h}}_j$的大部分，且它与$\mathbf{h}_i$已经很接近。如图2(b)所示。</p>
<p><img loading="lazy" src="/posts/2022-11-15-ClusterSCL/2.png#center" alt=""  />
</p>
<p>对于negative pair $(v_i, v_j)$。如果$v_j$位于$v_i$所在的cluster $c_i$内，如果直接推远$\mathbf{h}_i$和$\mathbf{h}_j$，会导致如果$v_j$的邻居有$v_i$的positive sample，那么这个positive sample也会被间接推远。所以$\tilde{\mathbf{h}}_j$应该保留较少的$\mathbf{h}_j$，即$\alpha$应该小。但是本文不考虑negative pairs的这种情况了，直接套用posiive的CDA原则。</p>
<p>综合上面的（1）（2）即对于close positive pairs，要让他们尽可能接近，即$\alpha$要大，对于distant positive pairs，要让他们不要太接近，$\alpha$要小一些。所以$\alpha$应与positive pair之间的相似度相关。所以$\alpha$定义如下：
$$
\alpha=\frac{\exp \left(\mathbf{h}_i^{\top} \mathbf{h}_j\right)}{\exp \left(\mathbf{h}_i^{\top} \mathbf{h}_j\right)+\exp \left(\mathbf{h}_i^{\top} \mathbf{w}_{c_i}\right)}
$$
上式分子越大$\alpha$越大，说明对于anchor node $v_i$， 如果的positive sample $v_j$位于它的cluster内（$v_i$与$v_j$相似）,$\mathbf{h}_j$的augmentation $\tilde{\mathbf{h}}_j$要保留越多自身信息。</p>
<h3 id="integraging-clustering-and-cda-into-supcon-learning">Integraging Clustering and CDA into SupCon Learning</h3>
<p>目标是给定节点$v_i$以及它所在的cluster 隐变量$c_i$，$v_i$的positive samples $s_i$的cluster-aware SupCon定义为条件概率：
$$
\begin{aligned}
p\left(s_i \mid v_i, c_i\right) &amp;=\frac{\exp \left(\mathbf{h}_i^{\top} \tilde{\mathbf{h}}_{s_i} / \tau\right)}{\sum_{j \in V \backslash\{i\}} \exp \left(\mathbf{h}_i^{\top} \tilde{\mathbf{h}}_j / \tau\right)} \\
&amp;=\frac{\exp \left(\mathbf{h}_i^{\top}\left(\alpha \mathbf{h}_{s_i}+(1-\alpha) \mathbf{w}_{c_i}\right) / \tau\right)}{\sum_{j \in V \backslash\{i\}} \exp \left(\mathbf{h}_i^{\top}\left(\alpha \mathbf{h}_j+(1-\alpha) \mathbf{w}_{c_i}\right) / \tau\right)}
\end{aligned} \tag{6}
$$
即对于positive pair $(v_i, s_i)$，最大化$\mathbf{h}_i$和$s_i$的augmentation $\tilde{\mathbf{h}}_{s_i}$之间的一致性，$\alpha$可以依据$s_i$和$c_i$的关系来调整$\mathbf{h}_{s_i}$对于SupCon的贡献，使得$\mathbf{h}_{i}$与$\mathbf{h}_{s_i}$在位于不同cluster的情况下不会被拉的太近。其中$c_i$是隐变量。</p>
<p>首先定义关于节点$v_i$的cluster分布，即$v_i$属于每个$c_i$的概率。给定anchor node $v_i$，它属于cluster $c_i \in \{1,2, \ldots, M\}$的概率定义为：
$$
p\left(c_i \mid v_i\right)=\frac{\exp \left(\mathbf{h}_i^{\top} \mathbf{w}_{c_i} / \kappa\right)}{\sum_{m=1}^M \exp \left(\mathbf{h}_i^{\top} \mathbf{w}_m / \kappa\right)} \tag{7}
$$
$\mathbf{w}_{c_i}$是cluster $c_i$的prototype表示，$v_i$属于在embedding空间中与它相似的cluster的概率更高。ClusterSCL旨在最大化给定锚节点$v_i$，锚节点与其positive sample $s_i$的likelihood：
$$
p\left(s_i \mid v_i\right)=\int_{c_i} p\left(c_i \mid v_i\right) p\left(s_i \mid v_i, c_i\right) d c_i= \sum^M_{m=1} p(m|v_i)p(s_i|v_i,m)    \tag{8}
$$
即给定anchor $v_i$，$s_i$是$v_i$的postive sample的概率为 当$v_i$属于cluster $m$的情况下，$s_i$是其positive sample的概率， over all clusters $m \in M$。</p>
<p>在likelihood Eq.(8)中，anchor node $v_i$ 为待优化参数，它的positive sample $s_i$为观测数据，$c_i$为隐变量。</p>
<h3 id="maximize-likelihood-eq8-via-em">Maximize likelihood Eq.(8) via EM</h3>
<p>Objective: $\mathrm{maximize} \log p(s_i| v_i)$，即最大化positive pairs的条件概率 given anchor node $v_i$。</p>
<p>E-step：$\mathbb{E}_{p(c_i|s_i, v_i)} \log p(s_i, c_i|v_i)$</p>
<p>M-step: $\widehat{v}_i = \arg \max_{v_i} \mathbb{E}_{p(c_i|s_i, v_i)} \log p(s_i, c_i|v_i)$</p>
<p>可见，如果要通过EM算法来优化得到anchor node $v_i$的表示，需要计算后验 $p(c_i|s_i, v_i)$：
$$
\begin{aligned}
p(c_i|s_i, v_i) &amp; = \frac{p(c_i,v_i, s_i)}{p(s_i,v_i)} \\
&amp; = \frac{p(v_i)p(s_i,c_i | v_i)}{p(s_i |v_i) p(v_i)}\\
&amp; = \frac{p(s_i,c_i|v_i)}{p(s_i |v_i)} \\
&amp; = \frac{p(s_i,c_i|v_i)}{\sum^M_{m=1}p(m|v_i)p(s_i | v_i, m)}\\
&amp; = \frac{\frac{p(s_i,c_i,v_i)}{p(v_i)} = \frac{p(c_i,v_i)}{p(v_i)} \frac{p(s_i,c_i,v_i)}{p(c_i,v_i)} = p(c_i | v_i)p(s_i|c_i,v_i)}{\sum^M_{m=1}p(m|v_i)p(s_i | v_i, m)} \\
&amp; = \frac{p(c_i | v_i)p(s_i|c_i,v_i)}{\sum^M_{m=1}p(m|v_i)p(s_i | v_i, m)}<br>
\end{aligned}\tag{9}
$$
后验中，$p(c_i | v_i)$，$p(m|v_i)$是$v_i$的cluster 分布，在Eq.(7)中给出定义。但是，对于$p(s_i|c_i,v_i)$和$p(s_i | v_i, m)$，Eq.(6)中给出了它的定义，$p\left(s_i \mid v_i, c_i\right) =\frac{\exp \left(\mathbf{h}_i^{\top} \tilde{\mathbf{h}}_{s_i} / \tau\right)}{\sum_{j \in V \backslash\{i\}} \exp \left(\mathbf{h}_i^{\top} \tilde{\mathbf{h}}_j / \tau\right)}$， 可以看出分母部分需要计算$\mathbf{h}_i$与所有节点，并且还要over all $M$ cluster，因此后验难以计算。为了解决这个问题，我们可以maximize evidence lower bound (ELBO) of  $\log p(s_i | v_i)$：
$$
\begin{aligned}
\log p(s_i | v_i) &amp;= \log \frac{p(s_i,v_i)}{p(v_i)} = \log  \frac{p(s_i,v_i)p(c_i | v_i,s_i)}{p(v_i)p(c_i | v_i,s_i)} \\
&amp;= \log \frac{p(v_i,s_i,c_i)}{p(v_i)p(c_i | v_i,s_i)} \\
&amp;= \log \frac{p(s_i|v_i,c_i)p(v_i,c_i)}{p(v_i)p(c_i | v_i,s_i)} = \log \frac{p(s_i|v_i,c_i)p(c_i|v_i)p(v_i)}{p(v_i)p(c_i | v_i,s_i)} \\
&amp; = \log \frac{p(s_i|v_i,c_i)p(c_i|v_i)}{p(c_i | v_i,s_i)} \\
&amp; = \log p(s_i|v_i,c_i)-\log p(c_i | v_i,s_i) +  \log p(c_i|v_i) \\
&amp; \text{引进一个关于隐变量$c_i$的分布$q(c_i)$，可以是任意形式，这里定义为$q(c_i|v_i,s_i)$}\\
&amp; = \log p(s_i|v_i,c_i) - \log \frac{p(c_i | v_i,s_i)}{q(c_i|v_i,s_i)} + \log \frac{p(c_i|v_i)}{q(c_i|v_i,s_i)} \\
&amp;\text{左右两边分别对$q(c_i|v_i,s_i)$求期望} \\
\text{左边} &amp;= \int q(c_i|v_i,s_i) \log p(s_i | v_i) d c_i = \int q(c_i|v_i,s_i) d c_i \cdot \log p(s_i | v_i) = \log p(s_i | v_i) \\
\text{右边} &amp;= \int q(c_i|v_i,s_i) \log  p(s_i|v_i,c_i) dc_i - \underbrace{\int q(c_i|v_i,s_i) \log \frac{p(c_i | v_i,s_i)}{q(c_i|v_i,s_i)} dc_i}_{-\mathrm{KL}(q(c_i|v_i,s_i)||p(c_i | v_i,s_i))} + \underbrace{\int q(c_i|v_i,s_i) \log \frac{p(c_i|v_i)}{q(c_i|v_i,s_i)} dc_i}_{-\mathrm{KL}(q(c_i|v_i,s_i)||p(c_i|v_i))} \\
&amp;= \int q(c_i|v_i,s_i) \log  p(s_i|v_i,c_i) dc_i + \mathrm{KL}(q(c_i|v_i,s_i)||p(c_i | v_i,s_i)) - \mathrm{KL}(q(c_i|v_i,s_i)||p(c_i|v_i)) \\
&amp; \geq \underbrace{\mathbb{E}_{q(c_i|v_i,s_i)} \log  p(s_i|v_i,c_i) - \mathrm{KL}(q(c_i|v_i,s_i)||p(c_i|v_i))}_{ELBO}
\end{aligned}  \tag{10}
$$
因此， we have：
$$
\log p(s_i | v_i) \geq ELBO = \mathbb{E}_{q(c_i|v_i,s_i)} \log  p(s_i|v_i,c_i) - \mathrm{KL}(q(c_i|v_i,s_i)||p(c_i|v_i)) \tag{10}
$$
所以目标为找到node embeddings $\mathbf{h}_i, \forall i$， 最大化ELBO。接下来可以定义任意关于隐变量$c_i$的vartational distribution $q(c_i)$。 这里将关于$c_i$的variational distribution定义为用mini-batch近似后验的形式：
$$
q\left(c_i \mid v_i, s_i\right)=\frac{p\left(c_i \mid v_i\right) \tilde{p}\left(s_i \mid v_i, c_i\right)}{\sum_{m=1}^M p\left(m \mid v_i\right) \tilde{p}\left(s_i \mid v_i, m\right)}  \tag{11}
$$
其中$\tilde{p}\left(s_i \mid v_i, c_i\right)=\exp \left(\mathbf{h}_i^{\top} \tilde{\mathbf{h}}_{s_i} / \tau\right) / \sum_{j \in I \backslash\{i\}} \exp \left(\mathbf{h}_i^{\top} \tilde{\mathbf{h}}_j / \tau\right)$，与Eq.(6)不同的是$\tilde{p}\left(s_i \mid v_i, c_i\right)$的分母只计算mini-batch $I$内的negative samples。并且用$\tilde{p}\left(s_i \mid v_i, c_i\right)$来替换了Eq.10 中的$ p(s_i|v_i,c_i)$，文中证明了这种替代的合理性。</p>
<p>在E-step，定义了variational distribution $q\left(c_i \mid v_i, s_i\right)$和likelihood objective的ELBO，在M-step最大化ELBO。给定一个mini-batch $I$，目标函数为最大化$I$中每对positive pairs 的ELBO：
$$
\max \quad \mathcal{L}_{\mathrm{ELBO}}(\theta, \mathbf{w} ; I) \approx \frac{1}{|I|} \sum_{i \in I} \frac{1}{\left|S_i\right|} \sum_{s_i \in S_i} \mathcal{L}_{\mathrm{ELBO}}\left(\theta, \mathbf{w} ; v_i, s_i\right)
$$</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>NeurIPS2021 《From Canonical Correlation Analysis to Self-supervised Graph Neural Networks》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/cca-ssg/</link>
      <pubDate>Thu, 14 Apr 2022 22:54:10 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/cca-ssg/</guid>
      <description>NeurIPS2021 &amp;#34;From Canonical Correlation Analysis to Self-supervised Graph Neural Networks&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2106.12484">paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>本文提出了一种新型的Graph Contrastive Learning构造Contrastive pairs的方式，即将跨图的同维度特征作为positive pairs， 不同维度特征作为negative pairs。 和过去的GCL方法相比，本文无需互信息估计器（MI Estimator），映射头（Projector），不对称结构（asymmetric structures）。 并且理论证明了该方法可以看做Information Bottleneck 原则在自监督设置下的实例。</p>
<p>具体来说，受典型相关分析（From Canonical Correlation Analysis）的启发，本文提出了一种简单有效的GCL框架，从而是模型避免复杂难以理解多模块设计。 和过去的方法<strong>相同</strong>的是，为输入图以随机增强的方式生成两个view， 目的是为两个view学习共享的 node representations 通过共享的GNN Encoder。<strong>不同</strong>在于，本文利用了典型相关分析（CCA），具体来说，新目标旨在最大化同一输入的两个增强views之间的相关性，同时对单个视图表示的不同（特征）维度进行去相关（避免不同维度捕获相同信息，即同一个view内的不同维度channel互为negative pairs）。 这么做的目的是 1）本质上追求的是丢弃增强后变化的信息，同时保留增强后不变的信息，以及 2）防止维度崩溃（即不同维度捕获相同的信息）。</p>
<p><img loading="lazy" src="/posts/2022-04-15-CCA-SSG/1.png#center" alt=""  />
</p>
<p>和其他方法的对比如上图所示， 本文提出的CCA-SSG无需negative pairs， 参数化的互信息估计器， projection head或者不对称结构。对比对的数量仅为$O(D^2)$, 其中$D$为输出维度。</p>
<h1 id="canonical-correlation-analysis">Canonical Correlation Analysis</h1>
<p>CCA: Identify and Quantify the associations between  two sets of variables， 即CCA用来衡量两组随机变量的相关性，每组可能有很多Random Variables.</p>
<p>从相关系数引入：</p>
<p>Pearson 相关系数： 给定两组数据集$X$， $Y$。 其中$X \in \mathbb{R}^{N \times 1}$ 表示只有一个随机变量（属性），样本数为$N$。 $Y \in  \mathbb{R}^{M \times 1}$: 一个随机变量，样本量为$M$。那么Pearson 相关系数$\rho$定义为：
$$
\rho(X,Y)=  \frac{\mathrm{Cov}(X,Y)}{\sigma_X \sigma_Y}
$$
其中$\sigma_X$，$\sigma_Y$分别为$X$和$Y$的标准差。$\mathrm{Cov}(X,Y)$为$X$, $Y$的协方差。$\rho \in [-1,1]$。 $\rho$越接近1， $X$和$Y$的线性相关性越高。$\rho$越接近0，$X$和$Y$的线性相关性月底。</p>
<p><strong>相关系数存在问题</strong>：相关系数不适用于高维数据。 如果$X$是2维的（2个属性，例如身高和体重）， $Y$也是2维的，属性为(跑步，跳远)， $X \in \mathbb{R}^{N \times 2}$, $Y \in  \mathbb{R}^{M \times 2}$。此时，相关系数$\rho$無法計算2維隨機變量的相關程度。</p>
<h2 id="cca-基本思想">CCA 基本思想</h2>
<p>$X$和$Y$ 为两个变量集合， 例如$X$中有两个随机变量（2维）， $Y$中也有两个随机变量。 要衡量变量间的相关性： 现将高维随机变量（即多个随机变量）降到一维（一个随机变量），再用相关系数计算相关性。</p>
<p>令$X = \{\boldsymbol{x}_1,\boldsymbol{x}_2\} \in \mathbb{R}^{n_1\times m}$， 表示$n_1=2$个随机变量，$m$个样本。 $Y = \{\boldsymbol{y}_1,\boldsymbol{y}_2\} \in \mathbb{R}^{n_2\times m}$表示$n_2=2$个随机变量，$m$个样本。</p>
<p>$U$为随机变量集合$X$的线性组合：
$$
U = a_1 \boldsymbol{x}_1 + a_2 \boldsymbol{x}_2 = [a_1, a_2]\begin{bmatrix} \boldsymbol{x}_1 \\ \boldsymbol{x}_2\end{bmatrix} = a^\top X
$$
$V$为随机变量集合$Y$的线性组合：
$$
V = b_1 \boldsymbol{y}_1 + b_2\boldsymbol{x}_2 = b^\top Y
$$
<strong>CCA</strong>的优化目标： 找到一组最优解$a$和$b$， 使得$\rho_{U,V}$最大：
$$
\arg \max_{a,b} \rho_{U,V} = \frac{\mathrm{Cov}(U,V)}{\sigma_U \sigma_V}
$$
得到的$a$, $b$是使得$X$与$Y$有最大关联的权重。</p>
<h2 id="cca的表示与求解">CCA的表示与求解</h2>
<p>输入：两个随机变量集合$X = \{\boldsymbol{x}_1 , \cdots, \boldsymbol{x}_n\}$, $Y= \{\boldsymbol{y}_1 , \cdots, \boldsymbol{y}_m\}$。 分别有$n$个和$m$个随机变量。</p>
<p>$X$是一个$n \times L$的矩阵， 即有$L$个样本， $n$个属性（$n$个随机变量）。</p>
<p>$Y$是一个$m \times L$的矩阵， $L$个样本， $m$个属性。</p>
<p>$U = a^\top X \in \mathbb{R}^{1 \times L}$, $V= b^\top Y \in \mathbb{R}^{1\times L}$, 分别将组高维随机变量转为一维。 目标函数为
$$
\arg \max_{a,b} \rho_{U,V} =\arg \max_{a,b}  \frac{\mathrm{Cov}(U,V)}{\sigma_U \sigma_V}
$$
设 $\Sigma_{XX} = \mathrm{Cov}(X,X) = \mathrm{Var}(X)$， $\Sigma_{YY} = \mathrm{Cov}(Y,Y) = \mathrm{Var}(Y)$， $\Sigma_{XY} = \mathrm{Cov}(X,Y)$， $E[X] = \mu_X \in \mathbb{R}^{n \times 1}$ （样本均值）， $E[Y] = \mu_Y \in \mathbb{R}^{m \times 1}$。</p>
<p>定义$X$ 为一个$n$个随机变量stack成的列向量：
$$
X= \begin{bmatrix} \boldsymbol{x}_1 \\ \cdots \\ \boldsymbol{x}_n\end{bmatrix} \in \mathbb{R}^{n \times L}
$$
$C$ 为$n$个scalars $c_1, \cdots, c_n$ stack成的列向量：
$$
C= \begin{bmatrix} \boldsymbol{c}_1 \\ \cdots \\ \boldsymbol{c}_n\end{bmatrix}
$$
$C^\top X$是这$n$个Random Variables的线性组合。 $C^\top X$的方差为：
$$
\mathrm{Var}(C^\top X) = C^\top \Sigma_{XX} C = C^\top \mathrm{Var}(X) C
$$
那么$\mathrm{Var}(U) = \mathrm{Var}(a^\top X) = a^\top \mathrm{Var}(X) a$。</p>
<p>每个随机变量$\boldsymbol{x}_i$为数据的第$i$个特征，每列为一个样本$X \in \mathbb{R}^{n \times L}$。 有$L$个样本， 对特征维度做标准化，也就是对每个维度$\boldsymbol{x}_i$做标准化， 可得$E(\boldsymbol{x}_i) = 0$, $\mathrm{Var}(\boldsymbol{x}_i) = 1$。
$$
\begin{aligned}
\mathrm{Var}(X) &amp;= E(X-E(X))^2 \\
&amp;= E(\begin{bmatrix} \boldsymbol{x}_1 \\ \cdots \\ \boldsymbol{x}_n\end{bmatrix} -\begin{bmatrix} \boldsymbol{\mu}_1 \\ \cdots \\ \boldsymbol{\mu}_n\end{bmatrix} )^2   \\
&amp;= E (\begin{bmatrix} \boldsymbol{x}_1 \\ \cdots \\ \boldsymbol{x}_n\end{bmatrix}^2) \\
&amp;= E(XX^\top)
\end{aligned}
$$
所以$\mathrm{Var}(U) = a^\top E(XX^\top) a$， 同理$\mathrm{Var}(V) = b^\top E(YY^\top) b$。另外：
$$
E(a^\top X) = E(a_1\boldsymbol{x}_1 + \cdots + a_n\boldsymbol{x}_n) = a_1E(\boldsymbol{x}_1) + \cdots + a_n E(\boldsymbol{x}_n) = 0
$$
那么：
$$
\begin{aligned}
\mathrm{Cov}(U,V) &amp;= \mathrm{Cov}(a^\top X, b^\top Y) \\
&amp;= E\left[ \langle a^\top X - E(a^\top X), b^\top Y- E(b^\top Y) \rangle  \right] \\
&amp;= E[\langle a^\top X,  b^\top Y \rangle] \\
&amp;= E[(a^\top X)(b^\top Y)^\top] \\
&amp;= E[a^\top X Y^\top b] \\
&amp;= a^\top E[XY^\top]b
\end{aligned}
$$</p>
<p>$$
\begin{aligned}
\mathrm{Var}(X) &amp;= \mathrm{Cov}(X,X) = E[XX^\top] \\
\mathrm{Var}(Y) &amp;= \mathrm{Cov}(Y,Y) = E[YY^\top] \\
\mathrm{Cov}(X,Y) &amp;= E[\langle X-\mu_X, Y-\mu_Y \rangle] = E[XY^\top] = \Sigma_{XY}\\
\mathrm{Cov}(Y,X) &amp;=E[YX^\top]
\end{aligned}
$$</p>
<p>优化目标转化为：
$$
\begin{aligned}
\arg \max_{a,b} \rho_{U,V} &amp;=\arg \max_{a,b}  \frac{\mathrm{Cov}(U,V)}{\sigma_U \sigma_V}  \\
&amp;=\arg \max_{a,b} \frac{a^\top \Sigma_{XY}b}{\sqrt{a^\top \Sigma_{XX} a} \sqrt{b^\top \Sigma_{YY}b}}
\end{aligned}
$$
若对$a$， $b$同时放缩， 即$a$放缩$k$倍， $b$放缩$l$倍， 公式的值不会改变：
$$
\frac{ka^\top \Sigma_{XY}lb}{\sqrt{ka^\top \Sigma_{XX} ka} \sqrt{lb^\top \Sigma_{YY}lb}} =  \frac{a^\top \Sigma_{XY}b}{\sqrt{a^\top \Sigma_{XX} a} \sqrt{b^\top \Sigma_{YY}b}}
$$
所以， 可以直接对$a$做放缩，使得$a^\top \Sigma_{XX} a=1$, 对$b$做放缩，使得$b^\top \Sigma_{YY}b=1$（类似于SVM）。 那么优化目标转化为：
$$
\begin{aligned}
&amp;\max_{a, b} a^{\top} \Sigma_{X Y} b, \\ &amp;\text{ s.t. } a^{\top} \Sigma_{X X} a=b^{\top} \Sigma_{Y Y} b=1
\end{aligned}
$$
对于两个向量集合$X_1$和$X_2$， CCA 寻求两组向量最大化它们的相关性，并受到它们彼此不相关的约束。 后来的研究通过用神经网络代替线性变换，将 CCA 应用于具有深度模型的多视图学习。 具体来说，假设 $X_1$和$X_2$作为输入数据的两个视图，CCA的优化目标为：
$$
\max_{\theta_{1}, \theta_{2}} \operatorname{Tr}\left(P_{\theta_{1}}^{\top}\left(X_{1}\right) P_{\theta_{2}}\left(X_{2}\right)\right) \quad \text { s.t. } P_{\theta_{1}}^{\top}\left(X_{1}\right) P_{\theta_{1}}\left(X_{1}\right)=P_{\theta_{2}}^{\top}\left(X_{2}\right) P_{\theta_{2}}\left(X_{2}\right)=I \text {. }  \tag{1}
$$
其中， $P_{\theta_{1}}$和$P_{\theta_{2}}$为两个Neural Network。尽管上式很精确，但这种计算确实很昂贵。Soft CCA 通过采用以下拉格朗日松弛, 消除了hard decorrelation constraint：
$$
\min_{\theta_{1}, \theta_{2}} \mathcal{L}_{\text {dist }}\left(P_{\theta_{1}}\left(X_{1}\right), P_{\theta_{2}}\left(X_{2}\right)\right)+\lambda\left(\mathcal{L}_{S D L}\left(P_{\theta_{1}}\left(X_{1}\right)\right)+\mathcal{L}_{S D L}\left(P_{\theta_{2}}\left(X_{2}\right)\right)\right)
$$
其中$\mathcal{L}_{\text {dist }}$用于衡量两个view的representations之间的相关性，$\mathcal{L}_{S D L}$ (stochastic decorrelation loss)计算$P_{\theta_{i}}\left(X_{i}\right)$和identity matrix之间的$L_1$距离。</p>
<h1 id="approach">Approach</h1>
<p><img loading="lazy" src="/posts/2022-04-15-CCA-SSG/2.png#center" alt=""  />
</p>
<p>模型包含3个模块 1. 随机图增强器$\mathcal{T}$，2. GNN encoder $f_\theta$, 3. 基于CCA的feature-level对比损失。</p>
<h2 id="graph-augmentations">Graph Augmentations</h2>
<p>本文利用 edge droping和 node feature masking两种graph corruption方式来对输入图做增强。 $\mathcal{T}$是所有可能的转换操作，$t \sim \mathcal{T}$表示图$G$的一种特定的转换。比如删除一条边的操作$t_r$就是$\mathcal{T}$中的一个变换。</p>
<h2 id="training">Training</h2>
<p>从$\mathcal{T}$随机采样两种图变换 $t_A$和$t_B$。 生成两个View: $\tilde{\mathbf{G}}_{A}=\left(\tilde{\mathbf{X}}_{A}, \tilde{\mathbf{A}}_{A}\right)$和$\tilde{\mathbf{G}}_{B}=\left(\tilde{\mathbf{X}}_{B}, \tilde{\mathbf{A}}_{B}\right)$，经过共享的GNN后，得到输出$\mathbf{Z}_{A}=f_{\theta}\left(\tilde{\mathbf{X}}_{A}, \tilde{\mathbf{A}}_{A}\right)$，$\mathbf{Z}_{B}=f_{\theta}\left(\tilde{\mathbf{X}}_{B}, \tilde{\mathbf{A}}_{B}\right)$。然后对feature dimensionzuo normalization (列标准化)， 是的每个特征维度均值为0， 标准差为$1 / \sqrt{N}$：</p>
<p>$$
\tilde{\mathbf{Z}}=\frac{\mathbf{Z}-\mu(\mathbf{Z})}{\sigma(\mathbf{Z}) * \sqrt{N}}
$$</p>
<h1 id="inference">Inference</h1>
<p>基于公式（1）,使用公式(1)中的CCA目标函数，将向量集定义为输出$\tilde{\mathbf{Z}}$的列向量， 最终CCA-SSG的目标函数定义如下：
$$
\mathcal{L}=\underbrace{\left|\left|\tilde{\mathbf{Z}}_{A}-\tilde{\mathbf{Z}}_{B}\right|\right|_{F}^{2}}_{\text {invariance term }}+\lambda \underbrace{\left(\left|\left|\tilde{\mathbf{Z}}_{A}^{\top} \tilde{\mathbf{Z}}_{A}-\mathbf{I}\right|\right|_{F}^{2}+\left|\left|\tilde{\mathbf{Z}}_{B}^{\top} \tilde{\mathbf{Z}}_{B}-\mathbf{I}\right|\right|_{F}^{2}\right)}_{\text {decorrelation term }}
$$
第二项中，要求不同特征之间的相似度尽可能低， 从而使得不同特征捕获不同的语义信息。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ICML2020 《Contrastive Multi-View Representation Learning on Graphs》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/mvgrl/</link>
      <pubDate>Tue, 12 Apr 2022 22:21:29 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/mvgrl/</guid>
      <description>ICML2020 &amp;#34;Contrastive Multi-View Representation Learning on Graphs&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2006.05582">paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>本文旨在通过多视图Contrastive Learning 来学习节点表示和图表示。其中对比视图为结构视图（structural view）。本文发现，两个以上的对比视图不会提升性能（我觉得仅是针对本文的Diffusion-based view吧~）。 本文实验性的表明了基于一阶邻居和图扩散视图做CL可以达到最好的效果。</p>
<p>为了将对比学习应用到图表示学习任务，本文提出通过最大化图的不同结构视角的互信息来作为监督信号。通过对提出框架的系统研究，本文展示了一些GCL和visual CL上的不同： （1）将view数量（即增强）增加到两个以上不会提高性能，最好的性能是通过对比来自一阶邻居view的embedding和graph diffusion的embedding，(2) 与对比图编码或多尺度编码相比，跨视图对比节点和图编码在node classification 和 graph classification上都能获得更好的结果。 (3) 与分层图池化方法（例如DiffPool相比）一个简单的Readout在这node classification 和 graph classification上实现了更好的性能，以及 (4) 应用正则化（early stopping除外） 或归一化层对性能有负面影响。</p>
<h1 id="method">Method</h1>
<p><img loading="lazy" src="/posts/2022-04-13-MVGRL/1.png" alt=""  />
</p>
<p>MVGRL通过最大化一个view的node embedding和另一个view的graph embedding之间的 互信息来学习节点和图表示。如上图所示，MVGRL由以下几个部分构成</p>
<ul>
<li><strong>增强机制</strong>：将样本图转化为同一个图的相关view， 这个view只是structural view， 不会改变原图中的node feature，然后对两个增强图中的相同节点（identical node）进行子采样，类似于CV中的域剪裁。</li>
<li><strong>两个专用的GNNs</strong>， 每个view一个GNN，再接一个共享的MLP作为projection head，来为两个view学习representation。</li>
<li><strong>图池化层</strong>， 在MLP后学习两个图的graph-level representation。</li>
<li><strong>判别器</strong> 来对比一个图的embedding和另一个图的节点embedding,并对他们的一致性（agreement）评分。</li>
</ul>
<h2 id="augmentations">Augmentations</h2>
<p>考虑两种类型的图增强：(1) 对初始节点特征进行操作的特征空间增强，例如，mask或添加高斯噪声，以及 (2) 通过添加或删除连通性、子采样或使用最短路径或diffusion matrix生成全局视图来对做图结构增强。 前一种增强可能是有问题的，因为许多数据集不带有初始节点特征。 此外，观察到在任一空间上屏蔽或添加噪声都会降低性能。 因此，本文选择生成全局视图，然后进行子采样。</p>
<p>实验表明，在大多数情况下，最好的结果是通过将邻接矩阵转化为扩散矩阵，并将这两个矩阵视为同一图的结构的两个一致view。因为<strong>邻接矩阵和扩散矩阵分别提供了图结构的局部和全局视图</strong>，从这两种view中学习到的表示之间最大一致性，从而鼓励模型同时编码的局部和全局信息。</p>
<p>Diffusion matrix从全局角度提供了任意节点对之间的相关性，其中$\mathbf{T} \in \mathbb{R}^{n \times n}$是通用转移矩阵，$\Theta$是权重系数，决定了全局和局部信息的比例，即对于每个节点，不同层次信息的比重， $\Theta_{k}$越大，表示全局信息权重越大。 令$\sum_{k=0}^{\infty} \theta_{k}=1, \theta_{k} \in[0,1]$，$\lambda_{i} \in[0,1]$,其中$\lambda$是$\mathbf{T}$的特征向量，  这样来保证$\mathbf{S}$可以收敛到一个固定矩阵。扩散用快速近似值和稀疏化方法计算：
$$
\mathbf{S}=\sum_{k=0}^{\infty} \Theta_{k} \mathbf{T}^{k} \in \mathbb{R}^{n \times n}
$$
给定一个邻接矩阵$\mathbf{A} \in \mathbb{R}^{n \times n}$和一个对角度矩阵$\mathbf{D} \in \mathbb{R}^{n \times n}$, Personalized PageRank (PPR)和Heat Kernel分别为两种不同的Diffusion matrix实例。对于PPR和HK，转移概率矩阵定义为$\mathbf{T}=\mathbf{A} \mathbf{D}^{-1}$。PPR将第$k$层的权重系数设置为$\theta_{k}=\alpha(1-\alpha)^{k}$, 而HK将第$k$层的权重系数设置为$\theta_{k}=e^{-t} t^{k} / k !$。</p>
<p>PPR的封闭阶如下所示：
$$
\mathbf{S}^{\mathrm{PPR}}=\alpha\left(\mathbf{I}_{n}-(1-\alpha) \mathbf{D}^{-1 / 2} \mathbf{A} \mathbf{D}^{-1 / 2}\right)^{-1}
$$
HK的封闭解如下所示：
$$
\mathbf{S}^{\text {heat }}=\exp \left(t \mathbf{A} \mathbf{D}^{-1}-t\right)
$$</p>
<h2 id="sub-sampling">Sub-Sampling</h2>
<p>从一个view中<strong>随机采样节点及其边</strong>，并从另一个view中<strong>选择exact的的节点和边</strong> (如示意图所示， 从第一个图中采样节点和边的子图作为一个view，从第二个图中采样相同节点以及这些节点之间的边作为另一个view，来做对比学习)。这个过程允许MVGRL应用于具有图数据不适合GPU内存的inductive任务，也可以通过将子样本视为独立的图来考虑transductive任务。</p>
<h2 id="encoder">Encoder</h2>
<p>和其他GCL方法不同的是，这里不同视图使用的是各自的GNN编码器， 邻接矩阵和Diffusion matrix是同一个图的两个一致视角，分别反映了局部和全局性质。首先，为两种view采样之后的子图分别定义GNN encoder：$g_{\theta}(.), g_{\omega}(.): \mathbb{R}^{n \times d_{x}} \times \mathbb{R}^{n \times n} \longmapsto \mathbb{R}^{n \times d_{h}}$， 使用最简单的GCN，传播矩阵分别为normalized adjacency matrix $\sigma(\tilde{\mathbf{A} }X \boldsymbol{\Theta})$ 和 Diffusion Matrix:  $\sigma(\mathbf{S} X \boldsymbol{\Theta})$。学习到的embedding输入projection head （MLP）$f_{\psi}(.): \mathbb{R}^{n \times d_{h}} \longmapsto \mathbb{R}^{n \times d_{h}}$中， 得到两个view的输出node embedding matrix: $\mathbf{H}^{\alpha}, \mathbf{H}^{\beta} \in \mathbb{R}^{n \times d_{h}}$。</p>
<p>接下来使用pooling $\mathcal{P}(.): \mathbb{R}^{n \times d_{h}} \longmapsto \mathbb{R}^{d_{h}}$ 输出两个view的graph representations。 本文采用JKnet中的跳连机制，即GNN的每层输出做sum pooling, 然后将所有层拼起来做特征变换：
$$
\vec{h}_{g}=\sigma\left(||_{l=1}^{L}\left[\sum_{i=1}^{n} \vec{h}_{i}^{(l)}\right] \mathbf{W}\right) \in \mathbb{R}^{h_{d}}
$$
其中$\vec{h}_{i}^{(l)}$是节点$i$的第$l$层输出，$||$是concatenation， $\mathbf{W} \in \mathbb{R}^{\left(L \times d_{h}\right) \times d_{h}}$是特征变换参数，$\sigma$是PReLU非线性激活。最终，将图表示输入到一个projection head $f_{\phi}(.): \mathbb{R}^{d_{h}} \longmapsto \mathbb{R}^{d_{h}}$ 中，得到最终的图表示：$\vec{h}_{g}^{\alpha}, \vec{h}_{g}^{\beta} \in \mathbb{R}^{d_{h}}$。</p>
<p>在推理阶段， 由于两个view来自同一个图，可以把两个view的表示结合起来作为原图的表示：两个view的graph embedding直接相加，作为原图 embedding.。 两个view的node embedding 直接相加，作为原图的node embedding $\vec{h}=\vec{h}_{g}^{\alpha}+\vec{h}_{g}^{\beta} \in \mathbb{R}^{n}$ 。 $\mathbf{H}=\mathbf{H}^{\alpha}+\mathbf{H}^{\beta} \in \mathbb{R}^{n \times d_{h}}$。 这里得到的原图embedding可以应用于下游任务。</p>
<h2 id="training">Training</h2>
<p>为了端到端训练encoder并学习与下游任务无关的丰富节点和图级表示，本文利用 Deep InfoMax 方法并通过对比一个视图的节点表示与图表示来最大化两个视图之间的 互信息。 实验表明，这种方法在节点和图分类上始终优于对比图-图或多尺度编码。 目标定义如下：
$$
\max_{\theta, \omega, \phi, \psi} \frac{1}{|\mathcal{G}|} \sum_{g \in \mathcal{G}}\left[\frac{1}{|g|} \sum_{i=1}^{|g|}\left[\operatorname{MI}\left(\vec{h}_{i}^{\alpha}, \vec{h}_{g}^{\beta}\right)+\operatorname{MI}\left(\vec{h}_{i}^{\beta}, \vec{h}_{g}^{\alpha}\right)\right]\right]
$$
其中$\theta, \omega, \phi, \psi$为是GNN encoder和projection head的参数, $|\mathcal{G}|$是图数量，$|\mathcal{g}|$是图中节点数， $\vec{h}_{i}^{\alpha}, \vec{h}_{g}^{\beta}$分别表示view $\alpha$中的节点$i$的representation， 和view $\beta$的 graph representation。</p>
<p>互信息判别器： $\mathcal{D}(., .): \mathbb{R}^{d_{h}} \times \mathbb{R}^{d_{h}} \longmapsto \mathbb{R}$简单的设置为表示向量间的内积相似度：
$$
\mathcal{D}\left(\vec{h}_{n}, \vec{h}_{g}\right)=\vec{h}_{n} \cdot \vec{h}_{g}^{T}
$$
作者发现当判别器和projection head集成到双线性层中时，节点分类基准略有改进。 为了确定 MI 估计器，实验中调查了四个估计器并为每个基准选择了最好的一个。</p>
<p>正样本采样自联合分布$x_{p} \sim p\left(\left[\mathbf{X}, \tau_{\alpha}(\mathbf{A})\right],\left[\mathbf{X}, \tau_{\beta}(\mathbf{A})\right]\right)$， 从边际乘积中采样负样本 $x_{p} \sim p\left(\left[\mathbf{X}, \tau_{\alpha}(\mathbf{A})\right]\right) p\left(\left[\mathbf{X}, \tau_{\beta}(\mathbf{A})\right]\right)$。利用小批量随机梯度下降法对模型参数进行优化。 MVGRL算法如下：</p>
<p><img loading="lazy" src="/posts/2022-04-13-MVGRL/2.png" alt=""  />
</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>WWW2022 《SimGRACE:A Simple Framework for Graph Contrastive Learning without Data Augmentation》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/simgrace/</link>
      <pubDate>Sat, 09 Apr 2022 14:47:57 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/simgrace/</guid>
      <description>WWW2022 &amp;#34;SimGRACE:A Simple Framework for Graph Contrastive Learning without Data Augmentation&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2202.03104">paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>图对比学习（GCL）已经成为图表示学习的主要技术，它最大化了共享相同语义的成对图增强之间的互信息。鉴于图数据的多样性，在增强过程中很难很好地保留语义。目前，GCL 中选择图增强方式的途径通常有以下三种。 1.  适用于不同数据集的图增强方式可能是不同的，需要在每个数据集上做验证，手动选择最适用于每个数据集的增强。2. 通过繁琐的搜索来选择增强方式。3. 通过邻域只是来选择增强方式。所有这些都限制了现有 GCL 方法的效率和通用性。为了解决该问题，本文提出了一种不需要对图做编辑， 而是对GNN编码器做扰动的增强方式： <strong>SimGRACE</strong>。并且对SimGRACE设计了对抗训练的方案：<strong>AT-SimGRACE</strong>。</p>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/1.png#center" alt="图1"  title="123"  />
</p>
<p>上图的实验中，两类图用不同的颜色标出，三种GCL模型分别在三个数据集上训练，训练完成后的分类效果如第一行所示。 对于GraphCL, 对边做扰动后再输入GraphCL 训练好的encoder,可以看出GraphCL的encoder对于扰动后的图数据集无法很好的保留分类语义。而对于SIMGRACE，不对图做扰动，而对训练好的encoder做扰动，扰动后的encoder对数据集的分类效果可以很好地保留语义信息。由此实验性表明了对encoder扰动可以保留比直接对图扰动更多的语义信息。</p>
<p>GraphCL 表明 GNN 可以使用他们提出的框架获得鲁棒性。 但是，（1）他们没有解释为什么 GraphCL 可以增强鲁棒性； (2) GraphCL 似乎对随机攻击具有很好的免疫力，而对对抗性攻击的表现却不尽如人意。为了弥补这些缺陷，本文基于SimGRACE提出了一种新的算法 AT-SimGRACE通过对抗的方式来扰动编码器，从而是实现对抗训练的效果，它引入了更少的计算开销，同时显示出更好的鲁棒性。</p>
<h1 id="method">Method</h1>
<h2 id="simgrace">SimGRACE</h2>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/2.png#center" alt="图1"  />
</p>
<h3 id="编码器扰动encoder-perturbation">编码器扰动（Encoder perturbation）</h3>
<p>给定一个GNN编码器$f(\cdot;\theta)$,它的参数扰动版本表示为$f(\cdot;\theta^\prime)$。如图中所示，参数扰动版本的编码器不需要梯度反传训练参数，每次训练过程更新$f(\cdot;\theta)$，而$f(\cdot;\theta^\prime)$的参数$\theta^\prime$只通过对$\theta$扰动得到。第$l$层GNN的参数表示为$\theta_l$，那么它的扰动后参数$\theta^\prime_l$有下式得到：
$$
\theta_{l}^{\prime}=\theta_{l}+\eta \cdot \Delta \theta_{l} ; \quad \Delta \theta_{l} \sim \mathcal{N}\left(0, \sigma_{l}^{2}\right)
$$
其中$\eta$用来控制扰动的缩放，$\Delta \theta_{l}$是扰动项，扰动值采样自0均值$\sigma_{l}^{2}$的Gaussian Distribution。$f(\cdot;\theta)$和$f(\cdot;\theta^\prime)$的输出分别为$\mathbf{h}$和$\mathbf{h}^{\prime}$：
$$
\mathbf{h}=f(\mathcal{G} ; \boldsymbol{\theta}), \mathbf{h}^{\prime}=f\left(\mathcal{G} ; \boldsymbol{\theta}^{\prime}\right)
$$
从下图可以看出，如果不对编码器施加扰动，即超参数$\eta=0$，效果会很差，扰动太多效果也会很差。</p>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/3.png#center" alt="图1"  />
</p>
<h3 id="映射头-projection-head">映射头 （Projection Head）</h3>
<p>和其他大多数GCL方法一样，该方法也要一个projection head来对GNN的output representation做一次变换，通常就是个MLP，得到输出$z$和$z^\prime$：
$$
z=g(\mathbf{h}), z^{\prime}=g\left(\mathbf{h}^{\prime}\right)
$$</p>
<h3 id="对比损失contrastive-loss">对比损失（Contrastive loss）</h3>
<p>和GraphCL一样，使用NT-Xent作为损失函数。具体来说，用$z_n$和$z_n^\prime$分别表示表示图$n$在$f(\cdot;\theta)$和$f(\cdot;\theta^\prime)$两个编码器下的输出， 用$z_n$和$z_{n^\prime}$表示一个batch中两个不同图$n$和图$n^\prime$在未扰动编码器$f(\cdot;\theta)$下的输出。在一个batch内，最大化同一个图的两个编码器（$f(\cdot;\theta)$和$f(\cdot;\theta^\prime)$）输出间的相似度，同时最小化不同图在未扰动编码器$f(\cdot;\theta)$下输出的相似度：
$$
\ell_{n}=-\log \frac{\left.\exp \left(\operatorname{sim}\left(z_{n}, z_{n}^{\prime}\right)\right) / \tau\right)}{\sum_{n^{\prime}=1, n^{\prime} \neq n}^{N} \exp \left(\operatorname{sim}\left(z_{n}, z_{n^{\prime}}\right) / \tau\right)}
$$
即同一个图的两个输出为positive pair, 不同图的$f(\cdot;\theta)$输出为negative pair.</p>
<h2 id="why-can-simgrace-work-well">Why can SimGRACE work well?</h2>
<p>[1] 提供了两个属性来衡量对比学习学到的representation的质量： <em>Alignment和Uniformity</em>。其中Alignment metric直接定义为positive pairs之间的距离：
$$
\ell_{\text {align }}(f ; \alpha) \triangleq \underset{(x, y) \sim p_{\text {pos }}}{\mathbb{E}}\left[||f(x)-f(y)||_{2}^{\alpha}\right], \quad \alpha&gt;0
$$
其中$p_{\text {pos }}$为positive pairs的分布，也就是positive pairs之间的距离越小，说明CL越好。 基于SimGRACE构造contrastive pairs的方式，alignment metric 可以定义为如下形式：
$$
\ell_{\text {align }}(f ; \alpha) \triangleq \underset{x \sim p_{\text {data }}}{\mathbb{E}}\left[\left|\left|f(x ; \theta)-f\left(x ; \theta^{\prime}\right)\right|\right|_{2}^{\alpha}\right], \quad \alpha&gt;0
$$
另一个衡量指标是Uniformity， 定义为成对高斯势函数（Gaussian Potential）：
$$
\ell_{\text {uniform }}(f ; \alpha) \triangleq \log \underset{x, y_{\sim}^{i . i . d .} p_{\text {data }}}{\mathbb{E}}\left[e^{-t||f(x ; \theta)-f(y ; \theta)||_{2}^{2}}\right] . \quad t&gt;0
$$
它要求随机样本的embedding应尽可能分散在hypersphere上， 即随机采样两个图在未扰动编码器输出的embedding距离要尽可能大。从下图可以看出，随着training epoch的增加，三种方法都呈现出正确的趋势。</p>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/4.png#center" alt="图1"  />
</p>
<h2 id="at-simgrace">AT-SimGRACE</h2>
<p>通过对抗训练（Adversarial Training， AT）来提升SimGRACE的鲁棒性。 对抗训练的优化问题定义如下：
$$
\min_{\theta} \mathcal{L}^{\prime}(\theta), \quad \text { where } \quad \mathcal{L}^{\prime}(\theta)=\frac{1}{n} \sum_{i=1}^{n} \max_{ | |\mathrm{x}_{i}^{\prime}-\mathrm{x}_{i} | |_{p} \leq \epsilon} \ell_{i}^{\prime}\left(f\left(\mathrm{x}_{i}^{\prime} ; \theta\right), y_{i}\right)
$$
其中$n$是训练样本数，$\mathrm{x}_{i}^{\prime}$是对抗样本， 其中对抗样本在训练样本的$\epsilon$-ball中，即$| |\mathrm{x}_{i}^{\prime}-\mathrm{x}_{i} | |_{p} \leq \epsilon$, 表示对抗样本和原样本的变化不能超过$\epsilon$。Adversarial Training: 优化$\theta$，使得$f$可以在$\mathrm{x}_{i}$的对抗样本$\mathrm{x}_{i}^{\prime}$上可以预测准确。其中$\ell^{\prime}(\cdot)$为监督分类损失，$\mathcal{L}^{\prime}(\theta)$为对抗损失。AT不能直接应用于CL上，因为（1）CL任务无标签，（2）对数据集中的每个样本扰动计算量太大。 为了解决这个问题，本文将AT loss中的损失函数部分换成NT-Xent对比学习损失，然后用对抗的方式来扰动encoder，从而无需对数据集中的所有样本扰动。</p>
<p>假设$\Theta$为GNN的权重空间(weight space)， 对于任意$\mathbf{w}$任意正实数$\epsilon$, 为$\theta$定义半径为$\epsilon$,中心为$\mathbf{w}$的norm ball:
$$
\mathbf{R}(\mathbf{w} ; \epsilon):=\{\boldsymbol{\theta} \in \boldsymbol{\Theta}:||\boldsymbol{\theta}-\mathbf{w}|| \leq \epsilon\}
$$
$\theta \in \Theta$表示权重空间$\Theta$中任意一组可能的GNN权重$\theta$, $\mathbf{R}(\mathbf{w} ; \epsilon)$表示GNN所有与$\mathbf{w}$相似的权重，即所有与$\mathbf{w}$的差距小于$\epsilon$的权重。</p>
<p>那么AT-SimGRACE的优化问题定义如下：
$$
\begin{gathered}
\min_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta}+\Delta) \\
\text { where } \mathcal{L}(\boldsymbol{\theta}+\Delta)=\frac{1}{M} \sum_{i=1}^{M} \max_{\Delta \in \mathrm{R}(0 ; \epsilon)} \ell_{i}\left(f\left(\mathcal{G}_{i} ; \boldsymbol{\theta}+\Delta\right), f\left(\mathcal{G}_{i} ; \boldsymbol{\theta}\right)\right)
\end{gathered}
$$
这里$\mathrm{R}(0 ; \epsilon)=\{\Delta \in \Theta: ||\Delta|| \leq \epsilon\}$ ，$\mathcal{L}(\boldsymbol{\theta}+\Delta)$表示在对GNN参数施加扰动$\Delta$，使得GNN的效果最差，换句话说，找到一个扰动$\Delta$，使得GNN的参数在被$\Delta$扰动后（变为$\theta+\Delta$）两个图最不匹配（对比学习损失达到最大）。 $min_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta}+\Delta)$表示训练GNN参数，使得对比学习可以适应该扰动。算法如下：</p>
<p><img loading="lazy" src="/posts/2022-04-12-SimGRACE/5.png#center" alt="图1"  />
</p>
<p>对抗训练：</p>
<p>内层： 固定GNN参数，训练扰动参数$\Delta$，使得GNN的对比学习loss上升</p>
<p>外层： 固定扰动参数$\Delta$， 训练GNN参数$\theta$， 使得$\theta$加上扰动$\Delta$后的对比学习loss最小化。</p>
<h1 id="reference">Reference</h1>
<p>[1] Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere. ICML (2020)</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ICML2020 《When Does Self-Supervision Help Graph Convolutional Networks?》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/2020-04-03-ssgcns/</link>
      <pubDate>Fri, 08 Apr 2022 14:04:49 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/2020-04-03-ssgcns/</guid>
      <description>ICML2020 &amp;#34;When Does Self-Supervision Help Graph Convolutional Networks?&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p><a href="https://arxiv.org/abs/2006.09136v4">Paper</a></p>
<h1 id="introduction">Introduction</h1>
<p>本文是自监督方法在GCNs上首次系统的探索，设计了3种自监督任务来将分析自监督在GCN中起到的作用。自监督旨在充分利用unlabeled数据中的知识来设计前置任务（pretext task），来帮助模型学习更具迁移性和泛化能力的表示。前置任务可以认为是对目标任务有帮助的辅助正则化网络，设计用于帮助原任务学习到更多下游任务相关的语义信息。</p>
<p>GCN任务通常是直推半监督的（transductive semi-supervised）,含有大量unlabeled数据，而self-supervision(SSL)可以充分利用unlabeled data， 那么就产生了一个值得探索的问题：<strong>将自监督学习应用到GCN上是否也可以达到提升泛化能力和鲁棒能力的效果？</strong></p>
<p>先给结论</p>
<p>Q1: 自监督学习可否在分类任务中提升GCN？ 如果可以，如何将其合并到 GCN 中以最大化增益？</p>
<p>A1: 本文证明了通过多任务学习将自监督学习融入 GCN 是有效的，即多任务损失作为 GCN 训练中的正则化项。 这种作为自监督作为正则化项的方法，强于用自监督来预训练或者self-training。</p>
<p>Q2: 前置任务的设计重要吗？ GCN 有哪些有用的自监督前置任务？</p>
<p>A2: 本文研究了三个基于图属性的自监督任务。 分别是节点聚类node clustering, 图划分graph partitioning 和图补全graph completion。 并且进一步说明不同的模型和数据集倾向于不同的自监督任务。</p>
<p>Q3: 自监督也会影响 GCN 的对抗鲁棒性吗？ 如果是，如何设计前置任务？</p>
<p>A3: 本文进一步将上述发现推广到对抗性训练环境中。提供了广泛的结果，以表明自监督还可以提高 GCN 在各种攻击下的鲁棒性，而不需要更大的模型或额外的数据。</p>
<h1 id="method">Method</h1>
<p>GCNs $\boldsymbol{Z}=\hat{\boldsymbol{A}} \operatorname{ReLU}\left(\hat{\boldsymbol{A}} \boldsymbol{X} \boldsymbol{W}_{0}\right) \boldsymbol{W}_{1}$可以分为两块来看 (1) 特征提取模块$f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) = \hat{\boldsymbol{A}} \operatorname{ReLU}\left(\hat{\boldsymbol{A}} \boldsymbol{X} \boldsymbol{W}_{0}\right)$ 参数为$\theta = \{\boldsymbol{W}_{0}\}$和（2）线性变换模块$\boldsymbol{Z}=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta}$ 其中 参数$ \boldsymbol{\Theta} = \boldsymbol{W}_{1}$。 半监督GCN优化任务的目标函数为：
$$
\begin{aligned}
\boldsymbol{Z} &amp;=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta} \\
\theta^{*}, \boldsymbol{\Theta}^{} &amp;=\arg \min_{\theta, \boldsymbol{\Theta}} \mathcal{L}_{\mathrm{sup}}(\theta, \boldsymbol{\Theta}) \\
&amp;=\arg \min_{\theta, \boldsymbol{\Theta}} \frac{1}{\left|\mathcal{V}_{\text {label }}\right|} \sum_{v_{n} \in \mathcal{V}_{\text {label }}} L\left(\boldsymbol{z}_{n}, \boldsymbol{y}_{n}\right)
\end{aligned} \tag{1}
$$
其中$L(\cdot, \cdot)$是每个labeled node的损失函数。</p>
<h2 id="three-schemes-self-supervision-meets-gcns">Three Schemes: Self-Supervision Meets GCNs</h2>
<p>研究三种将SSL配置到GCNs的方式。 其中 给定输入$\boldsymbol{X}_{ss}$, $\hat{\boldsymbol{A}}_{\mathrm{ss}}$, label $\boldsymbol{Y}_{ss}$和节点集$\mathcal{V}_{ss}$。</p>
<h3 id="pretraining--fintuning">Pretraining &amp; Fintuning</h3>
<p>预训练过程：
$$
\begin{aligned}
\boldsymbol{Z}_{\mathrm{ss}} &amp;=f_{\theta}\left(\boldsymbol{X}_{\mathrm{ss}}, \hat{\boldsymbol{A}}_{\mathrm{ss}}\right) \boldsymbol{\Theta}_{\mathrm{Ss}} \\
\theta_{\mathrm{ss}}^{*}, \boldsymbol{\Theta}_{\mathrm{ss}}^{*} &amp;=\arg \min_{\theta, \boldsymbol{\Theta}_{\mathrm{ss}}} \mathcal{L}_{\mathrm{ss}}\left(\theta, \boldsymbol{\Theta}_{\mathrm{ss}}\right) \\
&amp;=\arg \min_{\theta, \boldsymbol{\Theta}} \frac{1}{\left|\mathcal{V}_{\mathrm{ss}}\right|} \sum_{v_{n} \in \mathcal{V}_{\mathrm{ss}}} \underbrace{L_{\mathrm{ss}}\left(\boldsymbol{z}_{\mathrm{ss}, n}, \boldsymbol{y}_{\mathrm{ss}, n}\right)}_{\text{loss of other task}}<br>
\end{aligned} \tag{2}
$$
也就是在另一个任务训练好的模型参数$\theta_{\mathrm{ss}}^{*}, \boldsymbol{\Theta}_{\mathrm{ss}}^{*}$迁移到新任务（如半监督节点分类任务）上作为初始化参数训练新模型。</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/1.png#center" alt=""  />
</p>
<p>上表中，可以看出用graph partitioning作为预训练任务，得到的模型fine-tuning到节点分类任务上之后，效果仅从79.10变成了79.19,是非常微小的。 本文推测可能原因有两个（1）.两个不同的任务的Loss function不一样，从$\mathcal{L}_{\mathrm{ss}}$变为$\mathcal{L}_{\mathrm{sup}}$会影响实验效果。（2）参数迁移前一句是在多层GCN上的训练结果了，迁移后再训练，相当于深层，易oversmoothing。</p>
<h3 id="self-training">Self-Training</h3>
<p>每次迭代为unlabeled samples分配高度可信的为标签，然后将这些分配了伪标签的节点纳入到下一次迭代的监督训练中，随迭代过程不断更新标签。</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/2.png#center" alt=""  />
</p>
<p>表2可以看出Self-training的方式带来的提升有限</p>
<h3 id="multi-task-learning">Multi-task Learning</h3>
<p>考虑一个目标task和一个自监督task. GCN的目标为公式（1）。该多任务的训练过程如下：
$$
\begin{aligned}
\boldsymbol{Z} &amp;=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta}, \quad \boldsymbol{Z}_{\mathrm{ss}}=f_{\theta}\left(\boldsymbol{X}_{\mathrm{ss}}, \hat{\boldsymbol{A}}_{\mathrm{ss}}\right) \boldsymbol{\Theta}_{\mathrm{ss}} \\
\theta^{*}, \boldsymbol{\Theta}^{*}, \boldsymbol{\Theta}_{\mathrm{ss}}^{*} &amp;=\arg \min_{\theta, \boldsymbol{\Theta}, \boldsymbol{\Theta}_{\mathrm{ss}}} \alpha_{1} \mathcal{L}_{\mathrm{sup}}(\theta, \boldsymbol{\Theta})+\alpha_{2} \mathcal{L}_{\mathrm{ss}}\left(\theta, \boldsymbol{\Theta}_{\mathrm{ss}}\right)
\end{aligned} \tag{3}
$$
其中任务的权重参数$\alpha_{1}, \alpha_{2} \in \mathbb{R}_{&gt;0}$, 半监督目标任务的损失$\mathcal{L}_{\mathrm{sup}}$定义为公式（1）， 辅助自监督损失$\mathcal{L}_{\mathrm{ss}}$定义为公式（2）.其中特征提取器$f_{\theta}(\cdot, \cdot)$对于自监督任务和目标任务是参数共享的，而线性变换参数$\boldsymbol{\Theta}, \boldsymbol{\Theta}_{\mathrm{ss}}$是各自任务的。</p>
<p>在公式(3)中，自监督任务的loss作为一个<strong>regularization term</strong> 与目标任务一同训练。正则化项在图信号处理中是广泛应用的， 常见的有Graph Laplaician Regularization（GLR）， 它用于惩罚相邻节点间的不平滑，用于在学习目标任务的同时保持特征在图结构上的smoothing。虽然GLR可以作为一个自监督任务，但是它是给予不涉及具体数据情况下的平滑先验，SSL的regularization term不用的是，SSL是给予unlabeled data,是一种引入数据驱动的先验知识。综上所述， 多任务学习是3种自监督方式中最通用的。</p>
<h2 id="gcn-specific-self-supervised-tasks">GCN-Specific Self-Supervised Tasks</h2>
<p>本文为 GCN 扩展了一个自监督任务的“工具包”。 通过利用图中的丰富节点和边信息，可以定义各种GCN特定的自监督任务（如表 3 所示），并且进一步证明了不同的自监督任务对不同类型的监督/下游任务有益。这些自监督任务会为节点分配伪标签来构造自监督损失$\mathcal{L}_{ss}$, 如公式（3）所示。</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/4.png#center" alt=""  />
</p>
<h3 id="node-clustering">Node clustering</h3>
<p>第一个任务为节点聚类， 给定节点集$\mathcal{V}$以及feature set $\boldsymbol{X}$, 一个预设值的簇数量$K \in\{1, \ldots,|\mathcal{V}|\}$（是一个超参数）一定要小于等于节点数$|\mathcal{V}|$。 聚类算法输出一个节点集合的集合$\left\{\mathcal{V}_{\text {clu }, 1}, \ldots, \mathcal{V}_{\text {clu }, K} \mid \mathcal{V}_{\text {clu }, n} \subseteq \mathcal{V}, n=1, \ldots, K\right\}$， 其中$\mathcal{V}_{\text {clu }, i}$是一个集合表示在簇$i$中的节点集。
$$
\begin{aligned}
&amp;\mathcal{V}_{\text {clu }, n} \neq \emptyset \quad(n=1, \ldots, K), \quad \cup_{n=1}^{K} \mathcal{V}_{\text {clu }, n}=\mathcal{V} \\
&amp;\mathcal{V}_{\text {clu }, i} \cap \mathcal{V}_{\text {clu }, j}=\emptyset \quad(\forall i, j=1, \ldots, K \text { and } i \neq j)
\end{aligned}
$$
这$K$个簇互相之间没有公共的节点，SSL任务将每个节点所在的簇的index作为伪标签来构造自监督损失$\mathcal{L}_{ss}$：
$$
y_{\mathrm{ss}, n}=k \text { if } v_{n} \in \mathcal{V}_{\mathrm{clu}, k}(\forall n=1, \ldots,|\mathcal{V}|, \forall k=1, \ldots, K)
$$</p>
<h3 id="graph-partitioning">Graph partitioning</h3>
<p>上面的节点聚类任务，是基于特征的，与拓扑无关。 而这里的图划分任务，与feature无关，只与拓扑有关。 具体来说，通过“强”边连接的两个节点很可能属于同一标签类别。 因此，本文提出了一种使用图划分的基于拓扑的自监督任务。</p>
<p>图划分是将图的节点划分为大致相等的子集，使得跨子集间的边数最小化（高聚类，低耦合，同时簇中节点数不能差别太大）。先预定义一个簇数量，$K \in\{1, \ldots,|\mathcal{V}|\}$（超参数）。 和节点聚类任务类似，图划分算法也会输出一个节点集合的集合，用来标识每个节点属于哪个partition: $\left\{\mathcal{V}_{\text {par }, 1}, \ldots, \mathcal{V}_{\text {par }, K} \mid \mathcal{V}_{\text {par }, n} \subseteq \mathcal{V}, n=1, \ldots, K\right\}$, 使得：
$$
\begin{aligned}
&amp;\mathcal{V}_{\text {par }, n} \neq \emptyset \quad(\forall n=1, \ldots, K), \quad \cup_{n=1}^{K} \mathcal{V}_{\text {par }, n}=\mathcal{V} \\
&amp;\mathcal{V}_{\text {par }, i} \cap \mathcal{V}_{\text {par }, j}=\emptyset \quad(\forall i, j=1, \ldots, K \text { and } i \neq j)
\end{aligned}
$$
上面的约束其实和node clustering任务差不多，Graph partitioning任务还需要两个约束，一个是平衡约束来保证簇不要太大：
$$
K \frac{\max_{k}\left|\mathcal{V}_{\text {par }, k}\right|}{|\mathcal{V}|} \leqslant 1+\epsilon, \text { where } \epsilon \in(0,1)
$$
其中$\max_{k}\left|\mathcal{V}_{\text {par }, k}\right|$是节点数最多的簇中的节点数。 另一个约束要保证簇间边要尽可能少，即最小化edgecut:
$$
\text { edgecut }=\frac{1}{2} \sum_{k=1}^{K} \sum_{v_{i} \in \mathcal{V}_{\text {par }, k}} \quad\sum_{\left(v_{i}, v_{j}\right) \in \mathcal{E} ,\text {and } v_{j} \notin \mathcal{V}_{\text {par }, k}} \quad a_{i j}
$$
将每个节点所在的partition index作为label。</p>
<h3 id="graph-completion">Graph completion</h3>
<p>图补全任务如下图所示。</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/5.png#center" alt=""  />
</p>
<p>图补全首先通过删除目标节点的特征来mask目标节点。 然后，通过向 GCN 提供未掩蔽的节点特征（目前仅限于 2 层 GCN 的每个目标节点的二阶邻居）来恢复/预测被mask的节点特征。设计该自监督任务的原因如下：1）标签可以自由获取，也就是节点特征本身； 2）图补全可以帮助网络获得更好的特征表示，这可以教会网络从上下文中提取特征。</p>
<p>最终多任务自监督GCN模型的框架如下图所示：</p>
<p><img loading="lazy" src="/posts/2022-04-09-SSGCNs/3.png#center" alt=""  />
</p>
<h2 id="self-supervision-in-graph-adversarial-defense">Self-Supervision in Graph Adversarial Defense</h2>
<p>本文专注于Evasion Attack，在模型训练好后对目标节点$v_n$扰动， 实际上对于Evasion Attack，对扰动图重新训练或许可以纠正扰动的影响，但是本文这里不考虑重新训练。一个attacker $g$生成新的特征和邻接矩阵：
$$
\boldsymbol{X}^{\prime}, \boldsymbol{A}^{\prime}=g\left(\boldsymbol{X}, \boldsymbol{A}, \boldsymbol{Y}, v_{n}, \theta^{*}, \boldsymbol{\Theta}^{*}\right)
$$
其中$ \theta^{*}, \boldsymbol{\Theta}^{*}$是在clean 图上训练好的模型参数。</p>
<p>对抗训练的目标函数定义为:
$$
\begin{aligned}
\boldsymbol{Z} &amp;=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta}, \quad \boldsymbol{Z}^{\prime}=f_{\theta}\left(\boldsymbol{X}^{\prime}, \boldsymbol{A}^{\prime}\right) \boldsymbol{\Theta} \\
\theta^{*}, \boldsymbol{\Theta}^{*} &amp;=\arg \min_{\theta, \boldsymbol{\Theta}}\left(\mathcal{L}_{\text {sup }}(\theta, \boldsymbol{\Theta})+\alpha_{3} \mathcal{L}_{\mathrm{adv}}(\theta, \boldsymbol{\Theta})\right)
\end{aligned}
$$
表示模型要同时在扰动图和训练图上都保持较好的效果。 本文将基于自监督的对抗训练定义为：
$$
\begin{aligned}
\boldsymbol{Z} &amp;=f_{\theta}(\boldsymbol{X}, \hat{\boldsymbol{A}}) \boldsymbol{\Theta}, \quad \boldsymbol{Z}^{\prime}=f_{\theta}\left(\boldsymbol{X}^{\prime}, \boldsymbol{A}^{\prime}\right) \boldsymbol{\Theta} \\
\boldsymbol{Z}_{\mathrm{ss}}=&amp; f_{\theta}\left(\boldsymbol{X}_ \mathrm{ss}, \boldsymbol{A}_{\mathrm{ss}}\right) \\
\theta^{*}, \boldsymbol{\Theta}^{*}, \boldsymbol{\Theta}_{\mathrm{ss}}^{*}=&amp; \arg \min_{\theta, \boldsymbol{\Theta}, \boldsymbol{\Theta}_{\mathrm{ss}}}\left(\alpha_{1} \mathcal{L}_{\mathrm{sup}}(\theta, \boldsymbol{\Theta})\right.\\
&amp;\left.+\alpha_{2} \mathcal{L}_{\mathrm{ss}}\left(\theta, \boldsymbol{\Theta}_{\mathrm{ss}}\right)+\alpha_{3} \mathcal{L}_{\mathrm{adv}}(\theta, \boldsymbol{\Theta})\right)
\end{aligned}
$$
其中自监督损失被引入到以扰动图数据作为输入的训练中（自监督标签矩阵 $\boldsymbol{Y}_{ss}$ 也是从扰动输入生成的）。</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
