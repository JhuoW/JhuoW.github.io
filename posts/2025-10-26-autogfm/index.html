<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script type=text/javascript async src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><title>ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes | JhuoW‘s Notes</title>
<meta name=keywords content="GNN,LLM"><meta name=description content='ICML2025 "AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization" 阅读笔记'><meta name=author content="JhuoW"><link rel=canonical href=https://JhuoW.github.io/posts/2025-10-26-autogfm/><meta name=google-site-verification content="G-6F49SGED6V"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><link rel=preload href=/apple-touch-icon.png as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.2eadbb982468c11a433a3e291f01326f2ba43f065e256bf792dbd79640a92316.js integrity="sha256-Lq27mCRowRpDOj4pHwEybyukPwZeJWv3ktvXlkCpIxY=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://JhuoW.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://JhuoW.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://JhuoW.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://JhuoW.github.io/apple-touch-icon.png><link rel=mask-icon href=https://JhuoW.github.io/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://JhuoW.github.io/posts/2025-10-26-autogfm/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>MathJax={tex:{inlineMath:[["$","$"]]},displayMath:[["$$","$$"],["[[","]]"]],svg:{fontCache:"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-6F49SGED6V"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6F49SGED6V")}</script><meta property="og:title" content="ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes"><meta property="og:description" content='ICML2025 "AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization" 阅读笔记'><meta property="og:type" content="article"><meta property="og:url" content="https://JhuoW.github.io/posts/2025-10-26-autogfm/"><meta property="og:image" content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-26T13:59:35+08:00"><meta property="article:modified_time" content="2025-10-26T13:59:35+08:00"><meta property="og:site_name" content="JhuoW"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes"><meta name=twitter:description content='ICML2025 "AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization" 阅读笔记'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://JhuoW.github.io/posts/"},{"@type":"ListItem","position":2,"name":"ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes","item":"https://JhuoW.github.io/posts/2025-10-26-autogfm/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes","name":"ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes","description":"ICML2025 \"AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization\" 阅读笔记","keywords":["GNN","LLM"],"articleBody":"Introduction GFM旨在实现跨领域和任务之间的知识共享来提升图机器学习，但是现有的GFM依赖于手工设计并且fixed的backbone GNN架构，不能根据任务或者领域来自适应调整最优的GNN backbone架构。对于此问题，本文通过发现跨领域和任务的不变“图-架构”关系（invariant graph-architecture relationship）来解决该问题。什么是invariant graph-architecture relationship，就是不管是什么领域，图和架构之间存在一种不变的关系，什么样的图就应该对应于什么样的架构。这会带来3个挑战：\n如何捕获invariant和variant的pattern，其中invariant pattern指的是可以用来可靠预测图的架构的pattern，variant pattern指的是图中不能用来稳定预测图架构的pattern。换句话说，invariant pattern指的是图中可以决定架构的固有图结构，可以形成与对应GNN架构之间的一一对应的不变关系，而variant pattern指的是一个可变pattern，他可能对应于各种GNN架构，对于这类pattern，GNN架构是不确定的。 Invariant relationship between graph data and corresponding architecture 指的是一个架构适用于的固有图结构，即一个GNN架构对什么样的图结构一定适用。 如何为不同的领域和任务调整GFM中的GNN架构。 如何减轻架构搜索中的数据支配显现（Data domination）。 AutoGFM的核心思想是训练一个架构映射函数 $\\pi: \\mathcal{G} \\to \\mathcal{A}$，用于将图数据映射为特定GNN架构。\nArchitecture Inconsistency in GFM 当前GFM模型存在一个架构不一致（Architecture Inconsistency）问题，也就是说，不同领域不同任务的最优架构不一致。这边拿GFT这个foundation model为例，它在预训练图上预训练一个GNN模型，然后基于预训练图的embedding来构造一堆词汇表，然后下游任务的图基于这些预训练好的词汇表来作预测。其他GFM模型也都会在预训练阶段预训练好一个GNN模块。这个GNN模块的架构，比如可能是GCN也可能是GAT，是固定的。但这样就存在一个问题，就是下游任务的图不一定适用于这个固定的GNN架构。\nPreliminary Problem Formulation TAG：所有图用Text-attributed graph $\\mathcal{G}=(\\mathcal{V}, \\mathcal{E}, \\mathcal{R})$来统一所有图，其中 $\\mathcal{R}=r_1, \\ldots, r_{|\\mathcal{R}|}$是关系数量。\nNode of Interest (NOI) Subgraph：用子图分类任务来统一节点级，边级，图级任务。NOI subgraph $G_h$定义为一个在NOI node周围的子图。用 $S_h(v)=\\left\\{\\mathcal{V}_v^h, \\mathcal{E}_v^h, \\mathcal{R}_v^h\\right\\}$表示以节点 $v$为中心的 $h$-hop ego-subgraph。\n节点级：NOI node 就是节点 $v$本身，因此 $\\mathcal{T} = {v}$，NOI graph 表示为 $G_h(\\mathcal{T}) = S_h(v)$。\n边级：对于一条边 $(v_i,v_j$)，定义 $\\mathcal{T} = \\{v_i, v_j\\}$，该任务的NOI graph为 $G_h\\left(\\left\\{v_i, v_j\\right\\}\\right)=S_h\\left(v_i\\right) \\cup S_h\\left(v_j\\right)$。\n图级：NOI graph是整个图。\n所有的任务均可以统一成对NOI graph的分类任务。\nGraph Neural Architecture Search (GNAS) 对于一个图数据 $\\mathcal{D} = (\\mathcal{G}, \\mathcal{Y})$，图架构搜索旨在搜索一个从graph 到 label的函数 $F_{\\alpha,w}: \\mathcal{G} \\to \\mathcal{Y}$，其中 $\\alpha \\in \\mathcal{A}$是架构参数， $\\mathcal{A}$是架构空间。 $w\\in \\mathcal{W}$是权重。最优架构指的是，在该GNN架构下，模型的最优参数对图预测的loss最小，是一个bi-level optimization problem。如下图所示，上面的式子表示找到最有架构 $\\alpha^*$，满足该架构的最优参数可以使模型与 $\\mathcal{Y}$的loss最小。\nInvariant View of Architecture Customization\nThe goal is to identify invariant relationships between graph data and the correspond architecture, addressing the issue of architecture inconsistency by tailoring graph neural architecture for each data individually. （不变关系：一个图结构一定对应固定的架构，而不会对应于变化的架构，这样的图结构相对于架构空间称为invariant pattern）。\n基于此，本文构建了4个核心变量：输入图 $G$，架构 $A$，invariant pattern $Z_I$，variant pattern $Z_V$。将图到架构的映射分为2个成分：encoder $\\theta: G \\to Z_I$和 predictor $\\psi: Z_I \\to A$。分别从图中提取invariant pattern，以及用invariant pattern预测最适用于该图的架构。\nAssumption：（1） $Z_I=G \\backslash Z_V$， invariant pattern $Z_I$用于可靠预测架构；（2） $Z_V \\not \\perp A$， $Z_V$虽然不能稳定预测架构，但他并不是与架构相互独立；（3） $A \\perp Z_V \\mid Z_I$， $\\mathrm{A}=\\psi\\left(\\mathrm{Z}_I\\right)$，表示给定invariant pattern $Z_I$，架构 $A$的选择不会受到 variant pattern $Z_V$的影响。也就是说如果确定了图中的invariant pattern $Z_I$可以决定该图的架构 $A$，那么其他部分 $Z_V$不应该影响 $Z_I$对架构的选择。\n上面三个假设可以写为下式：\n$$ \\max _{\\theta, \\psi} I\\left(\\mathrm{Z}_I, \\mathrm{~A}\\right)-\\lambda I\\left(\\mathrm{Z}_I, \\mathrm{Z}_V\\right)-\\beta I\\left(\\mathrm{~A}, \\mathrm{Z}_V \\mid \\mathrm{Z}_I\\right) $$\n即 学到的invariant pattern $Z_I$要和架构完全相关，并且与variant pattern分离，同时在 $Z_I$可以确定架构的情况下， $Z_V$不能对架构的选择产生影响。AutoGFM就是要实现该目标。\nAutoGFM Disentangled Contrastive Graph Encoder 输入是一堆NOI graphs。对于一个NOI graph $G_i$，它的invariant和variant部分需要被disentangle (解纠缠)。Disentangled NOI-graph Encoder用于学习两个channel 的表示：\n$$ \\begin{aligned}\\mathrm{H}_k^{(l)} \u0026 =\\mathrm{GNN}_k\\left(\\mathrm{H}_k^{(l-1)}, \\mathbf{A}\\right), \\quad k=1,2, \\\\ \\mathrm{z}_k \u0026 =\\mathrm{MLP}_k\\left(\\mathrm{~h}_k\\right) \\\\ \\mathrm{h}_k \u0026 =\\operatorname{Readout}_k\\left(\\mathrm{H}_k^{(L)}\\right), \\quad k=1,2 .\\end{aligned} $$\n这里用两个GNN $\\mathrm{GNN}_1$和 $\\mathrm{GNN}_2$并行的学习一个图的2个表示 $z_1$和 $z_2$，作为图的invariant表示 $Z_I$和variant表示 $Z_V$。然后，本文提出NOI-graph-level contrastive learning方法来解纠缠的表示可以反应图数据的架构需求。这里要求两个表示被disentangle：\n$$ p_\\theta\\left(\\mathrm{z}_{i, k} \\mid \\mathrm{G}_i\\right)=\\frac{\\exp \\phi\\left(\\mathrm{z}_{i, k}, \\mathrm{p}_k\\right)}{\\sum_{j=1}^2 \\exp \\phi\\left(\\mathrm{z}_{i, k}, \\mathrm{p}_j\\right)} $$\n$\\mathrm{p}_k$（ $k=1,2$）是第 $k$个表示chunk的prototype，用于表示invariant或variant的可学习的protontype，上面的对比函数表示NOI graph $G_i$的表示 $z_{i,1}$要和 $\\mathrm{p}_1$相似，$z_{i,2}$要和 $\\mathrm{p}_2$相似，而 $z_{i,1}$要和 $\\mathrm{p}_2$不相似。以此来区分图中的invariant和variant成分。最大化上面的概率目的是最小化 NOI graph $G_i$ 的 $I\\left(\\mathrm{Z}_I, \\mathrm{Z}_V\\right)$。另外，不同NOI graph的invariant representation $Z_I$，需要encourage $Z_I$可以为不同的图数据捕获不同的架构需求，因此对于同一个图的invariant表示 $Z_I$，同一个图的 $Z_I$要相似，不同NOI graph的 $Z_I$要不相似，下面式子用到的 $z$全是 $Z_I$：\n$$ p_\\theta\\left(s\\left(\\mathrm{z}_{i, k}\\right) \\mid \\mathrm{G}_i, \\mathrm{z}_{i, k}\\right)=\\frac{\\exp \\phi\\left(\\mathrm{z}_{i, k}, \\mathrm{z}_{i, k}^{\\prime}\\right)}{\\sum_{j=1}^N \\exp \\phi\\left(\\mathrm{z}_{i, k}, \\mathrm{z}_{j, k}^{\\prime}\\right)} $$\n模型参数 $\\theta$的优化目标如下：\n$$ \\mathcal{L}_{\\text {dis }}=\\sum_i-\\log \\mathbb{E}_{p_\\theta\\left(\\mathrm{z}_{i, k} \\mid \\mathrm{G}_i\\right)} p_\\theta\\left(s\\left(\\mathrm{z}_{i, k}\\right) \\mid \\mathrm{G}_i, \\mathrm{z}_{i, k}\\right) $$\n旨在区分不同NOI graph的 $Z_I$，使得 $Z_I$可以为不同的图捕获不同的架构需求，同时要让同一个图的invariant和variant表示被区分。\nInvariant-guided Architecture Customization 接下来就是要构建不变表示和图架构之间的映射关系。 Invariant representation $Z_I$要可以映射到正确的架构上，对于一个GFM来说，之前的方法是定义一个GNN backbone，这个工作把backbone定义为 $|O|$个候选backbone的组合 $\\{GCN, GAT, GIN, \\ldots, SAGE\\}$，每个GNN都有自己的参数，被联合训练，如下图所示。\n这些GNN组成的超网络表示为：\n$$ \\mathrm{H}^{(l)} \\leftarrow \\sum_{i=1}^{|\\mathcal{O}|} \\alpha_{l, i} \\mathrm{GNN}_i^{(l-1)}\\left(\\mathrm{H}^{(l-1)}, \\mathbf{A}\\right), $$\n也就是当前NOI graph得到的表示是一堆候选GNN的组合。其中 $\\alpha_{l, i}$决定了每个GNN操作对给定数据集的贡献。\n架构预测器（Architecture Predictor）：对于一个图的表示 $z$（不变表示），invariant mapping predictor 定义为 $\\psi: z \\to \\{\\alpha_{l,i}\\}$。用于将invariant 表示映射为选择每个架构的概率：\n$$ \\begin{gathered}\\hat{\\alpha}_{l, i}=\\mathrm{z} \\cdot \\frac{\\mathrm{p}_{l, i}}{\\left|\\left|\\mathrm{p}_{l, i}\\right|\\right|_2} \\\\ \\alpha_{l, i}=\\frac{\\exp \\left(\\hat{\\alpha}_{l, i}\\right)}{\\sum_{j=1}^{|\\mathcal{O}|} \\exp \\left(\\hat{\\alpha}_{l, j}\\right)},\\end{gathered} $$\n其中 $\\mathrm{p}_{l, i}$是可学习的prototype，表示第$i$层第$i$个操作的表示，可以看作是architecture representation。若 $\\mathrm{H}^{(l)}$可以最好的匹配标签 $\\mathcal{Y}$，那么等价于最大化 $I\\left(\\mathrm{Z}_I, \\mathrm{~A}\\right)$。\nInvariant-guided Customization 上面的优化目标已经可以最大化 $I\\left(\\mathrm{Z}_I, \\mathrm{~A}\\right)$以及最小化 $I\\left(\\mathrm{Z}_I, \\mathrm{Z}_V\\right)$。最后还有一项，需要在给定 $Z_I$的情况下， $Z_V$不会对架构的选择产生影响，即最小化条件互信息 $I\\left(\\mathrm{~A}, \\mathrm{Z}_V \\mid \\mathrm{Z}_I\\right)$。具体来说，首先用不变pattern $Z_I$，基于架构预测器 $\\psi_I$来预测架构 $A_I$。并且用 $Z_I$和 $Z_V$的混合通过辅助预测器 $\\psi_E$来预测架构为 $A_E$：\n$$ \\mathrm{A}_I=\\psi_I\\left(\\mathrm{Z}_I\\right), \\quad \\mathrm{A}_E=\\psi_E\\left(\\mathrm{Z}_I, \\mathrm{Z}_V\\right) . $$\n然后遍历所有图数据，优化目标是使得 所有$A_I$和 $A_E$的差异尽可能小，也就是加上 $Z_V$后，对架构的预测改变要尽可能小：\n$$ \\begin{aligned}\\mathcal{L}_{\\mathrm{inv}} \u0026 =\\sum_i^{||\\mathcal{D}||} \\sum_j^{||\\mathcal{D}||}\\left|\\left|\\mathrm{A}_{I, i}-\\mathrm{A}_{E,(i, j)}\\right|\\right|, \\\\ \\text { s.t. } \\quad \\mathrm{A}_{I, i} \u0026 =\\psi_I\\left(\\mathrm{z}_{I, j}\\right), \\mathrm{A}_{E, i, j}=\\psi_E\\left(\\mathrm{z}_{I, i}, \\mathrm{z}_{V, j}\\right),\\end{aligned} $$\n架构的预测的任务目标是使得最后一层输出 $\\mathrm{H}^{(L)}$ 可以做出最好的预测：\n$$ \\mathcal{L}_{\\text {task }}=\\ell\\left(F_{\\psi\\left(\\mathrm{Z}_I\\right)}(\\mathrm{G}), \\mathrm{y}\\right) . $$\nAutoGFM的最终loss为：\n","wordCount":"467","inLanguage":"en","datePublished":"2025-10-26T13:59:35+08:00","dateModified":"2025-10-26T13:59:35+08:00","author":{"@type":"Person","name":"JhuoW"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://JhuoW.github.io/posts/2025-10-26-autogfm/"},"publisher":{"@type":"Organization","name":"JhuoW‘s Notes","logo":{"@type":"ImageObject","url":"https://JhuoW.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://JhuoW.github.io/ accesskey=h title="JhuoW's Notes (Alt + H)"><img src=https://JhuoW.github.io/apple-touch-icon.png alt=logo aria-label=logo height=35>JhuoW's Notes</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></span></div><ul id=menu><li><a href=https://JhuoW.github.io/about/ title=About><span>About</span></a></li><li><a href=https://JhuoW.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://JhuoW.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://JhuoW.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://JhuoW.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://JhuoW.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://JhuoW.github.io/posts/>Posts</a></div><h1 class=post-title>ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes</h1><div class=post-description>ICML2025 "AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization" 阅读笔记</div><div class=post-meta><span title='2025-10-26 13:59:35 +0800 +08'>October 26, 2025</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;JhuoW</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#architecture-inconsistency-in-gfm aria-label="Architecture Inconsistency in GFM">Architecture Inconsistency in GFM</a></li><li><a href=#preliminary aria-label=Preliminary>Preliminary</a><ul><li><a href=#problem-formulation aria-label="Problem Formulation">Problem Formulation</a></li><li><a href=#graph-neural-architecture-search-gnas aria-label="Graph Neural Architecture Search (GNAS)">Graph Neural Architecture Search (GNAS)</a></li></ul></li><li><a href=#autogfm aria-label=AutoGFM>AutoGFM</a><ul><li><a href=#disentangled-contrastive-graph-encoder aria-label="Disentangled Contrastive Graph Encoder">Disentangled Contrastive Graph Encoder</a></li><li><a href=#invariant-guided-architecture-customization aria-label="Invariant-guided Architecture Customization">Invariant-guided Architecture Customization</a></li><li><a href=#invariant-guided-customization aria-label="Invariant-guided Customization">Invariant-guided Customization</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h1><p>GFM旨在实现跨领域和任务之间的知识共享来提升图机器学习，但是现有的GFM依赖于手工设计并且fixed的backbone GNN架构，不能根据任务或者领域来自适应调整最优的GNN backbone架构。对于此问题，本文通过发现跨领域和任务的不变“图-架构”关系（invariant graph-architecture relationship）来解决该问题。什么是invariant graph-architecture relationship，就是不管是什么领域，图和架构之间存在一种不变的关系，什么样的图就应该对应于什么样的架构。这会带来3个挑战：</p><ol><li>如何捕获invariant和variant的pattern，其中invariant pattern指的是可以用来可靠预测图的架构的pattern，variant pattern指的是图中不能用来稳定预测图架构的pattern。<strong>换句话说，invariant pattern指的是图中可以决定架构的固有图结构，可以形成与对应GNN架构之间的一一对应的不变关系，而variant pattern指的是一个可变pattern，他可能对应于各种GNN架构，对于这类pattern，GNN架构是不确定的。</strong> Invariant relationship between graph data and corresponding architecture 指的是一个架构适用于的固有图结构，即一个GNN架构对什么样的图结构一定适用。</li><li>如何为不同的领域和任务调整GFM中的GNN架构。</li><li>如何减轻架构搜索中的数据支配显现（Data domination）。</li></ol><p>AutoGFM的<strong>核心思想</strong>是训练一个架构映射函数 $\pi: \mathcal{G} \to \mathcal{A}$，用于将图数据映射为特定GNN架构。</p><h1 id=architecture-inconsistency-in-gfm>Architecture Inconsistency in GFM<a hidden class=anchor aria-hidden=true href=#architecture-inconsistency-in-gfm>#</a></h1><p>当前GFM模型存在一个架构不一致（Architecture Inconsistency）问题，也就是说，不同领域不同任务的最优架构不一致。这边拿GFT这个foundation model为例，它在预训练图上预训练一个GNN模型，然后基于预训练图的embedding来构造一堆词汇表，然后下游任务的图基于这些预训练好的词汇表来作预测。其他GFM模型也都会在预训练阶段预训练好一个GNN模块。这个GNN模块的架构，比如可能是GCN也可能是GAT，是固定的。但这样就存在一个问题，就是下游任务的图不一定适用于这个固定的GNN架构。</p><p><img loading=lazy src=/posts/2025-10-26-autogfm/1.png#center alt=autogfm></p><h1 id=preliminary>Preliminary<a hidden class=anchor aria-hidden=true href=#preliminary>#</a></h1><h2 id=problem-formulation>Problem Formulation<a hidden class=anchor aria-hidden=true href=#problem-formulation>#</a></h2><p><strong>TAG</strong>：所有图用Text-attributed graph $\mathcal{G}=(\mathcal{V}, \mathcal{E}, \mathcal{R})$来统一所有图，其中 $\mathcal{R}=r_1, \ldots, r_{|\mathcal{R}|}$是关系数量。</p><p><strong>Node of Interest (NOI) Subgraph</strong>：用子图分类任务来统一节点级，边级，图级任务。NOI subgraph $G_h$定义为一个在NOI node周围的子图。用 $S_h(v)=\left\{\mathcal{V}_v^h, \mathcal{E}_v^h, \mathcal{R}_v^h\right\}$表示以节点 $v$为中心的 $h$-hop ego-subgraph。</p><p>节点级：NOI node 就是节点 $v$本身，因此 $\mathcal{T} = {v}$，NOI graph 表示为 $G_h(\mathcal{T}) = S_h(v)$。</p><p>边级：对于一条边 $(v_i,v_j$)，定义 $\mathcal{T} = \{v_i, v_j\}$，该任务的NOI graph为 $G_h\left(\left\{v_i, v_j\right\}\right)=S_h\left(v_i\right) \cup S_h\left(v_j\right)$。</p><p>图级：NOI graph是整个图。</p><p>所有的任务均可以统一成对NOI graph的分类任务。</p><h2 id=graph-neural-architecture-search-gnas>Graph Neural Architecture Search (GNAS)<a hidden class=anchor aria-hidden=true href=#graph-neural-architecture-search-gnas>#</a></h2><p>对于一个图数据 $\mathcal{D} = (\mathcal{G}, \mathcal{Y})$，图架构搜索旨在搜索一个从graph 到 label的函数 $F_{\alpha,w}: \mathcal{G} \to \mathcal{Y}$，其中 $\alpha \in \mathcal{A}$是架构参数， $\mathcal{A}$是架构空间。 $w\in \mathcal{W}$是权重。最优架构指的是，在该GNN架构下，模型的最优参数对图预测的loss最小，是一个bi-level optimization problem。如下图所示，上面的式子表示找到最有架构 $\alpha^*$，满足该架构的最优参数可以使模型与 $\mathcal{Y}$的loss最小。</p><p><img loading=lazy src=/posts/2025-10-26-autogfm/2.png#center alt=autogfm></p><p><strong>Invariant View of Architecture Customization</strong></p><p>The goal is to identify <em><strong>invariant relationships between graph data and the correspond architecture</strong></em>, addressing the issue of <em><strong>architecture inconsistency</strong></em> by tailoring graph neural architecture for each data individually. （不变关系：一个图结构一定对应固定的架构，而不会对应于变化的架构，这样的图结构相对于架构空间称为invariant pattern）。</p><p>基于此，本文构建了4个核心变量：输入图 $G$，架构 $A$，invariant pattern $Z_I$，variant pattern $Z_V$。将图到架构的映射分为2个成分：encoder $\theta: G \to Z_I$和 predictor $\psi: Z_I \to A$。分别从图中提取invariant pattern，以及用invariant pattern预测最适用于该图的架构。</p><p><strong>Assumption</strong>：（1） $Z_I=G \backslash Z_V$， invariant pattern $Z_I$用于可靠预测架构；（2） $Z_V \not \perp A$， $Z_V$虽然不能稳定预测架构，但他并不是与架构相互独立；（3） $A \perp Z_V \mid Z_I$， $\mathrm{A}=\psi\left(\mathrm{Z}_I\right)$，表示给定invariant pattern $Z_I$，架构 $A$的选择不会受到 variant pattern $Z_V$的影响。也就是说如果确定了图中的invariant pattern $Z_I$可以决定该图的架构 $A$，那么其他部分 $Z_V$不应该影响 $Z_I$对架构的选择。</p><p>上面三个假设可以写为下式：</p><p>$$
\max _{\theta, \psi} I\left(\mathrm{Z}_I, \mathrm{~A}\right)-\lambda I\left(\mathrm{Z}_I, \mathrm{Z}_V\right)-\beta I\left(\mathrm{~A}, \mathrm{Z}_V \mid \mathrm{Z}_I\right)
$$</p><p>即 学到的invariant pattern $Z_I$要和架构完全相关，并且与variant pattern分离，同时在 $Z_I$可以确定架构的情况下， $Z_V$不能对架构的选择产生影响。AutoGFM就是要实现该目标。</p><h1 id=autogfm>AutoGFM<a hidden class=anchor aria-hidden=true href=#autogfm>#</a></h1><h2 id=disentangled-contrastive-graph-encoder>Disentangled Contrastive Graph Encoder<a hidden class=anchor aria-hidden=true href=#disentangled-contrastive-graph-encoder>#</a></h2><p><img loading=lazy src=/posts/2025-10-26-autogfm/3.png#center alt=autogfm></p><p>输入是一堆NOI graphs。对于一个NOI graph $G_i$，它的invariant和variant部分需要被disentangle (解纠缠)。Disentangled NOI-graph Encoder用于学习两个channel 的表示：</p><p>$$
\begin{aligned}\mathrm{H}_k^{(l)} & =\mathrm{GNN}_k\left(\mathrm{H}_k^{(l-1)}, \mathbf{A}\right), \quad k=1,2, \\ \mathrm{z}_k & =\mathrm{MLP}_k\left(\mathrm{~h}_k\right) \\ \mathrm{h}_k & =\operatorname{Readout}_k\left(\mathrm{H}_k^{(L)}\right), \quad k=1,2 .\end{aligned}
$$</p><p>这里用两个GNN $\mathrm{GNN}_1$和 $\mathrm{GNN}_2$并行的学习一个图的2个表示 $z_1$和 $z_2$，作为图的invariant表示 $Z_I$和variant表示 $Z_V$。然后，本文提出NOI-graph-level contrastive learning方法来解纠缠的表示可以反应图数据的架构需求。这里要求两个表示被disentangle：</p><p>$$
p_\theta\left(\mathrm{z}_{i, k} \mid \mathrm{G}_i\right)=\frac{\exp \phi\left(\mathrm{z}_{i, k}, \mathrm{p}_k\right)}{\sum_{j=1}^2 \exp \phi\left(\mathrm{z}_{i, k}, \mathrm{p}_j\right)}
$$</p><p>$\mathrm{p}_k$（ $k=1,2$）是第 $k$个表示chunk的prototype，用于表示invariant或variant的<strong>可学习的protontype</strong>，上面的对比函数表示NOI graph $G_i$的表示 $z_{i,1}$要和 $\mathrm{p}_1$相似，$z_{i,2}$要和 $\mathrm{p}_2$相似，而 $z_{i,1}$要和 $\mathrm{p}_2$不相似。以此来区分图中的invariant和variant成分。最大化上面的概率目的是最小化 NOI graph $G_i$ 的 $I\left(\mathrm{Z}_I, \mathrm{Z}_V\right)$。另外，不同NOI graph的invariant representation $Z_I$，需要encourage $Z_I$可以为不同的图数据捕获不同的架构需求，因此对于同一个图的invariant表示 $Z_I$，同一个图的 $Z_I$要相似，不同NOI graph的 $Z_I$要不相似，下面式子用到的 $z$全是 $Z_I$：</p><p>$$
p_\theta\left(s\left(\mathrm{z}_{i, k}\right) \mid \mathrm{G}_i, \mathrm{z}_{i, k}\right)=\frac{\exp \phi\left(\mathrm{z}_{i, k}, \mathrm{z}_{i, k}^{\prime}\right)}{\sum_{j=1}^N \exp \phi\left(\mathrm{z}_{i, k}, \mathrm{z}_{j, k}^{\prime}\right)}
$$</p><p>模型参数 $\theta$的优化目标如下：</p><p>$$
\mathcal{L}_{\text {dis }}=\sum_i-\log \mathbb{E}_{p_\theta\left(\mathrm{z}_{i, k} \mid \mathrm{G}_i\right)} p_\theta\left(s\left(\mathrm{z}_{i, k}\right) \mid \mathrm{G}_i, \mathrm{z}_{i, k}\right)
$$</p><p>旨在区分不同NOI graph的 $Z_I$，使得 $Z_I$可以为不同的图捕获不同的架构需求，同时要让同一个图的invariant和variant表示被区分。</p><h2 id=invariant-guided-architecture-customization>Invariant-guided Architecture Customization<a hidden class=anchor aria-hidden=true href=#invariant-guided-architecture-customization>#</a></h2><p>接下来就是要构建不变表示和图架构之间的映射关系。 Invariant representation $Z_I$要可以映射到正确的架构上，对于一个GFM来说，之前的方法是定义一个GNN backbone，这个工作把backbone定义为 $|O|$个候选backbone的组合 $\{GCN, GAT, GIN, \ldots, SAGE\}$，每个GNN都有自己的参数，被联合训练，如下图所示。</p><p><img loading=lazy src=/posts/2025-10-26-autogfm/4.png#center alt=autogfm></p><p>这些GNN组成的超网络表示为：</p><p>$$
\mathrm{H}^{(l)} \leftarrow \sum_{i=1}^{|\mathcal{O}|} \alpha_{l, i} \mathrm{GNN}_i^{(l-1)}\left(\mathrm{H}^{(l-1)}, \mathbf{A}\right),
$$</p><p>也就是当前NOI graph得到的表示是一堆候选GNN的组合。其中 $\alpha_{l, i}$决定了每个GNN操作对给定数据集的贡献。</p><p>架构预测器（Architecture Predictor）：对于一个图的表示 $z$（不变表示），invariant mapping predictor 定义为 $\psi: z \to \{\alpha_{l,i}\}$。用于将invariant 表示映射为选择每个架构的概率：</p><p>$$
\begin{gathered}\hat{\alpha}_{l, i}=\mathrm{z} \cdot \frac{\mathrm{p}_{l, i}}{\left|\left|\mathrm{p}_{l, i}\right|\right|_2} \\ \alpha_{l, i}=\frac{\exp \left(\hat{\alpha}_{l, i}\right)}{\sum_{j=1}^{|\mathcal{O}|} \exp \left(\hat{\alpha}_{l, j}\right)},\end{gathered}
$$</p><p>其中 $\mathrm{p}_{l, i}$是可学习的prototype，表示第$i$层第$i$个操作的表示，可以看作是architecture representation。若 $\mathrm{H}^{(l)}$可以最好的匹配标签 $\mathcal{Y}$，那么等价于最大化 $I\left(\mathrm{Z}_I, \mathrm{~A}\right)$。</p><h2 id=invariant-guided-customization>Invariant-guided Customization<a hidden class=anchor aria-hidden=true href=#invariant-guided-customization>#</a></h2><p>上面的优化目标已经可以最大化 $I\left(\mathrm{Z}_I, \mathrm{~A}\right)$以及最小化 $I\left(\mathrm{Z}_I, \mathrm{Z}_V\right)$。最后还有一项，需要在给定 $Z_I$的情况下， $Z_V$不会对架构的选择产生影响，即最小化条件互信息 $I\left(\mathrm{~A}, \mathrm{Z}_V \mid \mathrm{Z}_I\right)$。具体来说，首先用不变pattern $Z_I$，基于架构预测器 $\psi_I$来预测架构 $A_I$。并且用 $Z_I$和 $Z_V$的混合通过辅助预测器 $\psi_E$来预测架构为 $A_E$：</p><p>$$
\mathrm{A}_I=\psi_I\left(\mathrm{Z}_I\right), \quad \mathrm{A}_E=\psi_E\left(\mathrm{Z}_I, \mathrm{Z}_V\right) .
$$</p><p>然后遍历所有图数据，优化目标是使得 所有$A_I$和 $A_E$的差异尽可能小，也就是加上 $Z_V$后，对架构的预测改变要尽可能小：</p><p>$$
\begin{aligned}\mathcal{L}_{\mathrm{inv}} & =\sum_i^{||\mathcal{D}||} \sum_j^{||\mathcal{D}||}\left|\left|\mathrm{A}_{I, i}-\mathrm{A}_{E,(i, j)}\right|\right|, \\ \text { s.t. } \quad \mathrm{A}_{I, i} & =\psi_I\left(\mathrm{z}_{I, j}\right), \mathrm{A}_{E, i, j}=\psi_E\left(\mathrm{z}_{I, i}, \mathrm{z}_{V, j}\right),\end{aligned}
$$</p><p>架构的预测的任务目标是使得最后一层输出 $\mathrm{H}^{(L)}$ 可以做出最好的预测：</p><p>$$
\mathcal{L}_{\text {task }}=\ell\left(F_{\psi\left(\mathrm{Z}_I\right)}(\mathrm{G}), \mathrm{y}\right) .
$$</p><p>AutoGFM的最终loss为：</p><p><img loading=lazy src=/posts/2025-10-26-autogfm/5.png#center alt=autogfm></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://JhuoW.github.io/tags/gnn/>GNN</a></li><li><a href=https://JhuoW.github.io/tags/llm/>LLM</a></li></ul><nav class=paginav><a class=prev href=https://JhuoW.github.io/posts/2025-11-08-task-tree/><span class=title>« Prev Page</span><br><span>ICML2025《Towards Graph Foundation Models：Learning Generalities Across Graphs via Task-Trees》 Reading Notes</span>
</a><a class=next href=https://JhuoW.github.io/posts/prodigy-icl/><span class=title>Next Page »</span><br><span>NeurIPS2023《Prodigy：Enabling In-context Learning Over Graphs》 Reading Notes</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes on twitter" href="https://twitter.com/intent/tweet/?text=ICML2025%e3%80%8aAutoGFM%ef%bc%9aAutomated%20Graph%20Foundation%20Model%20with%20Adaptive%20Architecture%20Customization%e3%80%8b%20Reading%20Notes&amp;url=https%3a%2f%2fJhuoW.github.io%2fposts%2f2025-10-26-autogfm%2f&amp;hashtags=GNN%2cLLM"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fJhuoW.github.io%2fposts%2f2025-10-26-autogfm%2f&amp;title=ICML2025%e3%80%8aAutoGFM%ef%bc%9aAutomated%20Graph%20Foundation%20Model%20with%20Adaptive%20Architecture%20Customization%e3%80%8b%20Reading%20Notes&amp;summary=ICML2025%e3%80%8aAutoGFM%ef%bc%9aAutomated%20Graph%20Foundation%20Model%20with%20Adaptive%20Architecture%20Customization%e3%80%8b%20Reading%20Notes&amp;source=https%3a%2f%2fJhuoW.github.io%2fposts%2f2025-10-26-autogfm%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fJhuoW.github.io%2fposts%2f2025-10-26-autogfm%2f&title=ICML2025%e3%80%8aAutoGFM%ef%bc%9aAutomated%20Graph%20Foundation%20Model%20with%20Adaptive%20Architecture%20Customization%e3%80%8b%20Reading%20Notes"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fJhuoW.github.io%2fposts%2f2025-10-26-autogfm%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes on whatsapp" href="https://api.whatsapp.com/send?text=ICML2025%e3%80%8aAutoGFM%ef%bc%9aAutomated%20Graph%20Foundation%20Model%20with%20Adaptive%20Architecture%20Customization%e3%80%8b%20Reading%20Notes%20-%20https%3a%2f%2fJhuoW.github.io%2fposts%2f2025-10-26-autogfm%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share ICML2025《AutoGFM：Automated Graph Foundation Model with Adaptive Architecture Customization》 Reading Notes on telegram" href="https://telegram.me/share/url?text=ICML2025%e3%80%8aAutoGFM%ef%bc%9aAutomated%20Graph%20Foundation%20Model%20with%20Adaptive%20Architecture%20Customization%e3%80%8b%20Reading%20Notes&amp;url=https%3a%2f%2fJhuoW.github.io%2fposts%2f2025-10-26-autogfm%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://giscus.app/client.js data-repo=JhuoW/WebComments data-repo-id=R_kgDOHHz8Ug data-category=Announcements data-category-id=DIC_kwDOHHz8Us4COa5e data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async></script></article></main><footer class=footer><span>Copyright &copy; 2025 <a href=https://JhuoW.github.io/>JhuoW‘s Notes</a></span>
<span></span><br><script>function siteTime(){var h=1e3,r=h*60,i=r*60,n=i*24,x=n*365,e=new Date,d=2019,w=1,_=16,y=19,b=15,C=11,l=e.getFullYear(),O=e.getMonth()+1,f=e.getDate(),p=e.getHours(),g=e.getMinutes(),v=e.getSeconds(),m=Date.UTC(d,w,_,y,b,C),j=Date.UTC(l,O,f,p,g,v),t=j-m,o=Math.floor(t/x),s=Math.floor(t/n-o*365),a=Math.floor((t-(o*365+s)*n)/i),c=Math.floor((t-(o*365+s)*n-a*i)/r),u=Math.floor((t-(o*365+s)*n-a*i-c*r)/h);d==l?document.getElementById("sitetime").innerHTML="本站已运行 "+s+" 天 "+a+" 小时 "+c+" 分钟 "+u+" 秒":document.getElementById("sitetime").innerHTML="本站已运行 "+o+" 年 "+s+" 天 "+a+" 小时 "+c+" 分钟 "+u+" 秒"}setInterval(siteTime,1e3)</script><span id=sitetime>载入运行时间...</span>
<script type=text/javascript id=clustrmaps src="//cdn.clustrmaps.com/map_v2.js?cl=080808&w=268&t=tt&d=YsONH-MzO6L7yrkA73Z_QW7LuMTfdUhk0uhb_KaBv-g&co=f5f5f5&cmo=3acc3a&cmn=ff5353&ct=808080"></script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>