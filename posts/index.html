<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script type=text/javascript async src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var t=MathJax.Hub.getAllJax(),e;for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><title>Posts | JhuoW‘s Notes</title><meta name=keywords content><meta name=description content="Posts - JhuoW‘s Notes"><meta name=author content="JhuoW"><link rel=canonical href=https://JhuoW.github.io/posts/><meta name=google-site-verification content="G-6F49SGED6V"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><link rel=preload href=/apple-touch-icon.png as=image><link rel=icon href=https://JhuoW.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://JhuoW.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://JhuoW.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://JhuoW.github.io/apple-touch-icon.png><link rel=mask-icon href=https://JhuoW.github.io/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://JhuoW.github.io/posts/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-6F49SGED6V"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6F49SGED6V",{anonymize_ip:!1})}</script><meta property="og:title" content="Posts"><meta property="og:description" content="Jhuo’s Notes"><meta property="og:type" content="website"><meta property="og:url" content="https://JhuoW.github.io/posts/"><meta property="og:image" content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="JhuoW"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Jhuo’s Notes"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://JhuoW.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://JhuoW.github.io/ accesskey=h title="JhuoW's Notes (Alt + H)"><img src=https://JhuoW.github.io/apple-touch-icon.png alt=logo aria-label=logo height=35>JhuoW's Notes</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://JhuoW.github.io/about/ title=About><span>About</span></a></li><li><a href=https://JhuoW.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://JhuoW.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://JhuoW.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://JhuoW.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://JhuoW.github.io/gallery/ title=Gallery><span>Gallery</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://JhuoW.github.io/>Home</a></div><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2>WWW2022 《ClusterSCL：Cluster-Aware Supervised Contrastive Learning on Graphs》 Reading Notes</h2></header><section class=entry-content><p>paper
Introduction 对于监督对比学习（Supervised Contrastive Learning, SupCon）, SupCon loss旨在表示空间中拉近属于同一个class的数据点，分离不同类的数据点。 但是SupCon难以处理高类内方差，类间相似度较大的数据集。为了解决该问题，本文提出了Cluster-aware supervised contrastive learning loss (ClusterSCL)。什么是高类内方差，高跨类相似度问题？如图1(a)所示，节点$u_1$和$u_3$ 是同类节点，$u_2$和$u_4$是同类节点。他们是同类节点但在不同的社区中，所以类内方差较大，即同一个类内的节点跨越了多个community。 另外$u_1$和$u_2$， $u_3$和$u_4$，是不同类的节点对， 但他们处在同一个社区中，导致在MPNN过程中，这些处在同一个community中的不同类节点被拉近，导致跨类相似度较高的问题。
如果对节点$u_2$计算SupCon时，如图1(b)所示，SupCon会使得同类节点被拉近，如$u_2$和$u_4$会被拉近。但是$u_3$和$u_4$处在同一个社区中（structurally similar）那么MPNN会使得$u_3$和$u_4$被拉近，所以SupCon在拉近$u_2$和$u_4$的同时，会间接拉近不同类节点$u_2$和$u_3$。同时，对于构成negative pairs的不同类节点，例如$u_1$和$u_2$，SupCon会推远$u_1$和$u_2$，但是$u_1$和$u_5$ structurally similar, 因此会推远$u_1$和$u_2$会间接导致$u_2$和$u_5$这两个同类节点被推远。因此对于一个cluster内节点不同类，且不同cluster中存在同类节点的情况，会导致复杂的决策边界，即在拉近同类但不同社区的节点时，也会间接拉近不同类不同社区的节点。在推远不同类同社区的节点时，也可能间接推远同类同社区的节点。
为了解决上述问题，最直接的方法是对于每个cluster，如图1(a)的Community 1，不考虑其他cluster，只对当前cluster内节点做SupCon。但是这么做忽略了跨cluster的同类节点交互，如$u_1$和$u_3$，$u_2$和$u_4$，这些跨cluster的positive pairs可能包含有益的信息。为了解决这个问题，本文提出cluster-aware data augmentation (CDA) 聚类感知的数据增强，来为每个节点生成augmented positives and negatives，如图1(b)中ClusterSCL所示。对于每个节点$u$，为它生成positive 和negative samples, 生成的samples 位于或接近$u$所在的cluster。Recall SupCon存在的问题：
SupCon会使得$u_2$和$u_4$被拉的太近，从而间接导致$u_2$和$u_3$被拉近，所以对于high intra-class variances，要求不同cluster的同类节点如$u_2$和$u_4$不要被拉太近； SupCon会使得$u_1$和$u_2$被推远，从而间接导致$u_2$和$u_5$被推远，所以对于high inter-class similarity，要求同一个cluster内的不同类节点如$u_1$和$u_2$不要被拉的太远。 Method Two stage training with Supervised Contrastive Loss SupCon encourages samples of the same class to have similar representations, while pushes apart samples of different classes in the embedding space....</p></section><footer class=entry-footer><span title="2022-11-17 01:33:20 +0800 CST">November 17, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to WWW2022 《ClusterSCL：Cluster-Aware Supervised Contrastive Learning on Graphs》 Reading Notes" href=https://JhuoW.github.io/posts/clusterscl/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2022 《Graph Condensation for Graph Neural Networks》 Reading Notes</h2></header><section class=entry-content><p>paper
Introduction 本文提出图浓缩技术（Graph Condensation），旨在将大图浓缩为一个小图，使得在小图上训练的GNN可以得到和大图相当的效果。通过优化gradient matching loss来模拟GNN在原图上的训练轨迹，从而解决图浓缩问题。
通常有两个策略来简化图：Graph Sparsification(图稀疏化)和Graph Coarsening(图粗化)。图稀疏化通过减少边数来近似一个图； 图粗化旨在减少节点数量。（1）当节点具有属性特征时，由于稀疏化不会减少节点数量，因此属性量不会减少。 （2）图粗化的目的是保存一些图属性比如主特征值，这可能对下游任务不是最优的保存属性。
本文提出图浓缩，来学习生成图的结构和节点属性，从这两方面同时进行浓缩。对于Reddit数据集，GCond可以将节点数浓缩至0.1%，并且在浓缩图上可以得到和原图相当的效果。如下图所示：
本文解决了图浓缩面临的两个挑战：1. 构建目标函数， 2. 参数化可学习的节点特征和图结构。为了解决上述挑战，本文使用gradient matching loss来匹配每一个training step上原图与浓缩图的GNN参数梯度，使得GNN在浓缩图上的训练趋势与原图相匹配。为了参数化节点特征和图结构，本文将浓缩图的Feature Matrix设为自由参数矩阵，将浓缩图结构设为关于Feature matrix 的 函数（基于结构与特征相关联假设），使得计算开销降低。
Methodology A graph $\mathcal{T}=\{\mathbf{A}, \mathbf{X}, \mathbf{Y}\}$，其中$\mathbf{X} \in \mathbb{R}^{N \times d}$是$d$维节点特征，$\mathbf{Y} \in\{0, \ldots, C-1\}^N$ 表示$N$个节点的labels，共有$C$个class。图浓缩旨在学习一个小的生成图$\mathcal{S}=\left\{\mathbf{A}^{\prime}, \mathbf{X}^{\prime}, \mathbf{Y}^{\prime}\right\}$，其中$\mathbf{A}^{\prime} \in \mathbb{R}^{N^{\prime} \times N^{\prime}}$是浓缩图的邻接矩阵，$\mathbf{X}^{\prime} \in \mathbb{R}^{N^{\prime} \times D}$是浓缩图的特征矩阵，$\mathbf{Y}^{\prime} \in\{0, \ldots, C-1\}^{N^{\prime}}$是浓缩图的node labels 其中$N^{\prime} \ll N$，特征维度从$d$变为$D$。图浓缩的目标是基于原图训练过程学习浓缩图$\mathcal{S}$，使得在$\mathcal{S}$上训练的GNN应用在原图上的loss最小： $$ \min_{\mathcal{S}} \mathcal{L}\left(\mathrm{GNN}_{\boldsymbol{\theta}_{\mathcal{S}}}(\mathbf{A}, \mathbf{X}), \mathbf{Y}\right) \quad \text { s.t } \quad \boldsymbol{\theta}_{\mathcal{S}}=\underset{\boldsymbol{\theta}}{\arg \min } \mathcal{L}\left(\mathrm{GNN}_{\boldsymbol{\theta}}\left(\mathbf{A}^{\prime}, \mathbf{X}^{\prime}\right), \mathbf{Y}^{\prime}\right), $$ Outer：固定GNN参数，优化小图。 Inner: 固定小图，在小图上训练GNN参数。...</p></section><footer class=entry-footer><span title="2022-09-01 10:47:21 +0800 CST">September 1, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2022 《Graph Condensation for Graph Neural Networks》 Reading Notes" href=https://JhuoW.github.io/posts/gcond/></a></article><article class=post-entry><header class=entry-header><h2>MLP and GNNs</h2></header><section class=entry-content><p>最近一些工作通过解耦Message-Passing 和 Feature Learning的方式来提升GNN的可拓展性，这里对一小部分相关工作做一个小总结。
1. Combining Label Propagation and Simple Models Out-performs Graph Neural Networks （ICLR2021） 模型首先忽略图结构，用简单模型（MLP），只使用节点特征预测label：
$$ \min \sum_{i \in L_{t}} \ell\left(f\left(x_{i}\right), y_{i}\right) $$ 考虑一个inductive bias：预测误差与邻近度关系强相关，对图中所有节点的误差做校正。
具体来说，首先计算一个初始的误差矩阵$E$，其中训练集误差如下 $$ E_{L_{t},:}=Y_{L_{t},:}-Z_{L_{t},:} $$ 其他节点的误差未知：$E_{L_{v},:}=0, \quad E_{U,:}=0$。然后通过Label Propagation将误差矩阵在图上做平滑，使得相邻节点的误差相似：
$$ \hat{E}=\underset{W \in \mathbb{R}^{n \times c}}{\arg \min } \operatorname{trace}\left(W^{T}(I-S) W\right)+\mu||W-E||_{F}^{2} $$ 由此得到所有节点的误差矩阵$\hat{E}$。然后用$\hat{E}$对基础MLP预测做校正，这个post-processing过程不涉及训练参数，校正后的预测为： $$ Z^{(r)} = Z + \hat{E} $$ 考虑homophily：校正的预测label要满足相邻节点label相似。 注意，这里不直接对$Z^{(r)}$做Label Propagation，而是构造了一个label矩阵$H \in \mathbb{R}^{n \times c}$，其中将训练集真实label和验证+测试集校正label加入$H$中，然后对$H$做label propagation： $$ \begin{aligned} H_{L_{t},:}&=Y_{L_{t},:} \\ H_{L_{v} \cup U,:}&=Z_{L_{v} \cup U,:}^{(r)} \end{aligned} $$ Label Prop: $$ H^{(t+1)}=(1-\alpha) H+\alpha S H^{(t)} $$ 最后直接用收敛的$H$做预测，即$\hat{Y} = H^{\infty}$，node $i$ 的预测class为： $$ y_i = \arg \max _{j \in\{1, \ldots, c\}} \hat{Y}_{i j} $$...</p></section><footer class=entry-footer><span title="2022-08-27 00:00:00 +0000 UTC">August 27, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to MLP and GNNs" href=https://JhuoW.github.io/posts/glnn/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2021 《Combining Label Propagation and Simple Models Out-performs Graph Neural Networks》 Reading Notes</h2></header><section class=entry-content><p>paper
Introduction 本文研究了结合更简单的模型来处理transductive node classification任务。 主要包括1个预测模块和两个后处理（post-processing）模块：
Base predictor：忽略图结构，用简单模型（如MLP或线性模型）使用节点特征预测label Error correction：校正步骤，将训练数据中的不确定性（误差）传播到图上，来校正Base predictor的预测 Smoothing：在图上平滑预测 其中只有第一步base predictor的参数是可学习的，即涉及图结构的操作（Correction和Smoothing）无需参数学习，这种简单的模型使得参数数量减少了几个数量级，训练时间也减少了几个数量级，并且可以轻松扩展到大规模图。
相比于过去的GNN+LP的方法，C&S更加高效：1）C&S首先只使用节点特征进行低成本的base prediction；2）然后再使用标签传播对基础预测进行校正 ；3）最后对最终预测进行平滑。 第一步是预测操作，后两部是后处理操作，也就是第一步为一个独立的端到端模型，后两部基于一个inductive bias来调整节点的表示。即homophily假设：相连节点的误差和label是相似的（正相关）。训练节点的误差和它相连节点的误差应相似，那么就用训练节点的误差来校正邻居节点。
因此，将标签更加直接的整合到GNN的学习算法中是本文性能的关键，并且发现LP与node features是相互互补的信号。实验表明，在OGB-Products上，参数量比GNN少了2个数量级，训练时间也减少2个数量级。
Correct and Smooth (C&S) Model 给定无向图$G=(V,E)$，$A$为邻接矩阵，$S=D^{-1 / 2} A D^{-1 / 2}$为归一化邻接矩阵。节点集划分为labeled nodes $V_L$和unlabeled nodes $V_U$，其中$V = V_L \cup V_U$。进一步，labeled nodes可以分为训练节点集$V_{L_t}$和验证节点集$V_{L_v}$。训练集和验证集的label分别为$Y_{L_t:}$和$Y_{L_v:}$， 每行为label的one-hot向量。
Simple Base Predictor $$ \min \sum_{i \in L_{t}} \ell\left(f\left(x_{i}\right), y_{i}\right) $$
$f(\cdot)$为简单的训练模型+softmax，如浅层MLP， $\ell$为cross-entropy loss。 基于训练节点$V_{L_t}$特征的模型$f$可以得到输出预测$Z \in \mathbb{R}^{n\times c}$， 其中$Z$的每行是softmax得到的分类概率分布。Simple Base Predictor是一个独立训练的端到端模型。
Correcting Base Prediction with Error Correlation (使用邻居误差关联来纠正基础预测） 通过融合标签信息来提高base prediction $Z$的准确率。 本文期望base prediction中的误差沿着图中的边正相关，即节点$i$出的预测误差在它的邻居处也会出现相似的误差。为了实现这个目的，首先定义一个误差矩阵$E \in \mathbb{R}^{n \times c}$用来保存每个节点的预测误差，其中误差为训练数据集上的残差（只有训练节点由误差）其他没有训练过程中不知道label的节点误差设为0： $$ E_{L_{t},:}=Y_{L_{t},:}-Z_{L_{t},:} \quad 为训练集节点 V_{L_t}的误差 $$...</p></section><footer class=entry-footer><span title="2022-07-11 09:42:15 +0800 CST">July 11, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2021 《Combining Label Propagation and Simple Models Out-performs Graph Neural Networks》 Reading Notes" href=https://JhuoW.github.io/posts/c_and_s/></a></article><article class=post-entry><header class=entry-header><h2>ICLR2022 《GLASS：GNN with Labeling Tricks for Subgraph Representation Learning》 Reading Notes</h2></header><section class=entry-content><p>Paper
Introduction SubGNN在学习子图representation时保留子图的三种属性：Position，Neighborhood，Structure，每种属性包含Internal 和Border两方面，并且要精心设计不同的anchor patch，所以过于复杂。通过分析SubGNN和普通GNN，作者发现子图表示的核心可能是区分子图内部和外部节点。基于此发现，本文提出了一种labeling trick, 即max-zero-one，来提升子图GNN的表达能力和可拓展性。
Subgraph representation task 如上图所示，目标子图$\mathbb{S}$被嵌入在整个图中，并且可能拥有多个连通分量，目标是学习子图的表示向量，使其可以预测子图的属性。NeurIPS2020文章SubGNN提出子图级message-passing来代替节点级的message passing，并且设计了三个message passing通道，每个通道分为内部和边界模块，分别捕获子图分量间的交互，以及子图与图的其他部分之间的交互。尽管取得了比普通GNN更好的效果，但是SubGNN需要繁琐的预计算，因为SubGNN通过不同采样规则的anchor patch来传递子图分量之间，以及子图分量与图其他部分之间的相关性，而三个通道共6个aspects需要不同的采样规则，以及各自的message passing，计算十分冗长（这里有解读）。另外 SubGNN对每个aspects需要使用不同的anchor patch随机采样策略，无法保证采样的anchor patch是最优的，因此效果的方差较大，使得鲁棒性堪忧。
通过对比SubGNN相较于普通GNN的优势，作者发现对于子图任务来说，区分子图内部节点和外部节点非常重要。基于这个发现，本文提出了一种labeling trick，即max-zero-one labeling trick，来标注每个节点是否在子图外或者子图内。
Labeling Trick [1]: 使用GNN生成multi-node representations （即，为一组节点，例如子图生成表示向量），该方法说明了为高阶结构生成有表达能力的representation，需要捕获结构内不同节点间的交互。在实现上，labeling trick通过一个专门设计的label来表示节点的结构特征，这个label与node feature 结合作为新的feature输入GNN中。
注： 本文只考虑诱导子图，即每个子图的每个连通分量保留原图中的所有边。
Plain GNN and SubGNN 如上图所示，$G$是一个regular graph, 所以在没有节点feature的情况下，每个节点的embedding相同，所以GNN无法区分子图$\mathcal{S}$和$\mathcal{S}^\prime$。如下图所示，Plain GNN 在message passing中子图$\mathcal{S}$内部节点1同时接收来自子图内和子图外的邻居信息，并不会加以区分。同样$\mathcal{S}^\prime$中节点3也同时接收子图内外节点，因此对于Plain GNN ，它无法区分节点1和3，因此无法区分两个子图。
而SubGNN引入了3个通道：position (P)，neighborhood (N), 和structure (S) 每个通道分别学习Internal 和Border两方面，共6个属性融入子图表示学习中。对于子图$\mathcal{S}$，为了捕获某个通道$i$的属性，SubGNN首先随机采样$n_A$个anchor patches： $\mathbb{A}_{i}=\left\{\mathcal{A}_{i}^{(1)}, \ldots, \mathcal{A}_{i}^{\left(n_{A}\right)}\right\}$，然后学习$\mathcal{S}$中的每个连通分量在这个属性$i$下的表示向量，通过子图内部连通分量和anchor patches之间的消息传递，来捕获子图内部连通分量的相对位置/邻域/结构信息，以及子图连通分量相对于子图外部分的位置/邻域/结构信息。如图2右边所示。对于通道$i$，它的Internal和border两方面采样的anchor patches表示为$\mathbb{A}_{i}=\left\{\mathcal{A}_{i}^{(1)}, \ldots, \mathcal{A}_{i}^{\left(n_{A}\right)}\right\}$，对于子图$\mathcal{S}$的一个连通分量$\mathcal{S}^{(c)}$，要学习该连通分量的表示，可使用一下subgraph-level message passing layer: $$ \begin{aligned} &\boldsymbol{a}_{i, \mathcal{S}^{(c)}}=\sum_{\mathcal{A}_{i} \in \mathbb{A}_{i}} \gamma_{i}\left(\mathcal{S}^{(c)}, \mathcal{A}_{i}\right) \boldsymbol{g}_{\mathcal{A}_{i}}, \\ &\boldsymbol{h}_{i, \mathcal{S}^{(c)}}^{(k)}=\sigma\left(W_{i} \cdot\left[\boldsymbol{a}_{i, \mathcal{S}^{(c)}}, \boldsymbol{h}_{i, \mathcal{S}^{(c)}}^{(k-1)}\right]\right) \end{aligned} $$ 其中$\gamma_{i}\left(\mathcal{S}^{(c)}, \mathcal{A}_{i}\right)$是子图分量$\mathcal{S}^{(c)}$和一个anchor patch $\mathcal{A}_{i}$的相似度。即每个子图分量依照与anchor patch 的相似度聚合来自anchor的信息。由于相似度函数的存在，SubGNN实际上是使用与子图分量$\mathcal{S}^{(c)}$接近或结构相似的anchor patch对$\mathcal{S}^{(c)}$的representation做平滑，即$\mathcal{S}^{(c)}$聚合更多与它结构相似的anchor patches的信息。通过精心设计的anchor和subgraph-level message passing，6个属性可以被各自保留，然后在融合。...</p></section><footer class=entry-footer><span title="2022-06-09 23:01:07 +0800 CST">June 9, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to ICLR2022 《GLASS：GNN with Labeling Tricks for Subgraph Representation Learning》 Reading Notes" href=https://JhuoW.github.io/posts/glass/></a></article><article class=post-entry><header class=entry-header><h2>NeurIPS2020 《Subgraph Neural Networks》 Reading Notes</h2></header><section class=entry-content><p>paper
Introduction GNN通常关注节点级任务和图级任务，缺少针对子图级预测任务的方法。针对这个问题，本文提出SubGNNs用于解耦子图在不同结构aspect的表示。为了学习准确的子图表示，SubGNN在子图的连通分量和随机采样的anchor patches之间进行消息传递，从而学习高准确度的子图表示。SubGNN指定了三个通道，每个通道捕获子图不同的拓扑结构属性。
从拓扑的角度来看，子图是非常具有挑战性的结构，对子图的预测存在以下挑战：
如要对更大且size不同的子图做联合预测，挑战在于如何表征含有多个分量，甚至分量间间隔较远的子图。 子图包含了高阶连通模式（connectivity patterns），这些连通模式不仅存在于子图内节点之间，也存在与子图内节点与子图外部节点之间， 挑战在于如何将子图边界信息和子图外部信息注入GNN中。 子图可能存在于图中的一个特定区域，也可能它的连通分量分布于多个局部邻域，挑战在于如何学习子图在图中的位置。 子图间共享边（sharing edges）和非边（non-edges）存在相关性，挑战在于如何将这种子图间的依赖融合进模型中，同时任然能够将特征信息考虑在内进行辅助归纳推理。 本文提出SubGNN以解决上述挑战， SubGNN的核心原则是子图级的消息传递，可以捕获子图位置、邻域、结构三种特征
Formulating Subgraph Prediction 给定无向图$G=(V,E)$，它的一个子图表示为$S=\left(V^{\prime}, E^{\prime}\right)$，每个子图$S$有一个label $y_{S}$，并且子图$S$可能包含多个连通分量，连通分量表示为$S^{(C)}$。
Problem (Subgraph Representations and Property Prediction) 给定子图集合 $\mathcal{S} = \left\{S_{1}, S_{2}, \ldots, S_{n}\right\}$，SubGNN $E_S$为每个子图$S\in \mathcal{S}$生成一个$d_s$维的表示向量$\mathbf{Z}_S \in \mathbb{R}^{d_{s}}$， 然后用这些子图的表示向量学习一个子图分类器 $f: \mathcal{S} \rightarrow\{1,2, \ldots, C\}$，使得输入子图得到预测label: $f(S)=\hat{y}_{S}$。
本文针对子图分类任务，所提出的模型为一个可学习的embedding函数$E_{S}: S \rightarrow \mathbb{R}^{d_{s}}$， 将每个子图映射为低维表示向量，这些表示向量可以捕获子图拓扑对预测重要的aspects。具体来说，对于一个子图，message再它的连通分量之间传递，这使得我们可以对多个连通分量的子图学习有意义的表示。
SUBGNN: Properties of subgraph topology 子图拥有独特的内部结构，边界连通性，邻域概念，以及和图其他部分的相对位置。直觉上，我们的目标是以最大的似然保存保存特定的图属性。本文设计模型以考虑6种特定的图结构属性：
具体来说：
(1) Position.
Border Position: 该属性保留子图和图的其他部分之间的距离，通过这种距离关系，可以区分两个同构但处于不同位置的子图。
Internal Position：子图自己连通分量之间的距离。
(2) Neighborhood.
Border Neighborhood：为子图的边界邻域，表示子图$S$中任意节点的$k$跳邻域中（不属于子图$S$）的节点集合。
Internal Neighborhood：子图内每个连通分量的边界邻域，每个连通分量$S^{(c)}$中任意节点的$k$跳邻域中（不属于子图$S^{(c)}$）的节点集合。...</p></section><footer class=entry-footer><span title="2022-05-27 17:13:33 +0800 CST">May 27, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to NeurIPS2020 《Subgraph Neural Networks》 Reading Notes" href=https://JhuoW.github.io/posts/subgnn/></a></article><article class=post-entry><header class=entry-header><h2>NeurIPS2021 《Decoupling the Depth and Scope of Graph Neural Networks》 Reading Notes</h2></header><section class=entry-content><p>paper
Introduction 现有的GNN在图和模型的size方面可拓展性有限。 对于大图，增加模型的深度对导致scope(感受野)大小成指数放大。深层model主要面临两个基本挑战： 1. oversmoothing导致表达能力下降，2. 邻域爆炸导致计算成本高昂。
本文旨在结构GNN的depth 和 scope，首先提取子图作为有限大小（bounded-size）的scope, 然后将任意深度的GNN用于子图上。 由于提取出的局部子图是由少量关键邻居组成，且排除了不相关的邻居，所以深层GNN也可以学到informative representations。
增加GNN层数会造成以下基本障碍：
Expresivity (oversmoothing): 邻居的迭代混合导致不同节点的切入向量收敛到一个固定的低维子空间 Scalability (neighbor explosion): 多跳邻居递归导致感受野大小呈指数级增长 为了研究导致表达能力和可拓展性缺陷的根本原因，本文提出了以下insight:
Two views on the graph: 如果从全局视角来看两个节点，如果两个节点在同一个图的同一个连通分量中，那么这两个节点在随机游走中存在到达概率，无论他们间隔多远。而本文给出了图的局部视角，具体来说， 给定节点$v$的局部子图$\mathcal{G}_{[v]}$，将$\mathcal{G}_{[v]}$仅包含节点$v$的特性，整个图看一看做所有子图$\mathcal{G}_{[v]}$的集合。那么$v$的邻域不在是所有节点$\mathcal{V}$，而它的邻域只存在于$\mathcal{V}_{[v]}$中。 如果节点$u$不在$\mathcal{V}_{[v]}$中，$u$将永远不会被考虑为$v$的邻居，无论GNN有多深。
Scope of GNNs: 加深GNN层次所造成的的表达能力和可拓展性问题都和GNN不断扩大的感受野（scope）有关。随着层次变深，感受野不断变大，使得每个节点包含的信息重叠越多，最终收敛到同一个子空间，导致oversmoothing; 另外 感受野变大，导致每个节点的邻居数呈指数级上升，导致邻居爆炸。所以GNN的层数加深会导致感受野变大（耦合），即$L$层GNN的感受野为全部$L$-hop以内的邻居，层数深度（depth）和感受野大小(scope)的强耦合限制了GNN的设计。
Decoupling the GNN depth and scope: 为了解耦GNN的深度（depth）与感受野(scope)，使得加层数与感受野无关。对于节点$v$，首先为它提取一个小的子图$\mathcal{G}_{[v]}$，然后在小的子图上应用任意层数的GNN。若GNN的层数$L^\prime$大于感受野的跳数，那么子图中的每对节点会交换多次信息，额外的消息传递有助于GNN更好的融合scope内的信息，从而增强表达能力。
Decoupling the Depth and Scope of GNNs Definition (Depth of subgraph) ：假设子图$\mathcal{G}_{[v]}$是连通的，$\mathcal{G}_{[v]}$的depth定义为$\max _{u \in \mathcal{V}_{[v]}} d(u, v)$, 其中$d(u, v)$表示$u$到$v$的最短路径。
本文提出shaDow-GNN，它包含了一个子图提取器$\text { EXTRACT}$。 shaDow-GNN的过程如下：
用子图提取器$\operatorname{EXTRACT}(v, \mathcal{G})$为节点$v$提取一个连通子图$\mathcal{G}_{[v]}$，子图的深度（距离$v$最远的节点和$v$之间的跳数）为$L$。 构建一个$L^\prime$层的GNN并应用在$\mathcal{G}_{[v]}$上。 如果 $L^\prime > L$那么可以反映decoupling，因为GNN层数此时与scope无关，层数加深不会影响感受野。 本文从三个不同的角度理论证明了shaDow-GNN可以提升GNN的表达能力。...</p></section><footer class=entry-footer><span title="2022-05-21 00:00:00 +0000 UTC">May 21, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;JhuoW</footer><a class=entry-link aria-label="post link to NeurIPS2021 《Decoupling the Depth and Scope of Graph Neural Networks》 Reading Notes" href=https://JhuoW.github.io/posts/decouplinggcn/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://JhuoW.github.io/posts/page/2/>Next Page »</a></nav></footer></main><footer class=footer><span>Copyright &copy; 2022 <a href=https://JhuoW.github.io/>JhuoW‘s Notes</a></span>
<span></span><br><script>function siteTime(){var u=1e3,r=u*60,a=r*60,n=a*24,x=n*365,e=new Date,d=2019,O=1,w=16,_=19,y=15,m=11,l=e.getFullYear(),C=e.getMonth()+1,f=e.getDate(),p=e.getHours(),g=e.getMinutes(),v=e.getSeconds(),b=Date.UTC(d,O,w,_,y,m),j=Date.UTC(l,C,f,p,g,v),s=j-b,o=Math.floor(s/x),t=Math.floor(s/n-o*365),i=Math.floor((s-(o*365+t)*n)/a),c=Math.floor((s-(o*365+t)*n-i*a)/r),h=Math.floor((s-(o*365+t)*n-i*a-c*r)/u);d==l?document.getElementById("sitetime").innerHTML="本站已运行 "+t+" 天 "+i+" 小时 "+c+" 分钟 "+h+" 秒":document.getElementById("sitetime").innerHTML="本站已运行 "+o+" 年 "+t+" 天 "+i+" 小时 "+c+" 分钟 "+h+" 秒"}setInterval(siteTime,1e3)</script><span id=sitetime>载入运行时间...</span>
<script type=text/javascript id=clustrmaps src="//cdn.clustrmaps.com/map_v2.js?cl=080808&w=268&t=tt&d=YsONH-MzO6L7yrkA73Z_QW7LuMTfdUhk0uhb_KaBv-g&co=f5f5f5&cmo=3acc3a&cmn=ff5353&ct=808080"></script>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>