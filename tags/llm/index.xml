<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LLM on JhuoW‘s Notes</title>
    <link>https://JhuoW.github.io/tags/llm/</link>
    <description>Recent content in LLM on JhuoW‘s Notes</description>
    <image>
      <url>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://JhuoW.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 May 2025 14:22:08 +0800</lastBuildDate><atom:link href="https://JhuoW.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>KDD2023《All in One：Multi-Task Prompting for Graph Neural Networks》 Reading Notes</title>
      <link>https://JhuoW.github.io/posts/allinone/</link>
      <pubDate>Tue, 20 May 2025 14:22:08 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/allinone/</guid>
      <description>KDD2023 &amp;#34;All in One：Multi-Task Prompting for Graph Neural Networks&amp;#34; 阅读笔记</description>
      <content:encoded><![CDATA[<p>图神经网络的预训练任务和下游任务之间可能存在较大gap，直接将预训练模型应用在下游任务上可能会产生负迁移现象（“negative transfer”）。例如，binary edge prediction经常用于pretrain graph model。这样的预训练模型使得有边连接的节点在representation space中接近。但是下游任务可能是node-level 或graph-level tasks，下游的任务如果是节点分类任务，那么预训练模型需要针对额外的节点类别标签搜索更高维度的参数空间。如果图中相连节点的类别不同（heterophilic），那么基于edge prediction pretrained的模型会对下游任务参数负面效果。</p>
<p>为了解决上述问题，一个潜在的方向是将“pretraining and fine-tuning”拓展为“pretraining, <strong>prompting</strong>, and fine-tuning”。例如在自然语言处理中，如果要赋予预训练语言模型预测句子情感的能力（sentiment analysis），可以通过prompt来完成，而不需要优化pretrained model。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/image.png#center" alt="你想输入的替代文字"  />
</p>
<p>以上图为例，对于一个fronzen LLM（参数固定），如果要为这个模型赋予情感分析的能力，我们可以额外训练一个最佳的prompt，训练数据为prompt parameters，要求这个prompt tokens在tasker $\phi$的优化下，生成的下一个token是正确的情感（label为excited）。即训练得到一个最佳的prompt tokens，比如训练得到的最佳prompt tokens是“I feel so [mask]”，使得frozen LLM应用在“KDD2023 will witness many high-quality papers. I feel so ” 这个句子上时，可以将下一个词预测为情感词，这样LLM在输入包含prompt tokens的情况下，可以具备预测句子情感的能力。也就是说， <strong>Prompt Learning的目的是训练得到一堆tokens，使得这些tokens与原来的context拼起来可以使得LLM具备新的能力。</strong></p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/1.png#center" alt="你想输入的替代文字"  />
</p>
<p><strong>这篇文章的目的是在图上做Prompt Learning，也就是在训练一个prompt graph，使得现有图拼上这个prompt graph后，预训练的GNN可以在新的任务上（预训练阶段没有接触过的任务上）也表现的较好。</strong> 但是在graph上做Prompt Learning存在以下挑战：</p>
<ul>
<li>自然语言处理中，prompt tokens是一个一维线性的句子，可以放在content的开头或结尾，但是在graph中，节点是非欧结构，因此如何组织prompt tokens，以及如何将graph prompts与input graph结合是一个挑战。</li>
<li>在自然语言处理中，类似于情感分析，和问答任务，这些任务都可以简单的重构为next token prediction（单词预测）的任务，所以只需要使用单词预测来训练prompt就可以。但是在图中，节点级任务、边级任务和图级任务难以统一成一种形式。因此如何将各种prompt任务统一来训练graph prompt也是一个挑战。</li>
</ul>
<p>训练好prompt token的向量化信息、连接结构、以及插入到原图的方式，然后Frozen Pretrained Model应用在这个combined graph上后，就可以为Pretrained Model赋予处理新任务的能力。</p>
<h2 id="reformulating-downstream-tasks">Reformulating Downstream Tasks</h2>
<p>将节点级和边级的下游任务统一为induced graph的标签预测问题。</p>
<p>对于节点预测任务，将它重构为图分类任务：</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/2.png#center" alt="你想输入的替代文字"  />
</p>
<p>将节点标签设置为它的 $k$-hop诱导子图的标签。</p>
<p>将边预测（存在性预测和类别预测都可以，即二分类和多分类）任务也重构为图分类任务，如下：</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/3.png#center" alt="你想输入的替代文字"  />
</p>
<h2 id="prompt-graph-design">Prompt Graph Design</h2>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/4.png#center" alt="你想输入的替代文字"  />
</p>
<p><strong>Prompt Tokens</strong> 首先Prompt graph 定义为 $\mathcal{G}_p(\mathcal{P},\mathcal{S})$，其中每个token $p_i \in \mathcal{P}$是Prompt graph中的节点，它的特征是 $\mathbf{p}_i$，维度与node features相同。</p>
<p><strong>Token Structures</strong> 每个tokens的特征 $\mathbf{p}_i$是随机初始化可学习的，然后可以通过计算相似度并用sigmoid和相应的阈值来控制 $\mathcal{G}_p$的结构。然后可以计算 $\mathbf{p}_k$和节点 $\mathbf{x}_i$之间的相似度来确定该prompt node如何将自身信息与节点 $\mathbf{x}_i$的信息结合，来赋予预训练模型处理节点 $i$相应任务的能力。
$$
w_{i k}= \begin{cases}\sigma\left(\mathrm{p}_k \cdot \mathrm{x}_i^T\right) &amp; \sigma\left(\mathrm{p}_k \cdot \mathrm{x}_i^T\right)&gt;\delta \\ 0 &amp; \text { otherwise }\end{cases}
$$</p>
<p>通过 $\hat{\mathbf{x}}_i=\mathbf{x}_i+\sum_{k=1}^{|\mathcal{P}|} w_{i k} \mathbf{p}_k$ 来为节点 $i$添加提示。</p>
<h2 id="如何训练-prompt-graph使其可以作为预训练模型的有效提示multi-task-prompting-via-meta-learning">如何训练 Prompt Graph，使其可以作为预训练模型的有效提示：Multi-task Prompting via Meta Learning</h2>
<p>学习最好的Prompt，使得该Prompt可以帮助Pretrained Model更好的适应下游任务。</p>
<p><strong>Phase 1</strong> 有一些 Source Task去训练Prompt 的初始值。</p>
<p><strong>Phase 2</strong> 对Target Task做测试。</p>
<p>具体来说，首先对于要训练的prompt graph $\theta$ （即所有token的特征）让它在多个training task上训练，如下图所示，又3个节点分类的tasks，每个tasks里又自己的训练集（support set）和测试集（query set）。每个task都有一个共同的起点，在几个tasks上训练上训练后，每个tasks上有个优化后的task-specific prompt (Prompt 1, Prompt 2, Prompt 3)。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/5.png#center" alt="你想输入的替代文字"  />
</p>
<p>在更新了之后，评估组合起来的Prompt是否会让整体的性能更好，如下图所示，把所有task-specific prompt组合起来，来看组合后的prompt是不是足够好。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/6.png#center" alt="你想输入的替代文字"  />
</p>
<p>如果当前的Initial prompt训练出来的模型在三个tasks上不够好，那么换一个Initial Prompt，直到某个Initial Prompt在所有training tasks经过训练后都表现的较好时，就说明这是一个 <strong>较好的初始prompt (训练起点)</strong>，它适合做training tasks的初始化prompt。</p>
<p>在Meta Training 结束后，我们可以得到一个较好的prompt初始化值，即上图中的Adapt prompt initialization。</p>
<p>在Meta Testing阶段，将我们通过Training Tasks学到的最佳初始Prompt在Test tasks的support set上做微调，然后在Test Task的query set上验证prompt initialization的效果。</p>
<p><img loading="lazy" src="/posts/2025-05-20-AllinOne/7.png#center" alt="你想输入的替代文字"  />
</p>
<p>通过上面方式得到的prompt可以作为graph prompt与input graph 结合，使其具备link prediction和node classification的能力。</p>
<p><strong>可以看作时学习一个图增强，使得预训练的图模型在这个增强图上可以适用于更多任务。</strong></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>LLMs and Graphs</title>
      <link>https://JhuoW.github.io/posts/graphllm/</link>
      <pubDate>Sat, 25 May 2024 01:04:50 +0800</pubDate>
      
      <guid>https://JhuoW.github.io/posts/graphllm/</guid>
      <description>Large Language Model, GNNs, and Foundation Models</description>
      <content:encoded><![CDATA[<h1 id="1-harnessing-explanations-llm-to-lm-interpreter-for-enhanced-text-attributed-graph-representation-learning-tape">1. Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning (TAPE)</h1>
<p><strong>Shallow model:</strong> Encoding the textual attributes using shallow or hand-crafted features such as skip-gram or bag-of-words (BoW) which used in PgG and DGL <strong>are limited in the complexity of the semantic features they can capture.</strong></p>
<p><strong>LM:</strong> 指相对较小并且可以被fine-tune的模型。GIANT <strong>fine-tune</strong> an LM using neighborhood prediction task （在neighborhood prediction task上来微调LM模型）. GLEM <strong>fine-tune</strong> an LM to predict the label distribution from GNN&rsquo;s output (GLEM 用GNN预测的伪标签作为监督信号，让LM来fine tune 节点的文本表示)。这些工作需要大量的计算资源，并且由于要微调模型的参数，所以选取的LM相对较小，比如BERT和DeBERTa，因此缺乏LLM的推理能力。</p>
<p>LLMs refer to very large language models such as GPT-3/4.</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/TAPE.png#center" alt="TAPE"  />
</p>
<p><strong>The present work: LLM augmentation using explanations:</strong> 使用解释作为node feature。通过LLM来解释它的预测，这些解释传达了text与prediction的相关知识和LLM的推理步骤，这些解释信息更易于小LM模型吸收消化。如上图所示，首先绿框中的节点text属性通过自定义的prompt来询问LLM，比如GPT-3.5，让GPT来生成关于文本类别的<strong>预测排名list</strong>（黄色框所示），并且<strong>提供这些得到这些预测的解释理由</strong>。接着，原始text，LLM的预测，以及解释共同用来fine-tune LM，比如BERT或DeBERTa。然后，LM将他们转化为节点的features用于下游预测。</p>
<h2 id="formalization">Formalization</h2>
<p><strong>LM for text classification</strong>
$$
h_n=\mathbf{L M}\left(s_n\right) \in \mathbb{R}^d
$$
其中$s_n \in \mathcal{D}^{L_n}$是节点$n$的文本属性。LM是已经被预训练的模型如BERT和DeBERTa。LM可以将文本属性编码为文本的表示向量$h_n$。</p>
<p><strong>LLM and prompting</strong></p>
<p>输入token序列 $x=\left(x_1, x_2, \ldots, x_q\right)$，目标是输出token序列 $y=\left(y_1, y_2, \ldots, y_m\right)$。并且在输入token序列中加入prompt $p$来对输出施加约束。LLM旨在优化一下条件概率：
$$
p(y \mid \hat{x})=\prod_{i=1}^m p\left(y_i \mid y_{&lt;i}, \hat{x}\right)
$$
其中$\hat{x}=\left(p, x_1, x_2, \ldots, x_q\right)$是使用prompt约束的input token sequence。</p>
<h2 id="tape">TAPE</h2>
<h3 id="使用llms生成预测和解释">使用LLMs生成预测和解释</h3>
<p>LLMs的prompt包括文章的title和abstract，并要求LLMs预测paper的一个或多个类别标签，并且将这些类别标签按从高到低的概率排序，并且要求LLMs提供预测的解释理由，完整prompt如下图所示：</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/tape_prompt.png#center" alt="TAPE"  />
</p>
<p>Abstract输入节点对应paper的摘要，Title输入paper的题目，question则要求模型输出一个或多个paper的预测类别标签并按照可能性排序，同时给出预测的解释。</p>
<h3 id="fine-tuning-lm-interpreter-and-node-feature-extraction">Fine-Tuning LM Interpreter and Node Feature Extraction</h3>
<p>将LM作为LLM得到文本解释的“理解器”。给定两个预训练好的LMs $\mathrm{LM}_{\text {orig }}$ 和$\mathrm{LM}_{\text {expl }}$，他们的输入分别是原始文本特征$s^{\text {orig }}$和该文本特征的解释$s^{\text {expl }}$，这样我们可以分别得到原始文本和解释的text embeddings:
$$
h_{\text {orig }}=\mathrm{LM}_{\text {orig }}\left(s^{\text {orig }}\right) \in \mathbb{R}^{N \times d}, \quad h_{\text {expl }}=\mathrm{LM}_{\text {expl }}\left(s^{\text {expl }}\right) \in \mathbb{R}^{N \times d}
$$
然后要对LM进行Fine-tuning使其与下游任务。首先使用MLP将原始文本和解释的text embedding分别映射到标签空间：
$$
y_{\text {orig }}=\operatorname{MLP}_{\text {orig }}\left(h_{\text {orig }}\right) \in \mathbb{R}^{N \times C}, \quad y_{\text {expl }}=\operatorname{MLP}_{\text {expl }}\left(h_{\text {expl }}\right) \in \mathbb{R}^{N \times C}
$$
通过最小化分类的cross-entropy loss来对LM进行fine-tuning，从而使$\mathrm{LM}_{\text {orig }}$ 和$\mathrm{LM}_{\text {expl }}$可以分别学习到文本和解释与标签之间的关联（什么样的原始文本对应于什么样的标签、什么样的解释对应于什么样的标签）。</p>
<p><strong>Ranked prediction features</strong> LLM同时也给出了对于每个节点文本的类别可能性排名，同样也是有价值的信息。假设每个节点有$C=5$个可能的类别数，对这些类别分别做one-hot编码，节点$i$排名第1的类别为类别4，那么$p_{i,1} = [0,0,0,1,0]$，那么LLM为节点$i$预测的top-$k$个label可以拼接成一个$kC$维的向量。然后通过一个线性变换:
$$
h_{\text{pred}} = \operatorname{MLP}_{\text {pred }}(\operatorname{Concat}(p_{i,1}, \cdots, p_{i,k})) \in \mathbb{R}^{N\times d_P}
$$
可以得到每个节点的排序预测特征，如Figure 1中的$h_{\text{pred}}$所示。</p>
<p><strong>TAPE node feature: $\{[h_{\text {orig }}, h_{\text {expl }}, h_{\text{pred}}]\}$</strong>。其中$h_{\text {orig }}$和$h_{\text {expl }}$是通过LM 对下游任务标签做fine-tuning后的文本特征和解释特征，用来简历原始文本和解释与label之间的联系，$h_{\text{pred}}$是LLMs预测类别标签编码。</p>
<h3 id="gnn-training-with-tape-features">GNN Training with TAPE features</h3>
<p>对于TAPE的三种特征：LM fine-tuning的原始text embedding $h_{\text {orig }}$, LM fine-tuning的解释text embedding $h_{\text {expl }}$，以及LLM的prediction embedding $h_{\text{pred}}$，使用3个GNN模型分别预测labels:
$$
\begin{aligned}
\hat{y}_{\text{orig}} &amp;= \operatorname{GNN}_{\text{orig}}(h_{\text {orig }}, A) \in \mathbb{R}^{N \times C}, \\
\hat{y}_{\text{expl}} &amp;= \operatorname{GNN}_{\text{expl}}(h_{\text {expl }}, A) \in \mathbb{R}^{N \times C}, \\
\hat{y}_{\text{pred}} &amp;= \operatorname{GNN}_{\text{pred}}(h_{\text {pred }}, A) \in \mathbb{R}^{N \times C}
\end{aligned}
$$</p>
<p>然后基于不同特征得到的预测取平均可以得到模型最终的预测label：
$$
\hat{y}=\operatorname{mean}\left(\hat{y}_{\text {orig }}, \hat{y}_{\text {expl }}, \hat{y}_{\text {pred }}\right) \in \mathbb{R}^{N \times C}
$$</p>
<h1 id="2-exploring-the-potential-of-large-language-models-llms-in-learning-on-graphs">2. Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs</h1>
<p><a href="https://arxiv.org/abs/2307.03393">paper</a></p>
<p>Q1: 能否利用LLMs来弥补图神经网络对contextualized knowledge和semantic comprehension理解不足的缺陷？</p>
<p>Q2: LLM能否独立运行于图结构任务？</p>
<h2 id="llms">LLMs</h2>
<h3 id="embedding-visible-llms">Embedding-visible LLMs</h3>
<p>可以获得words, sentences, documents的具体representations（embeddings），如BERT, Sentence-BERT和Deberta。</p>
<h3 id="embedding-invisible-llms">Embedding-invisible LLMs</h3>
<p>用户无法获取和操作embeddings，通常部署在web服务上，如ChatGPT，只能通过text来进行交互</p>
<h3 id="detailed-four-types-of-llms">Detailed four types of LLMs</h3>
<p><strong>Pre-trained Languagge Models (PLMs):</strong> 指相对较小的LLMs，比如Bert和Deberta，并且可以根据下游数据集进行fine-tuning，比如在下游数据集上fine-tune  Deberta然后取最后一个hidden state的embeddings作为text embedding。</p>
<p><strong>Deep Sentence Embedding Models:</strong> 使用PLMs作为base encoders，并且将训练好的PLMs进一步进行监督或对比学习<strong>预训练</strong>。这样的模型通常不需要Fine-tuning。</p>
<p><strong>Large Language Models:</strong> 与PLM相比，LLMs具有更强的能力和更多数量级的参数。</p>
<h2 id="llms-as-enhancers">LLMs-as-Enhancers</h2>
<p><strong>利用LLMs来增强节点的文本属性特征，然后用GNN生成预测。</strong></p>
<p>How LLMs can enhance GNNs by leveraging their <strong>extensive knowledge</strong> and <strong>semantic comprehension</strong> capability?</p>
<p>Challenge: 不同的LLMs能力不同，越强大的模型有更多使用限制，因此需要对不同的LLMs针对性设计使用策略来充分利用他们的能力。</p>
<h3 id="feature-level-enhancement">Feature-level Enhancement</h3>
<h4 id="1-cascading-structure-级联结构">1. Cascading Structure 级联结构</h4>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/cascading.png#center" alt="Cascading Structure"  />
</p>
<p>先试用embedding-visible的LLMs来对dataset中的text attribute做fine-tuning，然后生成每个节点的文本特征的embeddings，然后将这些embeddings作为node features，与图结构一起数据GNN中来训练GNN模型。</p>
<h4 id="2-iterative-structure-迭代结构">2. Iterative Structure 迭代结构</h4>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/iterative.png#center" alt="iterative Structure"  />
</p>
<p>如GLEM[1]，在E步根据真实标签和GNN预测的伪标签来训练PLM，在M步根据真实标签和PLM预测的伪标签和PLM学到的text embedding作为node feature来训练GNN模型，然后训练好的GNN模型和PLM模型都可以用来作为节点标签预测器。</p>
<h4 id="node-classification-comparison">Node Classification Comparison</h4>
<p>实验结果来看，</p>
<ol>
<li>在下游数据集上fine-tuned PLM模型取最后一层作为text embedding，然后GNN作为predictor的效果来看，fine-tuned PLM并不比简单点TF-IDF强。对于不同的text embedding方式（Fine-tuned PLM，PLM without fine-tuning，online sentence embedding）GNN的表现各不相同。</li>
<li>在监督训练数据较少的情况下，fine-tuned PLM和迭代结构的GLEM学习到的text embedding用到GNN后，得到的结果比普通的TF-IDF差。</li>
<li>使用Deep Sentence Embedding Models 如sentence-bert学习到的text embedding + GNN predictor的效果较好。</li>
<li>LLama的效果弱于deep sentence embedding models，说明简单的增加参数并不能生成对GNN有用的text embedding。</li>
</ol>
<h3 id="text-level-enhancement">Text-level Enhancement</h3>
<h4 id="1-tape">1. TAPE</h4>
<p>使用文本和LLM解释来fine-tuning PLM，LLM的分类解释和分类排序作为增强text embedding。</p>
<h4 id="2-knowledge-enhanced-augmentation-kea">2. Knowledge-Enhanced Augmentation (KEA)</h4>
<p>使用额外的knowledge来增强PLM。</p>
<h4 id="node-classification-comparison-1">Node Classification Comparison</h4>
<p>实验结果来看，</p>
<ol>
<li>TAPE的效果主要受益于LLMs生成的文本解释。</li>
<li>TAPE原文中采用PLM （Deberta）作为LM，将text attribute和explanation以及任务的label用来fine-tune PLM。而local sentence embedding model e5-large不fine-tune 直接用text attribute以及LLM的explanation来输出embeddings，相比于TAPE中使用的fine-tuned PLM，e5得到了更好的效果。</li>
</ol>
<h2 id="llms-as-predictors">LLMs-as-Predictors</h2>
<p><strong>LLMs作为独立的predictor</strong></p>
<p>How LLMs can be adapted to explicit graph structures as a <strong>predictor</strong>?</p>
<p>Challenge: 如何设计prompt使得LLM可以处理图中的structure和attribute信息。</p>
<p>直接使用LLM来预测节点类别标签可以使用以下几种prompt策略：</p>
<ol>
<li><strong>Zero-shot prompts:</strong> 给定单一节点的文本信息，让LLM预测它的类别标签，如下面的prompt所示。</li>
</ol>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/zero_shot_prompt.png#center" alt="zero-shot prompt"  />
</p>
<p>​       其中，Paper是一个节点的text attribute，Task提供可能的类别标签，然后prompt要求LLM输出一个最可能的类别。</p>
<ol start="2">
<li><strong>Few-shot prompts:</strong> 如下图所示，先按照zero-shot的形式给出一些node samples的 prompts，<strong>以及这些samples的ground-truth标签</strong>。最后，给出目标节点的prompt，要求LLMs输出节点的类别。</li>
</ol>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/few_shot_prompt.png#center" alt="few-shot prompt"  />
</p>
<ol start="3">
<li><strong>Zero-shot prompts with CoT (Chain-of-Thoughts):</strong> 基于zero-shot prompt，在prompt中进一步要求LLM生成思考过程，也就是<strong>Think it step by step and output the reason in one sentence</strong>  (用一句话来概括推理步骤)。</li>
</ol>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/zero_shot_cot.png#center" alt="zero-shot cot"  />
</p>
<ol start="4">
<li><strong>Few-shot prompts with CoT:</strong> 使用第三个prompt的zero-shot prompts with CoT来分别为多个sample生成推理步骤的sentences，然后将这些这些samples的文本内容、Ground-truth标签和CoT process共同作为prompt，并且要求LLM为当前的目标node输出预测标签以及CoT。</li>
</ol>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/few_shot_cot.png#center" alt="few-shot cot"  />
</p>
<h1 id="3-one-for-all-towards-training-one-graph-model-for-all-classification-tasks">3. One for All: Towards Training One Graph Model for All Classification Tasks</h1>
<p><strong>What is in-context learning?[2]</strong></p>
<p>&ldquo;In-Context Learning is a way to use LLMs to learn tasks given only a few examples. During in-context learning, we give the LM a prompt that consists of a  list of input-output pairs that demonstrate how to perform a task. At  the end of the prompt, we append a test input and allow the LM to make a prediction just by conditioning on the prompt and predicting the next  tokens. For example, to answer the two prompts below, the model needs to examine the training examples to figure out the input distribution  (financial or general news), output distribution (Positive/Negative or  topic), input-output mapping (sentiment or topic classification), and  the formatting. &quot;</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/icl.gif#center" alt="ICL"  />
</p>
<p>如上图（from [2]）所示，在prompt中包含一些上下文input-output pairs来演示（demonstrate）如何执行任务。在这些prompt的最后添加text input token来让LLM学习上下文中的演示来执行text input token的任务。</p>
<h2 id="challenge">Challenge</h2>
<p>Foundation Model指用单一模型来解决多个任务。但是Graph Foundation Model面临以下挑战：（1）不同来源的图数据在feature表征上通常完全不同。比如molecular graph中的节点特征是其中原子nominal feature的索引，e-commerce networks中的节点特征通常用Bag-of-Word来编码。这些不同来源的图数据特征维度、语义信息和尺度的差别都很大，几乎不可能用同一个模型来学习他们的表示。（2）不同的下游任务涉及图的不同部分（节点级、边级、图级）需要不同的策略和方法来学习表示。（3）如何设计统一的模型来实现跨领域和in-context learning是不确定的。</p>
<h2 id="ofa-one-for-all">OFA (One-for-All)</h2>
<h3 id="将不同domian的图转化为统一的tag形式">将不同Domian的图转化为统一的TAG形式</h3>
<p>用human-interpretable language来描述节点和边的属性，从而使LLM可以将这些text attribute编码到同一个空间。具体来说，通过以下方式来生成每个节点的text feature:</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/node_text_feature.png#center" alt="text feature"  />
</p>
<p>将不同domain的graph的节点属性用统一形式的文本来描述，如上图中，对于一个节点的特征，它的文本描述以<strong>Feature node</strong>开头，后面的每个$&lt;\text{feature describe}&gt;:&lt;\text{feature content}&gt;$是该节点的一个type-content文本对。如对于一个molecule graph，其中的一个节点是原子，那么它的type是<strong>Atom</strong>，它的content是该原子的属性文本描述<strong>Carbon, Atomic number 6, helix chirality</strong>。同理，边的text feature以<strong>Feature edge</strong>开头进行文本描述。</p>
<p>在用以上方式得到节点$v_i$的text feature $s_{v_i}$和边$e_{ij}$的text feature $s_{e_{ij}}$后，用LLM（这里用sentence transformer）来将每个节点和边的text feature编码为vector embeddings：
$$
x_i = \operatorname{LLM}(s_{v_i}), \quad x_{ij} = \operatorname{LLM}(s_{e_{ij}})
$$</p>
<h3 id="用nodes-of-interest-noi来统一不同的图任务">用Nodes-of-Interest (NOI)来统一不同的图任务</h3>
<p>图上的任务主要分为3中：node-level tasks，link-level tasks和graph-level tasks。如果要用一个模型来处理这些任务的话，<strong>需要将这些任务统一为一个任务以便于在图数据上训练</strong>。</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/NOI.png#center" alt="NOI"  />
</p>
<p>Nodes-of-Interest (<strong>NOI</strong>)指的是一个任务的<strong>目标节点</strong>，如上图的蓝色节点所示，表示为$\mathcal{T}$。对于节点级任务，NOI是待预测节点集合，边级任务NOI是待预测是否有边的节点对，图级任务NOI是待预测图中的所有节点。若一个NOI节点$v$的$h$-hop局部子图表示为$\mathcal{S}_h(v)$，那么NOI中所有目标节点的局部子图共同构成了一个<strong>NOI subgraph</strong>，表示为$\mathcal{G}_h (\mathcal{T})$。
$$
\mathcal{G}_h(\mathcal{T})=\bigcup_{v \in \mathcal{T}} \mathcal{S}_h(v)=\left\{\bigcup_{v \in \mathcal{T}} \mathcal{V}_v^h, \bigcup_{v \in \mathcal{T}} \mathcal{E}_v^h, \bigcup_{v \in \mathcal{T}} \mathcal{R}_v^h\right\}   \quad \text{NOI中所有节点的局部子图共同构成}
$$
<strong>NOI prompt node</strong>：定义NOI prompt node，该节点的文本信息用来描述任务，比如某个数据集上的节点分类、图分类等。NOI prompt node的节点text feature以如下形式构建：</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/NOI_prompt_node.png#center" alt="NOI"  />
</p>
<p>即每个数据集的一个task对应于一个prompt node，该node用来描述task。这样，把不同的图任务都用节点的text feature这种统一的形式来表达。</p>
<h3 id="graph-in-context-learning的图提示范式graph-prompting-paradigm">Graph In-Context Learning的图提示范式（Graph Prompting Paradigm）</h3>
<p>LLM的一大特性就是它可以通过prompt来实现in-context learning，使得模型可以在不用fine-tuning的情况下适应于不同的任务。比如在few-shot场景下，目标是基于一篇paper的摘要和内容预测它的类别，我们可以为LLM提供每个类别的$k$篇papers作为context加入prompt中，来指导模型基于这些提供的context来生成目标摘要和内容的类别预测。（通过一些<strong>任务相关的其他信息</strong>来指导模型对目标样本的预测）</p>
<p>本文发现实现图上in-context learning的核心在于操作输入图使其和下游任务对齐。<strong>Graph Prompting Paradigm (GPP)</strong> 即图提示范式旨在操作输入图使其可以从输入数据本身获得任务相关的信息。如图2中的虚线所示，用来描述任务的NOI prompt node与所有NOI node建立连接（任务的目标节点），表示在这些NOI nodes上执行对应prompt的任务（如节点分类，链路预测，图分类等）。图中的$p2t$和$t2p$ edge表示NOI节点和prompt node之间的边。下一步建立NOI prompt node和具体类别之间的联系，如图2中的<strong>Class Node</strong>用来描述该分类任务的每个类别的类信息，任务有多少个类，就有多少个Class Node。Class Node的Text feature如下图所示：</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/class_node.png#center" alt="NOI"  />
</p>
<p><strong>Zero-shot Learning:</strong> 对于NOI中的一个节点$q$，用于描述它的任务的NOI prompt node $p_q$，以及Class Node $\{c_i | i \in [N]\}$ ，其中$N$为任务的类别数。prompt node，class node，以及和prompt node 连接的所有边（包括与NOI连接的边）共同构成了<strong>prompt graph</strong> $\mathcal{P}=\left(\mathcal{V}_p, \mathcal{E}_p, \mathcal{R}_p\right)$。</p>
<p>然后，prompt graph $\mathcal{P}=\left(\mathcal{V}_p, \mathcal{E}_p, \mathcal{R}_p\right)$和NOI subgraph (即NOI节点的局部子图)相结合为<strong>通用graph model</strong>的输入图$\mathcal{G}_m=\left(\mathcal{V}_q^h \cup \mathcal{V}_p, \mathcal{E}_q^h \cup \mathcal{E}_p, \mathcal{R}_q^h \cup \mathcal{R}_p\right)$。如图2中的（a）(b)（c）都是graph model的输入图。通过模型的学习，可以得到每个Class node 的embeddings，如类别$c_i$的Class node embedding为$h_{c_i}$。因为$c_i$与任务相关的prompt node 连接，而prompt node与目标NOI node 连接，因此可以用$h_{c_i}$来推断NOI node属于类别$c_i$的概率：
$$
P[\text { NOI belongs to class } i]=\sigma\left(\operatorname{MLP}\left(h_{c_i}\right)\right)
$$</p>
<h1 id="4-talk-like-a-graph-encoding-graphs-for-large-language-models">4. Talk like a Graph: Encoding Graphs for Large Language Models</h1>
<p>prompt engineering的目的是找到一个合适的方式使LLM $f$可以解析问题$Q$，并且得到他的Answer $\mathcal{A}$，即$\mathcal{A} = f(Q)$。本工作的目标是为LLM$f$提供图$G$，使得LLM可以对图做推理QA，即$\mathcal{A} = f(G,Q)$。在该工作中，固定LLM $f$的参数不变，并引入一个图编码函数（graph encoding function）$g(G): G \to W$用于将图结构数据编码成text，以及一个问题重解析函数$q(Q): W \to W$。训练数据$D$有图$G$，问题$Q$和回答$S$组成，即每个训练数据$(G,Q,S) \in D$。训练目标是固定大语言模型$f$不变，找到最佳的图编码函数$g$和问题重解析函数$q$，使得给定训练$G$和$Q$，得到回答$S$的分数最高：
$$
\max _{g, q} \mathbb{E}_{G, Q, S \in D} \operatorname{score}_f(g(G), q(Q), S)
$$</p>
<h3 id="graph-encoding-function-gg">Graph encoding function $g(G)$</h3>
<p>$g(G)$用于将$G$映射为LLM可以处理的token：首先，encode图中的节点，然后encode图中的边。具体编码技术如下图所示：</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/encoding_graph.png#center" alt="NOI"  />
</p>
<p><strong>Encoding Nodes</strong>:</p>
<ol>
<li>
<p>整型节点编码：$G$ describes a graph among nodes 0,1,2,3,4,5,6,7</p>
</li>
<li>
<p>使用well-known English first names：$G$ describes a friendship among James, Robert, Michael, Mary.</p>
</li>
<li>
<p>使用电视剧《权力的游戏》和《南方公园》中流行的角色名字。</p>
</li>
<li>
<p>包括美国政治家的名字。</p>
</li>
<li>
<p>用字母表示的。</p>
</li>
</ol>
<p><strong>Representing Edges</strong>:</p>
<ol>
<li>用括号表示边：The edge in $G$ given as (0,1), (0,2), &hellip;, (6,7), (7,8)</li>
<li>Friendship: source node and target node are friends. 如 We have the following edges in $G$: James and Robert are friends, &hellip; Jennifer and Linda are friends。对应于上面的well-known English first name表示节点</li>
<li>Coauthorship: 比如 James and Robert wrote a paper together 来表示一条边</li>
<li>Social network: James and Robert are connected来表示一条边</li>
<li>Arrows: A-&gt;B 来表示边</li>
<li>Incident: Node 8 is connected to nodes 3,7 来表示每个节点的<strong>邻域</strong>。</li>
</ol>
<h2 id="experiments">Experiments</h2>
<p>使用PaLM 62B作为LLM，在不同图任务以及不同图编码器下的准确率比较，最有效的prompt (zero-shot、zero-cot、few-show、cot、cot-bag)用下划线标出，最佳图编码器用加粗标出。实验使用ER Graph作为数据集，ER Graph的统计数据如下表所示，可以看出平均节点数为12.37，平均边数为39.79，平均度为5.70。对于边存在任务，有53.96%的情况不存在边，对于cycle check任务，有81.96%的情况存在cycle（因为ER graph很可能存在cycle）。</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/graphqa_dataset.png#center" alt="graphqa_datase"  />
</p>
<p>从下面的实验结果可以看出，LLM在所有prompt heuristic的所有graph encoding function上预测的最高边存在概率为44.5%，76%的情况存在cycle。而在Node degree 任务上，均与真实平均度5.7差距较大，平均边数也与真实情况差距较大。</p>
<p>简单的Prompt比如zero-shot 在简单的任务上比复杂的prompt比如zero-cot效果更好，因为简单的任务无需多跳推理。</p>
<p>graph encoding function对LLM影响巨大。</p>
<p>整型节点编码可以提升算数性能，比如node degree、node count和edge count的预测。</p>
<p><img loading="lazy" src="/posts/2024-05-26-graphllm/graphqa_exp.png#center" alt="graphqa_exp"  />
</p>
<h1 id="5-can-language-models-solve-graph-problems-in-natural-language">5. Can Language Models Solve Graph Problems in Natural Language?</h1>
<p>[1] Learning on Large-scale Text-attributed Graphs via Variational Inference.</p>
<p>[2] <a href="https://medium.com/@francescofranco_39234/in-context-learning-icl-a775cd8b7261">https://medium.com/@francescofranco_39234/in-context-learning-icl-a775cd8b7261</a></p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
